,title,author,date,score,num_comments,upvotes_ratio
0,I have no experience with gsync but is this normal i have this monitor since last week and i am getting lower hz then what my fps is in game ?,Due-Department230,2021-05-29 23:05:08,1,3,1.0
3,Ready for retirement.,Z06Chris,2021-05-29 18:51:47,36,20,0.84
4,New MSI RTX 3070 Suprim X build I finished a couple weeks ago.,lllPrecisionlll,2021-05-29 18:32:34,7,4,0.73
5,3080 Strix white build,matthewgallo98,2021-05-29 17:39:45,6,10,0.65
7,Dyst-MMXX1 Ver. 1 with a Gigabyte Vision RTX 3070. I feel in love with this card. Chasing the 3080 version.,MechanicalPencilGirl,2021-05-29 15:28:23,0,10,0.4
8,All Black Build,Cireme,2021-05-29 15:10:45,136,17,0.92
10,Recently completed 3090/5900x build & setup! (also my first Reddit post!),Snoo_52037,2021-05-29 14:58:00,5,10,0.6
11,My first PC build,Fistedwaffel,2021-05-29 14:15:40,22,20,0.72
12,My first water cooled build! Including a 3080 wrapped in a Eiswolf 2 AIO,ixRobin,2021-05-29 13:18:45,8,4,0.65
14,My first pc build,Thijmen_07,2021-05-29 12:41:39,2447,149,0.97
16,"My First Custom Hard Tube Open Water Loop. Built on an intel i9 11900K paired with an RTX 3090 TUF-Gaming Edition. A Z590 Asus Rog Maximus XIII, and 32gbs of G.Skill Trident Royal Z Silver 4000MHZ CAS 18. Cooled by EKWB Quantum and ThermalTake Quad 120mm (x9) and Trio 200mm (x4) fans and 1200W TTP",Dry-Manufacturer7248,2021-05-29 06:16:54,145,22,0.87
17,NVIDIA’s Android SHIELD TV is getting an update that adds new controller and peripheral support,reps_up,2021-05-28 22:21:53,27,13,1.0
18,GeForce 466.47 Driver Performance Analysis – Using Ampere and Turing,thestigmata,2021-05-28 21:03:05,57,10,0.94
21,"My first build, featuring an EVGA 3060.",ByAlexandros,2021-05-28 17:56:38,75,40,0.87
24,NVIDIA GeForce RTX 3080 Ti Founders Edition pictured,Dangerman1337,2021-05-28 15:42:22,40,84,0.89
27,Meshify 2 Compact Build,SE-ResNeXt,2021-05-28 14:30:42,3057,182,0.97
28,TechPowerUp GPU-Z v2.40.0 Released,GPUNV,2021-05-28 14:21:02,32,0,0.95
31,NVIDIA GeForce RTX 3060 LHR and RTX 3080 Ti with new crytomining limiter have been tested,AidThisFellowUser,2021-05-28 11:43:10,46,85,0.82
33,"GeForce RTX 3080 Ti from MSI, EVGA, GALAX and Colorful have leaked",GPUNV,2021-05-28 09:47:48,18,10,0.83
35,NVIDIA GeForce RTX 3080 Ti final specifications confirmed - VideoCardz.com,ryandtw,2021-05-27 22:20:35,715,171,0.96
36,NVIDIA GeForce RTX 3080 Ti tested in Ashes of the Singularity - VideoCardz.com,ryandtw,2021-05-27 19:00:14,12,23,0.77
37,Keeping Games Up to Date in the Cloud with GeForce NOW | NVIDIA Blog,Nestledrink,2021-05-27 18:26:51,7,2,0.66
38,Marbles RTX Playable Sample Now Available in NVIDIA Omniverse | NVIDIA Blog,Nestledrink,2021-05-27 18:26:10,10,8,0.71
39,NERSC Turns on World's Fastest AI Supercomputer,Nestledrink,2021-05-27 18:12:25,14,10,0.86
40,"Acer announces Predator Triton 500 SE with i9-11980HK, RTX 3080 and 16-in 1250 nits display",AidThisFellowUser,2021-05-27 17:19:40,9,4,0.91
41,Quake II RTX Performance For AMD Radeon 6000 Series vs. NVIDIA On Linux,St3fem,2021-05-27 17:58:10,32,27,0.81
47,"Nvidia Expects RTX 30-Series Supply Shortages to Last Until ""The Second Half of the Year""",Dookman,2021-05-27 11:56:10,146,173,0.97
49,"MSI GeForce RTX 3070 Ti SUPRIM and VENTUS 3X pictured, GDDR6X confirmed - VideoCardz.com",ryandtw,2021-05-27 10:00:31,21,29,0.87
51,NVIDIA GeForce RTX 3080Ti is just as fast as RTX 3090 in Geekbench CUDA benchmark - VideoCardz.com,ryandtw,2021-05-27 09:19:21,1886,216,0.97
52,Next-Gen Nintendo Switch with OLED screen allegedly launches in September - VideoCardz.com,Nestledrink,2021-05-27 06:18:41,107,90,0.9
60,"NVIDIA RTX, Unreal Engine 5 Define Future of Game Development and Content Creation",GPUNV,2021-05-26 17:34:17,29,20,0.9
61,Unreal Engine 5 is now available in Early Access,GPUNV,2021-05-26 16:04:51,1165,232,0.98
62,NVIDIA GeForce Event - May 31st @ 10pm Pacific time (June 1st @ 1am Eastern Time),Nestledrink,2021-05-26 15:10:02,336,131,0.94
66,GALAX GeForce RTX 3060 LHR with GA106-302 goes on sale for 966 USD,ForgetfulKiwi,2021-05-26 09:33:39,188,188,0.93
72,EK Water Cooled Backplate For RTX 3080 / 3090,philosopherzen,2021-05-25 16:27:39,11,14,0.71
75,Alphacool launches Eisblock for RX 6800 Nitro+ & RTX 3080/3090 XC3 Ultra Gaming GPU,AidThisFellowUser,2021-05-25 14:02:55,3,1,0.8
76,"ASUS submits 100+ new GeForce RTX 3080Ti, RTX 3070Ti, LHR and CMP models to EEC",AidThisFellowUser,2021-05-25 11:57:26,1220,172,0.97
77,"LEADTEK GeForce RTX 3080 Ti WinFast Hurricane pictured, 12GB memory confirmed",AidThisFellowUser,2021-05-25 11:56:42,41,13,0.89
81,Realistic Lighting in Justice with Mesh Shading,Kaladinar,2021-05-24 20:41:26,555,47,0.97
84,Finally completed my build with a 3070 (bad lighting because my monitors are on),yooloo33,2021-05-24 01:40:08,0,35,0.4
85,Another 3080 FE Thermal Pad Replacement Success Story (-20C VRAM),Fidler_2K,2021-05-24 01:16:34,71,66,0.95
87,"Finished my build! Ryzen 7 3700x, 64GB Ram, 1TB M2 SSD and a RTX 3070 🙂🙂🙂🙂",Fun_Ear1634,2021-05-23 23:17:54,62,71,0.81
90,My 3060ti Build,bluerailz142,2021-05-23 21:00:24,9,12,0.61
91,White Strix 3080 to complete my rig!,yoitsbenvo,2021-05-23 20:43:46,3747,200,0.96
92,ek water block on the rtx 3090 msi gaming x trio is gorgeous,MC_SULY,2021-05-23 15:56:05,85,30,0.83
93,Razer officially taking preorders for GeForce RTX 3080Ti and RTX 3070Ti prebuilt systems on Chinese Tmall,sips_white_monster,2021-05-23 09:17:07,47,12,0.98
95,My 3060 TI build 🥰,SavingsAd3152,2021-05-23 04:20:04,30,39,0.71
96,final gaming set up <3,zerodegreeCx,2021-05-23 03:01:43,40,15,0.77
98,Best looking 3080 there is!,WhiteStar01,2021-05-23 03:47:39,0,14,0.37
99,"Was hoping for a 3080, but I guess a 3070 will do",GenericGoch,2021-05-23 03:47:17,77,118,0.81
100,Finally got my 3080 to complete my build,Justin_Herbert_1O,2021-05-23 01:24:56,2624,167,0.96
102,"Finally tidied up my workstation interior, never look inside it but it's nice to know it's looking alright.",Wet-Goat,2021-05-22 18:32:20,39,11,0.77
103,Did a little something with the 3080 FE I snagged - first water cooling attempt,Xhnoa,2021-05-22 13:34:37,25,9,0.73
104,Asus TUF 3080 10c+ GDDR6X temp drop with one extra peice of thermal pad where there was none.,b3rdm4n,2021-05-22 11:08:00,1512,238,0.99
105,Toxic trap. Baby and Mando in trouble.,RealityOfModernTimes,2021-05-22 09:16:18,28,5,0.68
106,RGB Me Up for MSRP,T04STY2030,2021-05-22 08:53:13,6,9,0.6
107,NVidia Marbles Demo running great in Omniverse on the RTX 3090 (101.0+ release),bozog,2021-05-22 07:32:45,16,11,0.76
109,Out with the old and in with the new: finally joined team green!,ThePinda,2021-05-22 02:24:16,38,26,0.79
110,The Gigabyte AORUS RTX 3090 XTREME Is HUGE!,Aceolus,2021-05-21 21:54:03,4962,325,0.96
113,NVIDIA 470 Series To Be The Last Supporting GTX 600/700 Series Kepler,pi314156,2021-05-21 16:36:09,37,17,0.93
115,Nvidia Declares 4-For-1 Stock Split,Nestledrink,2021-05-21 14:07:01,69,54,0.97
116,"NVIDIA GeForce RTX 3080Ti to be available on June 3rd, RTX 3070Ti on June 10th",AidThisFellowUser,2021-05-21 12:47:15,1752,650,0.95
119,NVIDIA: Founder Edition Cards will not get a Lite Hash rate Limiter SKU,HeadLemming,2021-05-20 18:36:12,757,278,0.98
122,LEADTEK and PALIT confirm GeForce RTX 3080 Ti with 12GB GDDR6X memory,AidThisFellowUser,2021-05-20 11:55:00,1063,286,0.98
127,XMG announces NEO 15 and NEO 17 with Intel Core i7-11800H and GeForce RTX 3080 165W,AidThisFellowUser,2021-05-19 13:51:14,31,13,0.93
132,"NVIDIA DLSS: No Man’s Sky And 8 Other Games, Including The First VR Titles, Add Performance-Accelerating Tech This Month",Nestledrink,2021-05-18 21:10:34,73,38,0.95
135,"ZOTAC adds GeForce RTX 3090Ti, RTX 3080Ti and RTX 3070Ti to its FireStorm software",AidThisFellowUser,2021-05-18 19:48:22,66,90,0.94
137,AMID EVIL with RTX | Available Now,abracadaver82,2021-05-18 17:18:48,52,30,0.93
141,No Man's Sky Nvidia DLSS support coming soon,AidThisFellowUser,2021-05-18 13:54:16,2361,256,0.97
143,A Further Step to Getting GeForce Cards into the Hands of Gamers,GPUNV,2021-05-18 13:11:55,178,367,0.88
152,Gigabyte refreshes its GeForce RTX 3060 lineup with Lite Hash Rate editions,AidThisFellowUser,2021-05-17 13:40:25,74,46,0.96
153,NVIDIA GeForce RTX 30 graphics card cost 3 times more than NVIDIA MSRP in Europe,AidThisFellowUser,2021-05-17 12:10:01,2406,627,0.99
157,Got lucky with a BestBuy 3090 FE and decided to go for my first attempt at water cooling!,Eturnus,2021-05-17 02:23:28,63,38,0.79
158,Still can’t believe i got a 3090,JustScxr,2021-05-17 02:07:51,16,23,0.59
160,Sometimes I just stare at it in disbelief that I actually own one,TheHeroicOnion,2021-05-16 23:53:36,2900,359,0.93
166,"New white build, Zeus! Went from black Meshify mATX to, be quiet 500dx in white. Added new mb(b550 vision d-p) and aio(Phanteks Glacier one). Pics of my old build at the end. I need to add some all white cables and maybe switch to white RAM.",thanaldo,2021-05-16 17:36:33,0,5,0.45
167,Lian Li 011D Mini - ATX W/Dual EK 360mm Rads.,markymike111,2021-05-16 17:06:15,57,15,0.83
171,EK announces water blocks for AORUS XTREME/MASTER GeForce RTX 30 series,AidThisFellowUser,2021-05-16 13:00:30,4,3,0.7
172,Aircooling wasn't working with my OC ambitions - 3080 FTW3 Ultra & 5800x,GinNJews,2021-05-16 12:46:33,2281,141,0.97
173,First waterloop and first FE card,remco_remember,2021-05-16 10:53:28,83,31,0.85
174,"3080FE and 3700X in a Fractal Meshify 2. Kind of first/second water cooled build. I did the same build with different parts, but didn't like the results, so I rebuilt.",SimpleJoint,2021-05-16 10:51:01,3,4,0.55
179,Rog strix 3090 stock pads and paste 88-90c 120 m/h,Nearby_Independent75,2021-05-16 03:13:18,0,21,0.23
180,Excuse the rainbow rgb. Lian li software won't work to change their color for uni120 fans. I present to you. Ryzen 5950x pair with Asus rog strix 3090 and Asus Crosshair Dark Hero !,OpportunityNo1834,2021-05-16 00:43:50,0,13,0.49
181,Yay! Noctua build 5950x 3090 ftw3,W1zard0fW0z,2021-05-15 23:38:34,32,43,0.78
182,My first build since 2004,Camtown501,2021-05-15 23:18:21,11,9,0.63
183,RTX 3080 with 9900k and 32GB of RAM. In love my my first custom loop and amazing Temps,phydps,2021-05-15 21:22:36,17,21,0.67
184,EVGA 3090 FTW3 teardown and replace thermal pads & paste,SilverStig,2021-05-15 18:59:36,82,84,0.92
186,My First PC build.,FrostDesigns,2021-05-15 17:41:31,33,8,0.72
188,[Digital Foundry] Nvidia Marbles RTX Hands-On: A Vision For The Future Of Ray Tracing?,Nestledrink,2021-05-15 14:47:37,36,10,0.92
189,"After 2 years of saving and an additional half year of GPU hunting, I have finally ascended!",DNXPeeJay,2021-05-15 14:11:55,41,27,0.72
190,First Time Builder 3080FE & 5800x,Free_Papi,2021-05-15 11:02:05,3653,370,0.96
191,RTX3080 - power draw with ray tracing on is 180 watts / 70% more than without.,marcosscriven,2021-05-15 09:28:16,3,29,0.59
192,MSI confirms GeForce RTX 3080 Ti 12GB and RTX 3070 Ti 8GB SUPRIM series - VideoCardz.com,ryandtw,2021-05-15 08:56:25,49,52,0.95
193,"Decided to upgrade the thermal pads, love that die shot :)",Sipheren,2021-05-15 01:04:18,32,5,0.82
194,NVIDIA Magnum IO GPUDirect Storage is now in open beta,BBelichick8,2021-05-15 00:29:07,25,12,0.94
196,"Got my hands on a 3080, and it's half my computer... Literally",CorerMaximus,2021-05-14 21:09:01,211,56,0.91
199,Metro Exodus Enhanced Edition - A New Gen of Raytracing,TheBvdder,2021-05-14 16:46:38,2291,218,0.98
200,NVIDIA Omniverse Machinima - Now Available in Open Beta,Ex0dus13,2021-05-14 16:19:53,30,1,0.92
203,"Decided to upgrade from my old build (last pic). First all white, all Corsair build. I'm especially happy with how the RGB strip behind the side panel turned out.",Benniisan,2021-05-14 14:36:41,17,20,0.71
205,EVGA RTX 3090 FTW3 ULTRA VS NZXT H1,Alucardis666,2021-05-14 13:17:57,0,0,0.25
206,Malicious Software Website Impersonating MSI Official Website (MSI Afterburner),sips_white_monster,2021-05-14 10:17:49,82,27,0.97
207,Metro Exodus Enhanced RTX Screenshots,pattybarf,2021-05-14 06:36:06,1709,224,0.98
214,"AORUS announces 17X gaming laptop: Core i9-11980HK, GeForce RTX 3080 + 300Hz LCD",AidThisFellowUser,2021-05-13 20:07:38,37,3,0.92
216,GeForce 466.27 Driver Performance Analysis – Using Ampere and Turing,thestigmata,2021-05-13 12:34:26,752,137,0.98
226,"PALIT submits GeForce RTX 3080Ti, RTX 3070Ti, RTX 3050Ti and CMP HX series to EEC - VideoCardz.com",velocityseven,2021-05-12 18:53:18,46,49,0.92
227,NVIDIA GeForce RTX 3080 Ti category shows up on MSI website,AidThisFellowUser,2021-05-12 18:15:37,1344,57,0.97
235,I made a spreadsheet with all 30-Series mobile GPUs based on TGP to hopefully clear up some buyer confusion (UPDATED),Fidler_2K,2021-05-11 19:36:18,1835,190,0.99
237,"[Phoronix] NVIDIA 460.80 Linux Driver Released With New Laptop GPU Support, Bug Fixes",InvincibleBird,2021-05-11 17:33:53,5,2,0.86
240,New List of Games coming to GeforceNow this May,AidThisFellowUser,2021-05-11 15:51:25,30,7,0.83
241,Nvidia GeForce RTX 3050 Ti Laptop GPU Performance Review,madn3ss795,2021-05-11 11:36:16,34,31,0.91
243,Found my favorite example of what Metro's ray traced global illumination can do. Check out the indirect shadows from the chair wheels!,LamboDiabloSVTT,2021-05-11 02:48:43,55,47,0.91
246,RTX 3050Ti laptop already available in Indonesia,Blacyess,2021-05-10 22:52:45,26,10,0.91
247,"Ray Tracing in the new Resident Evil game is truly breathtaking. All settings maxed, quality 2.0, 1440p using an RTX 3090 + AMD 5950x",kizzle69,2021-05-10 21:32:14,2331,389,0.95
253,EK announces Quantum Vector XC3 water block for EVGA RTX 3070 graphics cards,AidThisFellowUser,2021-05-10 12:54:55,25,8,0.97
254,Modded GeForce RTX 2080 Ti supports 22GB of GDDR6 memory,AidThisFellowUser,2021-05-10 12:53:58,1171,142,0.94
256,Helios Strix 3070 2021 build complete!,xdamm777,2021-05-09 23:17:11,56,24,0.81
257,"I Can't Believe It's Not Incomplete Anymore! NR200P, 3070 + 5600X Build + Tips Build/Photos",fabless_semicon,2021-05-09 21:42:01,2312,91,0.97
259,Nvidia's Marbles Tech Demo is now available to download via Nvidia Omniverse,IrishWolfhound-419,2021-05-09 16:21:34,67,54,0.9
262,"3080 TUF (OC version due to higher stock levels) for hopefully years of solid high setting 1440p gaming. Fortunate buy last year after waiting in a queue post-release (Aus). Paired with 5900x. Featuring Lian Li anti sag bracket, cut down to allow this GPU to click into the PCI-E lock - feels sturdy.",dashylorian,2021-05-09 14:04:58,1547,158,0.95
263,The Chip Shortage Keeps Getting Worse. Why Can’t We Just Make More?,overclockwiz,2021-05-09 12:05:47,209,190,0.96
265,"Been 10 years since my last build, 2020/2021 has pretty good to me. :)",Ryasha,2021-05-09 02:24:41,56,21,0.78
268,Unbox an Extremely Rare GeForce RTX 2077 Ti,lys1030,2021-05-08 20:27:01,23,14,0.71
270,Metro exodus PC enhanced edition looks like CGI compared to the base game,aiden041,2021-05-08 17:45:17,2902,439,0.95
274,3090 OC vision build,Terpberto,2021-05-08 12:01:05,19,14,0.61
275,My new EK 360 AIO looks great ❤️ one day I’ll build a custom loop,KingKato2014,2021-05-08 08:54:24,80,17,0.84
277,Diablo Rojo -- This is my Photoshop workstation. It's pretty mean lookin with the dark glass in place.,WaveAtElliot,2021-05-08 05:34:35,0,14,0.25
279,"Ladies, how was my braid?",Baozzer,2021-05-08 03:00:39,3,10,0.54
280,"I always tell myself ""no more upgrades"" but I seem to have selective hearing",aBurntToast69,2021-05-08 01:24:53,19,5,0.67
281,I went from 54L to 9.5L. 5600X + 3070 FormD T1 Build.,Fidler_2K,2021-05-07 23:50:58,41,8,0.81
282,Finally got the GPU i wanted | 2070 to PNY 3070 to 3080 FE,LewAshby309,2021-05-07 23:24:39,1,16,0.52
286,Decided to paint my 3080 white!,FinalFortune_,2021-05-07 19:20:27,86,46,0.86
289,GeForce & Radeon Ultrawide & 4K Gaming Performance Roundup,apoppin,2021-05-07 18:55:30,17,0,0.82
290,I will now be using portrait mode only when taking pics on my pc,Arun_HTD,2021-05-07 17:59:52,0,12,0.5
291,First all white build!,fr5ctal,2021-05-07 16:19:03,4460,208,0.96
293,Just finished my first non prebuilt pc (still waiting for braided cables),Perlern,2021-05-07 15:51:45,23,14,0.73
295,Dream build finally complete - RTX 3080 FE × Ryzen 7 5800x,durhammmer,2021-05-07 13:27:39,130,30,0.88
297,Marbles RTX Now Available To Play In NVIDIA Omniverse!,FiddleFun647,2021-05-07 05:39:00,586,95,0.98
299,Fiscal Report: The Nintendo Switch has now sold 84.5 Million Units Worldwide,BarKnight,2021-05-06 22:27:40,8,10,0.67
302,Kingpin Hydro Copper Notify direct link,brenden77,2021-05-06 15:48:49,5,6,0.73
303,Metro Exodus PC Enhanced Edition with RTX | Available Now!,AidThisFellowUser,2021-05-06 15:09:20,421,64,0.96
304,"Rust: NVIDIA Reflex Gives Players A Free Upgrade, Reducing System Latency By Up To 38%",Nestledrink,2021-05-06 13:18:27,127,21,0.93
305,Metro Exodus PC Enhanced Edition with NVIDIA DLSS 2.0,Nestledrink,2021-05-06 13:18:06,485,209,0.97
306,Metro Exodus PC Enhanced Edition Out Now With Improved Ray Tracing And DLSS 2.0,Nestledrink,2021-05-06 13:17:27,350,211,0.98
309,Mass Effect Legendary Edition For Budget Gamers Have A Sigh Of Relief,Setsunai04,2021-05-06 05:25:58,111,37,0.9
315,Is RTX a COMPLETE Waste of Money?,Significant_Value_27,2021-05-05 17:26:04,0,52,0.38
316,[Jarrod'sTech] HP Omen 15 (Ryzen 7 5800H/RTX 3070) Tested In Games!,InvincibleBird,2021-05-05 16:14:52,2,0,1.0
326,"[Gamers Nexus] NVIDIA & AMD Won't Like This: GPU Price Creep, Greed, and Generational Stagnation",ryandtw,2021-05-05 08:13:32,1623,606,0.97
331,"The Mystery Of Nvidia's ""GT 1010"" - Does It Actually Exist?",hi9580,2021-05-04 23:13:52,7,4,0.68
332,Gigabyte RTX 3060 Eagle 12G [LANOC],apoppin,2021-05-04 23:08:38,2,1,0.67
335,Gigabyte GeForce RTX 3080 Ti Gaming OC with 12GB memory has been confirmed - VideoCardz.com,ryandtw,2021-05-04 19:15:44,1745,243,0.96
338,"ARM Founder Claims Nvidia Will Compete Unfairly, Fails to Explain Why",St3fem,2021-05-04 13:28:25,70,146,0.74
346,T400/600/1000 Turing Quadros coming soon?,Neo_Whig,2021-05-03 20:21:41,12,11,0.83
349,"NVIDIA GeForce RTX 3080 Ti and RTX 3070 Ti to be announced on May 31st, launching in June - VideoCardz.com",ryandtw,2021-05-03 17:43:39,2174,575,0.95
355,Gigabyte and MSI GeForce RTX 3080 Ti custom cards listed by New Zeland and Australian retailers - VideoCardz.com,ryandtw,2021-05-03 08:57:28,78,71,0.95
356,NVIDIA GeForce RTX 3050 Ti mobile specs confirmed by GPU-Z validation - VideoCardz.com,ryandtw,2021-05-03 08:31:12,35,3,0.94
358,Samsung joins the ranks of laptop manufacturers that have announced the 3050Ti before nVidia.,WubbaTow64,2021-05-03 07:13:29,54,4,0.95
360,"Dusting off the build, thought I'd share with the glass off.",Korucalli,2021-05-02 23:25:05,2062,212,0.96
364,Sunday Morning Dedusting,Kellz1,2021-05-02 10:35:07,2207,163,0.97
365,"I've had my 3080 for 5 months, but only got my CPU last week to make proper use of it.",justo316,2021-05-02 09:51:08,29,16,0.69
368,Build finally complete w/ Strix 3090 OC,uhReckz,2021-05-02 05:08:22,37,18,0.75
370,Asus 3080 tuf oc and 5600x build,bucklekush,2021-05-02 01:23:45,39,41,0.71
373,D4RKHOLD is finally complete with the RTX 3070 HoloBlack,D3VH3AD,2021-05-01 21:00:49,1893,77,0.96
375,Just got a 3080 in new pc! Decided to buy this morning and got lucky!,compoundlearning,2021-05-01 17:03:26,675,132,0.93
379,[PCGH.de] Ray tracing showcase tested: Ampere outclasses Turing and RDNA 2 - a look into the future?,Nestledrink,2021-05-01 13:08:25,48,32,0.87
380,[Guru3D] PCIe Resizable BAR Performance AMD and NVIDIA benchmarks,InvincibleBird,2021-05-01 11:24:25,27,3,0.91
381,"NVIDIA shows off a custom GeForce RTX 3080 ""Overwatch"" graphics card",AidThisFellowUser,2021-05-01 12:37:10,1092,176,0.95
384,10700k + 3070 xc3 + Corsair h115i AIO Cooling *Recent UPDATE*,Careless_Rub_7996,2021-05-01 05:30:38,38,10,0.78
386,The Secret GPU Trade,wickedplayer494,2021-05-01 03:39:25,47,12,0.79
389,My Caselabs Bullet BH8 build that I tried to post earlier in the week.,dmit1989,2021-04-30 23:31:07,42,8,0.81
392,[Phoronix] NVIDIA RTX 30 Series vs. AMD Radeon Linux Gaming Performance For April 2021,InvincibleBird,2021-04-30 18:07:05,8,0,0.7
393,Update from Nvidia regarding the long-standing VR stuttering issue,Yozakgg,2021-04-30 18:06:08,91,33,0.95
394,I made a 3D model of the 3060 Ti Founder's Edition,eashanbhatt,2021-04-30 17:52:50,65,22,0.89
395,"It's strangely beautiful! Modded 2080 Ti Strix, now running stable at 2040Mhz and around 60° celsius!",KobraKay87,2021-04-30 17:00:16,4408,384,0.97
396,"My new workstation, powered by the all-mighty NVIDIA 3090",3DKirkegaard,2021-04-30 17:00:03,100,39,0.83
397,Bitspower reveals Mobius waterblock for GeForce RTX 3090 Founders Edition,AidThisFellowUser,2021-04-30 14:12:56,17,16,0.83
402,COLORFIRE graphics cards return with NVIDIA GPUs and pink colors,AidThisFellowUser,2021-04-30 00:51:39,40,13,0.88
404,"Going to try this Thermal Paste on Gigabyte 3080, anyone who used this? Thoughts?",ondre161,2021-04-29 21:34:44,1452,331,0.95
408,Alphacool announces Eiswolf 2 AIO solution for NVIDIA RTX 3090/3080 series,AidThisFellowUser,2021-04-29 12:30:46,111,68,0.98
409,ZOTAC launches GeForce RTX 3090 ArcticStorm with 16+4 phase power design,AidThisFellowUser,2021-04-29 12:29:07,6,8,0.66
414,linux 3080/3090 users be sure to drop by the nvidia forums and +1 the request to release vram temperatures on Linux,Either-Researcher681,2021-04-29 02:57:55,1450,123,0.97
415,Nvidia and Chengdu Hunters Collab,pleasantchickenlol,2021-04-29 03:09:51,0,2,0.43
418,"[LTT] NVIDIA, this is NOT ok!",InvincibleBird,2021-04-28 17:37:22,0,35,0.39
419,Exclusive: Metro Exodus Enhanced Edition Analysis - The First Triple-A Ray Tracing Game,Fidler_2K,2021-04-28 15:03:32,1033,365,0.98
420,The first RTX 3050ti will be used to power up the upcoming Galaxy Book Odyssey. It will cost $1399 and will be available in August.,RandomlyBroken2,2021-04-28 14:49:17,39,25,0.9
422,[Jarrod'sTech] Lenovo Legion 7 - Crazy Ryzen Gaming Performance! (R9 5900HX & RTX 3080 Mobile 16GB),InvincibleBird,2021-04-28 12:30:51,3,0,0.57
423,NVIDIA GeForce RTX 30 “Lite Hash Rate” series to begin shipping mid May,Dangerman1337,2021-04-28 10:35:44,1444,809,0.98
425,Denon & Marantz Introduce a FREE HDMI Adapter Kit To Solve 4K/120Hz & 8K Incompatibility Issue,wrongotti,2021-04-28 06:20:35,51,33,0.98
427,EVGA's Elite membership could be your best bet to bag an RTX 3080 Ti in the first 24 hours,brenden77,2021-04-27 21:03:58,5,57,0.56
432,Raytracing in Control - 1080p upscaled to 4k via DLSS @ max graphics settings (base campaign spoilers),maruf_sarkar100,2021-04-27 15:21:38,637,189,0.97
434,Swapped an EVGA 1080FTW for a Zotac 3070 Twin Gaming Edge OC.,Morkai,2021-04-27 11:02:53,2,21,0.54
438,Lambda GPU Cloud launches world's first RTX A6000 instances (48 GiB VRAM per GPU),mippie_moe,2021-04-26 18:49:55,242,18,0.98
439,[Optimum Tech] RTX 3080 FE vs ITX ⁠– Round 2!,InvincibleBird,2021-04-26 15:57:19,17,2,0.72
442,[KitGuru] eGPU Scaling Benchmark - RTX 3090 v 3080 v 3070 v 3060 Ti,InvincibleBird,2021-04-26 11:02:25,11,3,0.82
443,"ASUS CMP 40HX mining card tested, allegedy launches at 699 USD - VideoCardz.com",ryandtw,2021-04-26 09:33:34,33,66,0.83
448,Microsoft just fixed the FPS issues people are having.,Kelefane41,2021-04-25 21:07:06,55,33,0.94
450,"Finished the Dark Knight Build. X570 Asus Dark Hero, Asus Rog Strix 3090, Ryzen 5950X",OpportunityNo1834,2021-04-26 00:26:35,33,14,0.69
451,First custom budget build since 1995. The times have changed and so have the prices…Sheesh.,brwnb0mber,2021-04-25 22:14:53,55,66,0.71
455,Was feeling the red look today. Suprim 3090.,Less_Pie_7301,2021-04-25 18:55:40,0,0,0.33
456,"There are many like it, but this one is mine",stilliffex,2021-04-25 17:53:49,14,18,0.61
460,11L 3090FE Stealth Build,deckar01,2021-04-25 15:13:50,3164,178,0.97
461,2021 Build is done! All feedback is greatly appreciated,Gordon_Betto,2021-04-25 15:08:18,812,227,0.92
463,"Papa RTX, Momma RTX, Baby RTX",g00s3y,2021-04-25 12:17:36,202,70,0.81
464,Shield TV homescreen ads might be around the corner - 9to5Google,Hakker9,2021-04-25 09:58:32,17,8,0.9
465,5950x 3090FE - didn’t like my custom cable so I ordered a cable mod extension for my 24 pin connector. Seen too many “snow” builds so opted for a mix color scheme of white black and red. Specs in comments,finbarqs,2021-04-25 07:50:54,0,9,0.36
467,My first build in 8 years!,J_Triple,2021-04-25 08:15:41,126,47,0.87
468,5950x/3090/sff. Just finished my build (specs in comment),Vezrias,2021-04-25 05:57:02,82,44,0.83
469,A100 PCIE Desktop Cooling Solution,snake-robot,2021-04-25 04:52:23,29,26,0.87
470,May i know what is the type and size of this screw?,Ill-Confidence1586,2021-04-25 01:31:13,0,6,0.23
471,Newest Build- 3080 FE & 5600x.,TheTyphone,2021-04-24 23:01:53,59,17,0.78
472,Current build - 5900x / 3080 Vision - Bday present to myself back in January,Kenpachi2k,2021-04-24 21:02:36,1,2,0.52
474,"Legend of the RTX, (rendered on a GTX 1060)",AlexHydron,2021-04-24 22:28:11,4975,116,0.99
475,"Now by the rules on the weekend. 3080 FE, 5900X and a 3D printed Fan shroud to make 3 Fans fit in the front. Still without custom GPU cable though",J4Y-R4R,2021-04-24 22:14:38,0,2,0.27
476,My 3090 SLi Setup.,AriasFco,2021-04-24 20:41:08,45,40,0.76
478,Nvidia 2070 I just built,bmoneyo,2021-04-24 20:09:36,17,7,0.67
479,"Inventory sucks, so I've gotten into maintaining and repairing my friends' older GPUs.",StarlightSharpshot,2021-04-24 17:48:33,2469,151,0.97
482,Another 3080 FE thermal pad success story,earlscruggs,2021-04-24 16:35:43,8,21,0.68
483,Microsoft issues emergency fix for gaming performance issues in Windows 10,WPHero,2021-04-24 13:51:48,229,159,0.98
484,Current build - 5800X - RTX3080FE. Pleased with the result excuse my bad photography the fans are actually white.,SiphaSi,2021-04-24 12:03:48,160,42,0.89
485,Chernobylite Enables DLSS with the newest patch,Evonos,2021-04-24 11:21:14,44,20,0.97
487,Steam :: AMID EVIL :: RTX Beta Update,Beylerbey,2021-04-24 09:03:54,33,9,0.89
488,"An all black build (because everyone is posting white builds) with a RTX 3090 Aorus Xtreme. Took me forever to get all the parts, almost finished now.",Replica90_,2021-04-24 04:33:07,27,15,0.72
490,"Don’t see many (3080) Gundam builds around here, hopefully you enjoy with my bad NYC apartment lighting!",Biopanda_,2021-04-24 01:18:20,83,34,0.79
491,Who remembers the Voodoo series?,NeverwinterRNO,2021-04-24 01:01:38,3147,391,0.98
494,Even more cliché 'all white' build (3090 strix and ryzen 5900x),ApolloPS2,2021-04-23 21:20:47,557,99,0.91
496,Nvidia doesn’t want GeForce Now to make the same mistakes as Google Stadia,AidThisFellowUser,2021-04-23 21:12:06,56,25,0.93
497,College student created AI artists - miragegallery.ai,AugustFR,2021-04-23 20:36:35,14,0,0.79
498,Replaced the thermal pads & paste on my 3090FE,Dizman7,2021-04-23 20:33:05,38,35,0.89
499,Finally completed my goal. Im finished (yeah right),Ashen_Heart,2021-04-23 20:26:28,51,16,0.77
500,Blue & Purple 3080 Gaming OC Build,fall0utshelter,2021-04-23 19:13:52,13,1,0.66
502,MSI GeForce RTX 3080 Ti Ventus 3X OC listed by Polish retailer,AidThisFellowUser,2021-04-23 18:10:48,18,6,0.86
503,Cliché 'all white' build,Z06Chris,2021-04-23 15:39:35,98,21,0.8
504,Build is getting closer to finished,daegan666,2021-04-23 15:33:14,0,2,0.28
505,First build! Managed to upgrade from 3070 Vision to 3080 Strix.... still occasional airflow issues though 😸,acidwashed501s,2021-04-23 14:48:27,0,9,0.39
506,My new gaming PC😊,jolue234,2021-04-23 12:59:16,23,5,0.65
507,My Simple Build: i9 11th gen and 3080,herotz33,2021-04-23 12:25:41,111,64,0.81
508,"NVIDIA GeForce RTX 3080 Ti allegedly launches May 25th, RTX 3070 Ti early June",AidThisFellowUser,2021-04-23 12:21:29,247,258,0.98
510,The months wait dream pc - i9 10th gen direct die + 3080 strix oc!,Yuuga_na,2021-04-23 07:01:39,2914,198,0.97
513,NVIDIA Crushes Latest Artificial Intelligence Benchmarking Tests,PulitzerPrice,2021-04-22 22:23:27,15,0,0.84
514,NVIDIA staff suggests rolling back Windows 10 update to fix game issues,WPHero,2021-04-22 23:13:58,109,107,0.94
516,I made a LEGO RTX 3060 Ti. Details in comments.,emailsforaccsaredumb,2021-04-22 17:12:23,3591,120,0.97
517,NVIDIA GeForce RTX 3080 Ti's GA102-225 GPU pictured and specifications leaked - VideoCardz.com,ryandtw,2021-04-22 16:12:43,118,159,0.96
520,"Working and content creation with a notebook? In terms of Max-Q design, the GeForce RTX 3080 clearly beats the RTX 2080 Super! | igor´sLAB",InvincibleBird,2021-04-22 10:17:58,2,5,0.6
522,"Call of Duty: Warzone And Modern Warfare - NVIDIA DLSS Available Now, Accelerating Performance By Up To 70%",Nestledrink,2021-04-22 04:03:09,1302,535,0.99
525,Nvidia wants to put an AI in charge of in-game haptics,AidThisFellowUser,2021-04-21 22:49:42,1017,75,0.98
526,NVIDIA Dominates A Near-Empty Field In AI Benchmarks Again,PulitzerPrice,2021-04-21 19:57:49,8,4,0.84
528,GeForce 466.11 Driver Performance Analysis – Using Ampere and Turing,thestigmata,2021-04-21 18:42:44,67,60,0.9
529,Does anyone know if it’s possible to use this Adafruit MotorHat with a Jetson Nano? I’ve been looking everywhere and haven’t been able to get a definitive answer,Hasheeem,2021-04-21 17:46:15,11,3,0.79
540,[ETA PRIME] Is The Shield Still Usable In 2021? The Original Android Emulation Handheld!,InvincibleBird,2021-04-20 15:25:40,14,5,0.75
545,Palit 3090 Gamerock waterblock now available from French shop,ailveen,2021-04-20 09:16:28,5,1,0.78
546,LENOVO confirms GeForce RTX 3050 Ti and RTX 3050 Laptop GPUs TGP and clocks - VideoCardz.com,InvincibleBird,2021-04-20 08:17:01,38,14,0.91
549,"Nvidia has released the new tech Demo ""Attic"", developed in Unreal engine 4, featuring multiple RT effects and DLSS.",b3rdm4n,2021-04-20 01:38:46,1200,286,0.98
551,Nvidia And The U.K. Government: A Very Public Negotiation?,PulitzerPrice,2021-04-19 19:12:52,3,11,0.64
556,ASUS TUF Dash F15 laptop with GeForce RTX 3050 graphics listed by Amazon - VideoCardz.com,InvincibleBird,2021-04-19 14:51:47,24,2,0.92
559,Proposed acquisition of ARM Limited by NVIDIA Corporation: public interest intervention,holzi226,2021-04-19 12:56:13,111,119,0.93
560,NVIDIA CEO is confident the company will complete ARM acquisition in 2022,AidThisFellowUser,2021-04-19 12:19:14,239,86,0.97
567,Introducing NVIDIA DGX Station A100,hi9580,2021-04-19 06:29:38,5,4,0.7
569,EK Quantum Vector D-RGB RTX 3080 FE. Finally done.....,WRKBYDOM,2021-04-19 01:23:14,3046,175,0.96
571,My Nvidia ASUS TUF OC 3080 PC. I recently added another 16GB of RAM.,MidnightXCortana,2021-04-18 21:13:01,17,20,0.62
572,3090 FE / 3700X / Cougar QBX -- The Mondrian von Gonk,QuietlyDisruptive,2021-04-18 20:52:28,74,73,0.79
573,[Phoronix] LuxCoreRender 2.5 OptiX Performance Tested With 19 NVIDIA GPUs,InvincibleBird,2021-04-18 18:01:17,6,0,1.0
575,ASUS CMP 30HX mining card features ARGB lighting,AidThisFellowUser,2021-04-18 19:43:38,10,22,0.71
578,Unreal Engine 4 RTX showcase demo available for download.,artins90,2021-04-18 17:35:41,56,9,0.93
579,"When you make workstation with gaming GPU. Tnx NVIDIA, and tnx for driver support for CAD inside gaming drivers!",LionOfEmonia,2021-04-18 17:23:39,8,11,0.65
583,EVGA RTX 3080 FTW Ultra,GS-441524,2021-04-18 08:01:00,3159,105,0.97
585,Almost exactly one year after I bought the cpu/mobo I finally have the gpu upgrade to go along with it to replace my 1080ti!,Dizman7,2021-04-18 05:37:57,347,117,0.89
586,i9 10900F + RTX 3070,LordAzir,2021-04-18 04:35:57,79,6,0.83
588,First build complete!,Chad_Jon,2021-04-18 01:25:22,313,47,0.92
590,Warzone will reportedly get NVIDIA DLSS support with Season 3,AidThisFellowUser,2021-04-17 20:36:45,67,69,0.98
595,Finish my build!!!! Finally,Noobzero21,2021-04-17 17:38:20,68,24,0.79
596,3090/3950x after years of saving finally did it,Odashi,2021-04-17 17:34:09,2482,128,0.97
599,"2 x 8 pin power cable combs 3d printed. (If you use 3 8 pins, just use your motherboard's 24 pin combs)",smee665,2021-04-17 16:00:36,6,1,0.62
600,[HUB] How to Waste Money: Fastest Radeon vs. Fastest GeForce Graphics Card,InvincibleBird,2021-04-17 14:30:30,0,11,0.29
601,"3700x, 32gb 3666mhz, 3090 FE.",zypr3xa,2021-04-17 15:39:28,16,6,0.67
602,"A video on our latest Advanced Projects: ""Duality""",BIILT,2021-04-17 15:08:21,5,1,0.62
604,3090 FE + Ryzen 5600X,FalseChance,2021-04-17 13:14:07,2701,266,0.97
605,"NVIDIA removes ""code 43"" on their Geforce drivers so you can install your GPU in a Virtual Machine",studiox_swe,2021-04-17 13:07:42,82,20,0.98
606,Rate the build waiting on my cables from cablemod specs are a 2080ti oc strix from asus and a ryzen 9 3900,CremeOk7882,2021-04-17 12:57:52,3,8,0.55
610,Asus Z370 Beta Drivers for Resizable Bar are out,tomoki_here,2021-04-17 05:24:33,4,6,0.75
611,3070 founders + ryzen 7 3700x,KillerPro0404,2021-04-17 04:04:03,159,20,0.88
613,3080/ i7 9700k Build Complete(it's never complete),lllSquarelll,2021-04-17 00:36:03,2713,232,0.96
614,Naked MSI 3070 Ventus x3 :),sykonet,2021-04-16 22:46:10,16,14,0.77
619,Pretty happy with how the new build has turned out! Benchmarks were 💪🏻💪🏻💪🏻,Bbentley1986,2021-04-16 17:29:00,3,0,0.58
620,An Engine of Innovation: Sony Levels Up for the AI Era,Nestledrink,2021-04-16 16:50:37,1,0,0.67
625,"Create 3D Models from Images! AI and Game Development, Design... GANverse3D & NVIDIA Omniverse",OnlyProggingForFun,2021-04-16 15:40:43,9,11,1.0
627,ModMesh cables finally arrived and added some stickers to the back of the fans. RTX 3090 Aorus Xtreme,Replica90_,2021-04-16 14:42:46,26,19,0.81
631,"Igor's Lab: GeForce RTX 3080 Ti will get a new chip with pre-installed hash brake shortly before launch, the card is already in mass production.",sips_white_monster,2021-04-16 13:34:39,130,185,0.97
633,"[Jarrod'sTech] Lenovo L340 Still Worth It In 2021, or Time to Upgrade? (i5-9300H & GTX 1650)",InvincibleBird,2021-04-16 12:23:17,2,0,0.63
634,Plus And NVIDIA Deal Gives Indications Of Our Autonomous Truck Future,PulitzerPrice,2021-04-16 13:22:15,5,1,1.0
636,Cryptocurrency mining has started eroding graphics card warranties in some territories,caj1986,2021-04-16 12:51:23,124,94,0.96
640,"TSMC claims that they are ‘unlikely’ to meet demand for semiconductors until 2023, GPU availability will be impacted.",Smolders1,2021-04-16 11:41:40,2166,528,0.99
641,t1tan rtx,sexman510,2021-04-16 11:37:00,67,26,0.82
645,"i now have two teslas, am i hot?",Berfs1,2021-04-16 00:11:36,2039,103,0.97
648,[Phoronix] NVIDIA GeForce RTX 30 Series OpenCL / CUDA / OptiX Compute + Rendering Benchmarks,InvincibleBird,2021-04-15 19:53:16,5,0,0.79
658,MSI discontinuing 3080/3090 Trio X's and replacing it with the Trio Z with metal backplate (RIP previous backorders),Rbk_3,2021-04-15 15:32:57,1910,511,0.98
660,"For Arm-Driven Supercomputing, Nvidia is Right on Time",Nestledrink,2021-04-15 15:07:27,12,1,0.85
662,MSI launches GeForce RTX 3080 Sea Hawk X - VideoCardz.com,InvincibleBird,2021-04-15 10:55:15,0,12,0.47
664,/r/nvidia hit 800k subscribers yesterday,TrendingBot,2021-04-15 08:24:53,0,2,0.44
666,Is the Empire striking back? NVIDIA with new chip (GA106-302) and hardware ID against miners and beta drivers!,playthissong2541,2021-04-15 07:07:38,79,86,0.85
670,What's new in GeForce Experience 3.22.0,lawliet89,2021-04-15 01:41:49,26,24,0.89
673,NVIDIA Broadcast Noise Reduction Now Built-In To OBS,windscribe101,2021-04-14 23:55:40,106,28,0.97
678,NVIDIA A30 Data Center GPU Launched *Cheers in FP64*,trivialgroup,2021-04-14 21:56:46,6,0,0.8
681,LIFE: Lighting Invariant Flow Estimation (NVIDIA),AR_MR_XR,2021-04-14 21:14:13,128,1,0.99
682,Lambda GPU Benchmark Center for Machine Learning,mippie_moe,2021-04-14 20:56:19,142,14,0.98
683,OBS gets native support for Nvidia’s excellent noise-canceling tech,STEcelibate,2021-04-14 20:17:50,204,42,0.97
688,NVIDIA's Auto Business Takes Front Seat At NVIDIA GTC 2021,PulitzerPrice,2021-04-14 15:10:12,7,0,0.89
692,MSI 3080 Gaming X Trio Is Apparently Being Discontinued,TeddyVoid,2021-04-14 14:44:44,52,86,0.96
698,Redshift 3.0.43. RTX ON faster x2.8 times! - RS Principled Hair render test on 2x2080ti+NVLink.,artofcharly,2021-04-14 10:04:45,118,6,0.94
699,Gigabyte offically launches its CMP 30HX mining card - VideoCardz.com,ryandtw,2021-04-14 09:26:14,0,8,0.43
713,GTC21 fireside chat with NVIDIA CEO Jensen Huang and Adobe CTO Abhay Parasnis: A Shared Vision for the Future of AI. Join them at 1:00 p.m. PDT,Nestledrink,2021-04-13 19:34:41,2,0,0.6
716,NVIDIA Making Science Fiction Real,PulitzerPrice,2021-04-13 17:22:01,10,5,0.78
724,Nvidia expects GPU shortage to continue for much of this year,caj1986,2021-04-13 13:54:59,3184,731,0.98
728,"[HUB] Nvidia Resizable BAR Tested, As Good as AMD SAM?",InvincibleBird,2021-04-13 11:24:40,31,17,0.77
735,NVIDIA Announces Technology For Training Giant Artificial Intelligence Models,PulitzerPrice,2021-04-13 01:13:18,6,0,0.81
736,Nvidia mugs and bottle openers,Dry_Plant,2021-04-12 23:49:35,6,7,0.67
739,NVIDIA is Now OpenCL 3.0 Conformant | NVIDIA Developer Blog,Nestledrink,2021-04-12 22:25:16,27,3,0.92
742,Nvidia VRSS2 now works with eye tracking,maceandshield,2021-04-12 19:29:17,17,1,1.0
748,NVIDIA (NVDA) Says Q1 Revenue Tracking Above Outlook,Nestledrink,2021-04-12 18:22:57,17,3,0.91
749,Checking out one of the world’s first NVIDIA DGX Station A100s,Nestledrink,2021-04-12 18:07:17,0,3,0.5
751,Volvo Cars to Leverage NVIDIA DRIVE Orin | NVIDIA Blog,Nestledrink,2021-04-12 17:38:52,11,0,0.8
752,NVIDIA Brings Powerful Virtualization Performance with NVIDIA A10 and A16 | NVIDIA Blog,Nestledrink,2021-04-12 17:38:23,1,0,0.57
753,Mozilla partners with NVIDIA to democratize and diversify voice technology – The Mozilla Blog,TheEvilSkely,2021-04-12 17:31:23,79,2,0.9
754,Nvidia announces BlueField-3 DPUs for AI and analytics workloads,Sorin61,2021-04-12 16:24:52,13,0,0.93
755,"Engadget: ""NVIDIA and MediaTek want to bring RTX graphics to ARM laptops""",Dakhil,2021-04-12 17:01:36,8,0,0.83
756,"NVIDIA and Partners Collaborate on Arm Computing for Cloud, HPC, Edge, PC",Nestledrink,2021-04-12 16:50:21,18,0,0.82
757,"Swiss National Supercomputing Centre, Hewlett Packard Enterprise and NVIDIA Announce World’s Most Powerful AI-Capable Supercomputer",Nestledrink,2021-04-12 16:49:58,14,0,0.81
758,"NVIDIA releases its CPU, GPU and DPU datacenter 2020-2025 roadmap - VideoCardz.com",Dangerman1337,2021-04-12 16:43:54,129,45,0.96
763,[Jarrod'sTech] MSI GP76 Game Testing & Overclocking! (i7-10750H & RTX 3070 Mobile),InvincibleBird,2021-04-12 13:14:40,9,1,0.8
766,NVIDIA Atlan SoC with Grace-Next CPU and Ampere-Next GPU pictured - VideoCardz.com,ryandtw,2021-04-12 08:21:01,36,9,0.91
769,Powered by a 3090 Strix,Jafs44,2021-04-12 03:19:48,0,2,0.45
772,"Meet Salamence: Ryzen 9 5900X, EVGA 3080 FTW3, ROG Dark Hero, 64GB DDR4-3200",JtheNinja,2021-04-11 21:38:26,6,10,0.6
773,My First GPU. Found this going through the garage. Will look interesting up against a 7 series card one day,ebaake,2021-04-11 21:16:46,3364,268,0.98
774,Build finally complete!,stessmer12,2021-04-11 21:11:43,20,8,0.8
775,Unicorns do exist! Getting ready to install the stunning RTX 3080 FE in a zero-RGB build for a new client,TinyLittleTechShop,2021-04-11 20:03:26,0,4,0.37
776,[Level1Linux] Code 43? No More! NVIDIA Finally Blesses VFIO!? (ft. Threadripper Pro),InvincibleBird,2021-04-11 19:28:32,8,0,0.7
785,Any idea who the AIB manufacturer for this card is?,varunbehera,2021-04-11 15:38:07,708,64,0.97
791,5900X and 3090 FE 2021 liquid cooling update,tetchip,2021-04-11 14:02:20,0,3,0.46
792,Playing around with some lighting effects in iCue.,sheldoncooper0707,2021-04-11 12:28:09,0,8,0.5
793,Started with a iBuyPower PC now my own gaming PC is finally done.,RichCh1gga,2021-04-11 12:18:11,22,9,0.67
796,A true legend. 1080 ti strix OC 11Gb,Scarchance,2021-04-11 11:25:13,212,45,0.91
797,Zotac Trinity Thermal Pad Replacement,TSChuan92,2021-04-11 10:56:02,17,24,0.78
803,Removed the front panel to take a shot of my white build. Maybe will add some custom art in the future but for now it's all done.,sheldoncooper0707,2021-04-11 02:34:07,112,38,0.84
804,"RYZEN 9 5950X, ROG STRIX RTX 3090, 32GB DDR4 3200MHz Vengeance Pro.",sheldoncooper0707,2021-04-11 01:55:20,2500,379,0.96
807,"Had to wait 5 months for a custom 12pin to arrive, but the rig’s now done",Wyvxst,2021-04-10 21:06:00,246,57,0.9
808,3090 5800x Tridentz 64gb 3800mhz,Wirerat,2021-04-10 18:28:14,0,6,0.47
809,Set it and forget it watercoolish build.,Tomnician,2021-04-10 19:14:04,10,15,0.59
811,"Finally on Ryzen. 5800x, 3080, 3600 CL16",rickyschiano,2021-04-10 19:29:03,34,19,0.75
812,Switched to team green with a fresh build!,dgunns,2021-04-10 17:38:31,2,4,0.54
813,Can't believe i finished the project i started in 2019! Specs and my thoughts in the comment.,soZehh,2021-04-10 16:47:50,8,24,0.58
814,3090 Strix: Teardown & Pad Mod (-15°C),lies_about_flossing,2021-04-10 17:06:16,13,30,0.66
820,"Its happened.... It's finally happened guys/gals! MSRP 3090 FE. I wasn't even remotely interested in the 3090 but with prices and availability of 3080s, I said that if I could score one at MSRP I'd entertain the idea. Even picked it up early.",JermSwift,2021-04-10 13:11:48,143,95,0.83
823,11900K / STRIX 3080 OC / 3600MHz CL14,PovGRide742,2021-04-10 11:44:59,4069,588,0.94
824,First Build Complete!,DonNeedsHelp,2021-04-10 10:04:16,0,0,0.5
825,vgpu_unlock: Unlock vGPU functionality for consumer grade GPUs,enhki,2021-04-10 08:03:15,53,24,0.92
829,Sleek high airflow RTX 3080/ Ryzen 5900x build,epicloler,2021-04-10 03:21:06,15,36,0.64
836,hidden-treasure,Nestledrink,2021-04-09 16:58:50,45,19,0.85
837,Z390 GeForce Resizable BAR Performance Analysis,apoppin,2021-04-09 16:58:45,128,32,0.98
838,NVIDIA GTC 2021 Has A Scavenger Hunt - Hidden Message Decoded,Nestledrink,2021-04-09 16:26:56,51,20,0.92
840,[Phoronix] X.Org Server Git Lands Support For Hardware-Accelerated XWayland With NVIDIA,InvincibleBird,2021-04-09 15:51:22,31,0,0.89
841,My wife surprised me for my bday!,sakooma,2021-04-09 15:41:49,1175,178,0.94
843,[ServeTheHome] 4x NVIDIA A100 and 2x AMD EPYC 7763 in an ASUS RS720A-E11-RS24U Review,InvincibleBird,2021-04-09 11:02:23,7,3,0.74
845,NVIDIA G-SYNC vs. AMD FreeSync vs. V-Sync? We measure the system latency! | Practice | igor´sLAB,InvincibleBird,2021-04-09 07:43:21,92,45,0.93
856,NVIDIA Reflex + Overwatch,Careless_Rub_7996,2021-04-08 19:01:14,26,23,0.75
860,NVIDIA DLSS Now Available In Naraka: Bladepoint,Nestledrink,2021-04-08 18:10:27,90,31,0.91
861,"[HUB] Radeon RX 6700 XT vs GeForce RTX 3070, 45 Game Benchmark 1080p, 1440p & 4K",InvincibleBird,2021-04-08 11:02:09,19,26,0.77
863,Asus z370/z390 ReBAR BIOS expected late April to early May,eugene20,2021-04-08 13:14:30,91,58,0.96
866,"GFN Thursday: Outriders, Narita Boy and More This Month | NVIDIA Blog",apoppin,2021-04-08 13:42:22,7,1,0.82
873,Took Apart an Old HP Desktop and Found This,wtfHeated,2021-04-08 00:29:46,1494,87,0.98
876,Final Results: 3090 FE Post-Thermal Pad and Post-Repaste Mod,Sentinel_1116,2021-04-07 22:46:36,26,47,0.84
879,Pre-Thermal Pad and Pre-Repaste Mod 3090 FE: Under Load and Idle,Sentinel_1116,2021-04-07 17:58:39,1077,282,0.96
884,"Dieter Fox ""The Next Generation Of Robotics And Machine Learning""",meldiwin,2021-04-06 22:01:51,6,1,0.67
886,Lost to time: The deleted Nvidia FPS Benchmark that used WebGL for GeForce Series 6 cards,glen77777,2021-04-06 21:41:03,20,18,0.92
889,NVIDIA GTC 2021 - April 12-16,_A_S_D_F_G_H_J_K_L_,2021-04-06 19:08:54,39,39,0.94
891,MSI announces MEG and MAG desktops with Intel 11th Gen Core CPUs and NVIDIA RTX 30 graphics - VideoCardz.com,InvincibleBird,2021-04-06 09:32:32,7,1,0.71
894,You can now turn on Nvidia's excellent noise cancellation with any GeForce GPU,danielboos2,2021-04-06 12:33:04,2253,302,0.98
895,"3090 thermal pad replacement video recap, I forgot I recorded the results before the mod so here's the before and after",ZANTHERA,2021-04-06 12:29:53,247,72,0.95
896,3090 XC3 i was finally able to snag one but I've read these are slower than 450w 3080s?? Playing on 4k@120hz lg48cx so I want the fastest 4k card for best experience. What do you think? Any xc3 owners out there?,W1zard0fW0z,2021-04-06 12:26:41,0,52,0.46
904,"I did the 3090 FE thermal pad mod and it went very well, near 30 degree drop for the memory and even some gains on the core with Arctic MX-5",ZANTHERA,2021-04-05 18:11:16,2303,407,0.99
908,DLSS VR 'Into the Radius' Performance Benchmarked,Right_Use4206,2021-04-05 13:16:50,50,17,0.94
913,IceBox Build🥶,TAAYZEE,2021-04-05 05:37:29,2961,163,0.97
918,Blue and purple 💜. Ryzen 5950X and Asus 3090,OpportunityNo1834,2021-04-04 21:17:49,33,34,0.79
921,Took forever to get the 3080.,Cerebral-Zero,2021-04-04 21:00:55,0,11,0.49
924,Evga x Asus = BEASTMODE,OkSureWTVuSay,2021-04-04 20:55:52,81,22,0.83
926,"Initial build and boot up! I chose not to go with a hardline setup as I had invested (and had) so many fittings from my original builds laying around still. I am still waiting for some additional Lian Li SL120 fans to replace the 4x Scythe Gentle Typhoons, and 1x for the rear exhaust of the case.",veloster6ix,2021-04-04 17:43:31,1,6,0.52
929,3090 + EBWB quantum vector SE. Beautiful.,dazzlaa,2021-04-04 17:08:09,101,13,0.88
930,EVGA GeForce RTX 3080 FTW3 + Intel i7-11700KF,Perseverance___,2021-04-04 16:07:46,7,0,0.59
932,Hong Kong authorities foil smuggling attempt of 300 NVIDIA CMP 30HX mining cards,sips_white_monster,2021-04-04 12:24:24,176,62,0.97
933,"The Myth, the legend, Finally got my hands on the fabled 3090 FE",amroviper,2021-04-04 09:46:44,4848,422,0.94
939,GeForce 465.89 Driver Performance Analysis – Using Ampere and Turing,Nestledrink,2021-04-04 03:39:08,77,19,0.95
940,Build is Finally complete after many months of looking!,Drewsstruggle,2021-04-04 01:34:13,9,4,0.64
942,Nvidia's RTX 3070 Out-Sold Every Other GPU in March of 2021,AidThisFellowUser,2021-04-04 01:06:46,106,87,0.93
945,Strix Z590E-Gaming Wifi/ i9-10850K/Strix 3070 OC,NefariousScintilla,2021-04-03 23:41:19,13,14,0.66
946,"My Build Featuring an Asus Tuf RTX 3070, AMD 5600x, Lian Li O11 Mini, Custom Sensor Panel and PSU cables.",sprint_9,2021-04-03 22:59:50,50,18,0.8
947,Finally build complete...,JD_1981,2021-04-03 22:44:57,0,6,0.24
950,Red-Gold going strong since Dec2020!,devilindetails666,2021-04-03 20:14:01,0,2,0.21
958,NVDA YOLO. The re-up. Seemed like a good week to jump back in after losing my ass last time around. In Jensen Huang we trust,smellyfussy_parts,2021-05-21 19:18:52,30,43,0.78
959,"Nvidia sets 4-for-1 stock split, shares rise",gtaguy1234,2021-05-21 14:52:32,303,121,0.93
977,Earnings: Chipmaker Nvidia On A Tear,The-Techie,2021-05-27 14:18:08,1,0,1.0
979,"Markets: Nvidia To Split Stock 4-To-1, Shares Rise",The-Techie,2021-05-23 06:57:58,1,0,1.0
983,Stock Market Game Plan (Actionable) 2021 Part 1 $COIN $RIOT $MARA $CAN actionable and key levels Part 2 Review of today $TSLA $LABU $SOXL Part 3 Stocks that are or will be added to the Newsletter $NVDA etc,Aretetrading_Twitter,2021-04-15 23:23:57,2,0,1.0
984,Stock market Review and Plan (actionable) 2021 All in alphabetical order entry and exits points and why we are going to rip 🚀 $BNTX $NVDA $TSLA several more $UPST entry walk through,Aretetrading_Twitter,2021-04-14 00:19:50,3,5,0.81
985,Nvidia’s Stock Isn’t Likely To Return To Its Highs Anytime Soon,garzakage,2021-03-10 19:27:13,3,1,1.0
987,Nvidia’s Integration Dreams,Beren-,2020-09-15 19:04:47,58,10,0.94
991,Is it time to cash out? $nvda,BachirDD,2021-05-24 22:48:49,76,92,0.92
996,"Nvidia sets 4-for-1 stock split, shares rise",gtaguy1234,2021-05-21 14:52:05,127,25,0.97
1,"I’m thinking about getting an rtx 3080 laptop. But I’ve seen videos about it being very bad compared to the desktop 3080. How much better, or worse then a 3070 is it?

What performance should I expect?",speedequalsw33d,2021-05-29 22:53:16,0,3,0.5
2,Has anyone in the UK been to the actual scan store in Bolton and bought a 3070 or any 30 series card there?,TheGaffer10,2021-05-29 22:32:40,2,4,1.0
6,I plan to buy a Thinkpad P51 with this GPU mainly for video editing and occasionally light gaming too. I say light because it's a mobile game on Bluestacks and my PC handles it well but I've heard that the M1200 is bad for gaming so I don't know if it can handle the game in real use.,Tswki,2021-05-29 16:00:38,3,2,1.0
9,"I've an HP OEM RTX2080Ti and I've replaced the blower style cooler for an aftermarket one. I'm now considering flashing a new VBIOS onto it for higher boost clocks and a lower fan speed - any pointers for a good VBIOS that'll work on this, assumedly OEM card?",cietdoke22,2021-05-29 15:07:45,1,2,1.0
13,"Hi all! I would like to know if there are any scheduled improvements for NVIDIA Control Pannel? For example:

1. Graphic restyling of the NVCP 

2. Proper undervolting / overclocking tool, for GPU core and VRAM

3. Proper fan control",GrumpyCalabi314,2021-05-29 12:55:29,3,25,0.8
15,"Hey,

so I basically have the opportunity to switch my GTX 1660S to a GTX 1080 for free. Though I'm not sure if it's worth it. I know that most benchmarks show that the 1080 has obviously more power, though are there any drawbacks?",EinWildesPanda,2021-05-29 11:56:46,10,10,0.82
19,"I planned to replace all the pads on my Strix 3090 and bought a selection of Thermalright Odyssey 12w/mk pads in the 0.5mm, 1mm, 1.5mm and 2mm sizes. 

I have Noctua NH-1, Kryonaut and even CLU to re-tim the GPU die.

I also bought some NVME Heatsinks and 2x 80mm Noctua fans to cool the backplate.

Ready to Rock!

Then several times in the last few days I’ve seen people say that the Strix 3090 has the best stock pads out of all AIB cards and they don't need to be replaced.

Now I don't know what to think or do.

Would I be risking the warranty on an uber expensive GPU for little to no gain?

Should I forget about replacing the pads and just do the warranty maintaining backplate Heatsink and fan mods??",ca1ibos,2021-05-28 18:55:15,2,16,0.75
20,Going with a 9900K and 64GB of 3000MHz DDR4 RAM,Misodent,2021-05-28 18:49:40,0,35,0.35
22,"I am currently on an old gaming laptop (asus G75vw) with a GTX 660m 3G, but have purchased all of the parts for a new PC with the primary reason being video editing and general office work.

While I wait for a newer card would I notice a substantial difference in performance if I get something like a GTX 1050 2gb ($100) or a GTX 960 4gb ($170) compared to my current 660?",butte3,2021-05-28 17:16:22,4,9,0.84
23,Managed to get a 3090 FE. I’ve heard of the temp issues with stock pads so wondering what the best brand model and config mm is for the front and back. I’ve searched past posts but info varies and it’s not the latest information.,Prador,2021-05-28 17:16:04,2,18,0.63
25,"Hi all,

I read the blurbesters gsync guide but can't say I understood all of it and have some Q's. My setup is an i9-9900 (non-k) + RTX3080 +  Samsung U28E590D (4k 60Hz). I mostly play pubg so I prefer higher fps and lower input lag over tear-free visuals.

If I understand correctly gsync effectively aligns frames while reducing input lag, but I need your help to understand:

1) what will gsync give me i'm getting consistent 59-60FPS with vsync off (which is slightly annoying but not sure i would want to lose 3 fps just to get rid of vsync)?

2) does gsync basically replace vsync but with less input lag?

3) basically trying to understand if there is any benefit with my current screen or if it will be more effective (and less noticeable fps drop) if i upgrade to a 120+ hz screen?

4) If I upgrade to a new screen is full gsync needed or is gsync compatible enough?

Thanks!",raistandmuadib,2021-05-28 15:04:02,2,24,1.0
26,"Hello, fellow redditors.

Following the same format of my regular Early Performance Benchmark Driver threads, I've decided to run a few quick tests of the latest Windows 10 21H1 OS update on my Asus 1070Ti GPU, and compare them with the results I got using the previous Win10 OS revision (20H2).

I haven't been offered yet the update via the regular Windows Update system (as usual, Microsoft is deploying the 21H1 update on ""waves""), so I've used Microsft Media Creation Tool to install the new release. After 21H1 was installed, I wiped clean the drivers using DDU and installed the same 466.47 drivers again from scratch, just to be sure that nothing got messed up with the update.

As usual, the benchmark PC specs are: custom built desktop running Win10 v21H1 (latest non-optional Windows Updates applied), 16Gb DDR3-1600 Ram, Intel i7-4790k, Asus Strix GTX 1070Ti Adv. Binned, single BenQ 1080p 60hz. monitor with no HDR nor G-Sync. Stock clocks on both CPU and GPU. Hardware Accelerated GPU Scheduling (HAGS for short) is enabled.

Frame Times are recorded using PresentMon (except on TD2 which does it by itself) during the built-in benchmark run inside each game. Each benchmark is run initially four times, and the first result is discarded. Outliers results, with more than 5% variance in any of my used metrics from the average, are also discarded and repeated.

Unless explicitly stated otherwise, games run 1080p borderless windowed, best settings as possible while trying to hover above 60 FPS, but all available 'cinematic' options disabled when available, (like Motion Blur, Chromatic Aberration, Film Grain, Vignette effects, Depth of Field, and such, not due to performance but for my own preference and image quality reasons).

The usual disclaimer: This is NOT an exhaustive benchmark, just some quick numbers and my own subjective impressions. Also, I can only judge for my own custom PC configuration. Any other hardware setup, different nVidia architecture, OS version, different settings... may (and will) give you different results.

&nbsp;

**Important:** Frames per Second (FPS) are better the *higher* they are, and they usually show the ""overall"" performance of the game. Frame Times (measured in milliseconds) are better the *lower* they are; in particular, lower Frame Time percentiles tell us how much GPU time is needed to render the slowest and more complex frames, with bigger values meaning slowdowns, potential stutters and puntual lag spikes for a less smooth gameplay. _I'm now including also the percentage differences in the latest driver vs. the previous one (with the sign '+' denoting an improvement, and '-' meaning worse result)._

*******

## Tom Clancy's: The Division 2 WoNY
Using updated Snowdrop Engine with Dx12. High/Ultra settings (except Volumetric Fog set to medium).

The Division 2 - driver 466.47 on W10 v20H2:

* Avg. FPS: 87.54 / 86.67 / 87.26

* Frametimes: Avg. 11.47 - Low 1% 15.27 - Low 0.1% 18.10

The Division 2 - driver 466.47 on W10 v21H1:

* Avg. FPS: 85.74 / 85.76 / 85.41

* Frametimes: Avg. 11.68 _(-1.80%)_ - Low 1% 15.17  _(+0.66%)_ - Low 0.1% 17.93 _(+0.95%)_

While the average framerate on The Division 2 is slightly worse, the difference is quite small, and what's more important, the lower frametime percentiles are in fact a bit better now. So, even if the game is slightly slower overall, there are now less potential stutters and lag spikes, while the framerate is kept a bit more stable.

********

## Ghost Recon: Wildlands
Using the AnvilNext 2 engine on Dx11. Mostly V.High but no Gameworks options enabled.

GR: Wildlands - driver 466.47 on W10 v20H2:

* Avg FPS: 85.12 / 84.32 / 84.99

* Frametimes: Avg. 11.79 - Low 1% 15.73 - Low 0.1% 18.62

GR: Wildlands - driver 466.47 on W10 v21H1:

* Avg FPS: 84.01 / 83.96 / 84.70

* Frametimes: Avg. 11.87 _(-0.67%)_ - Low 1% 15.51 _(+1.42%)_ - Low 0.1% 18.66 _(-0.21%)_

Ghost Recon Wildlands behaves similarly to The Division 2. Average framerate is a hair slower, the lower 1% frametime percentile is a bit better, while the lower 0.1% frametime percentile is almost the same. In all, some numbers go up, some down, but changes are small enough to not be of concern.

********

## FarCry 5
A Dunia Engine Dx11 game (a heavily modified fork of the original CryEngine). Maxed Ultra settings with TAA and FoV 90.

FarCry 5 - driver 466.47 on W10 v20H2:

* Avg FPS: 91.41 / 90.15 / 90.68

* Frametimes: Avg. 11.02 - Low 1% 14.77 - Low 0.1% 16.23

FarCry 5 - driver 466.47 on W10 v21H1:

* Avg FPS: 91.75 / 89.40 / 90.99

* Frametimes: Avg. 11.03 _(-0.09%)_ - Low 1% 14.73 _(+0.27%)_ - Low 0.1% 16.40 _(-1.03%)_

FarCry 5 is pretty stable between both Windows revisions. Almost no changes in average framerate and in the lower 1% percentile: the lower 0.1% is a bit worse, but difference is just small enough that it may be very well just testing noise.

*******

## World of Tanks Encore RT
A dedicated benchmark tool for the new Dx11 game engine developed by Wargaming internally for their World of Tanks game, including hardware-agnostic Raytraced shadows. Config is set up to Ultra setting, with Raytracing enabled at Ultra too.

WoT - driver 466.47 on W10 v20H2:

* Avg FPS: 103.73 / 103.98 / 103.93

* Frametimes: Avg. 9.63 - Low 1% 15.02 - Low 0.1% 16.02

WoT - driver 466.47 on W10 v21H1:

* Avg FPS: 102.26 / 102.54 / 102.74

* Frametimes: Avg. 9.75 _(-1.23%)_ - Low 1% 15.22 _(-1.31%)_ - Low 0.1% 16.31 _(-1.77%)_

WOT is the first game in which we get a consistent result... in a bad way. All metrics are slightly worse here. Nothing big, but every single number is now lower than before. :(

*******

## Forza Horizon 4
A Dx12 game from Microsoft, using the propietary Forzatech engine. All quality options maxed, but Motion blur disabled, and just 4x Antialiasing.

FH4 - driver 466.47 on W10 v20H2:

* Avg FPS: 97.92 / 98.10 / 98.20

* Frametimes: Avg. 10.20 - Low 1% 13.16 - Low 0.1% 15.17

FH4 - driver 466.47 on W10 v21H1:

* Avg FPS: 96.08 / 95.66 / 96.21

* Frametimes: Avg. 10.42 _(-2.11%)_ - Low 1% 13.58 _(-3.09%)_ - Low 0.1% 15.46 _(-1.87%)_ 

Forza Horizon 4 gets also a small hit in performance like WoT on all metrics. This is usually the most stable game of my testing suite between nVidia drivers, so it's surprising that just the OS change make such a difference in FH4.

*******

## Bonus Track: Assassin's Creed Odyssey
A Dx11 game from Ubisoft, using the same AnvilNext 2 Engine of Wildlands, but with a slightly newer version. Quality options are High preset, except for AA and Volumetric Clouds set to Medium.

AC:O - driver 466.47 on W10 v20H2:

* Avg FPS: 62.10 / 64.93 / 62.84

* Frametimes: Avg. 15.81 - Low 1% 23.82 - Low 0.1% 28.39

AC:O - driver 466.47 on W10 v21H1:

* Avg FPS: 60.68 / 62.90 / 62.61

* Frametimes: Avg. 16.12 _(-1.92%)_ - Low 1% 25.16 _(-5.32%)_ - Low 0.1% 29.98 _(-5.30%)_ 

And this is the reason why I don't like the Assassins Creed games for Benchmarking. Even between runs of the same betch with exactly the same setup and the same drivers and OS version, the built-in benchmark give results with an enormous amount of variance. I had to take *5* full runs on each batch just to get 3 of them within the same values. The other runs had one of more metrics varying more than 5% of the other averages in that same batch.

Given this, I honestly don't know if the results here are significative or not. The trend is clearly downwards, but I cannot be sure if that's because of the OS change, or it is just because the embedded benchmark awful variance.

*******
&nbsp;

**System stability testing with the new OS Version**

My list of usually tested games (besides the ones benchmarked above) are running fine with the new OS revision: FarCry: New Dawn, Anno 2205, Anno 1800, BattleTech, Diablo 3, StarCraft2, World of Warcraft (both Retail and Classic), Marvel's Avengers, Elite:Dangerous Horizons, AC: Odyssey, Horizon Zero Dawn and Mass Effect Legendary Edition (short testing game sessions). All ran fine without crashing or obvious glitches on my setup.

&nbsp;

**OS 21H1 performance testing results on a Pascal GPU**

Out of the 5 tested games, 6 if we count AC:Odyssey, we have three technical draws (TD2, Wildlands and FC5) and two clear losses (WoT Encore and FH4), plus big losses too on AC:Odyssey, if we ignore the fact that its benchmark seems awfully designed and gives so much variance between otherwise identical runs.

Ironically, for my 1070Ti card the game with the biggest loss in performance due to the Windows 10 upgrade is Microsoft's own game, Forza Horizon 4; which is surprising given that this game is usually the most stable of the ones I use for testing my Pascal 1070Ti GPU.

Given that Microsoft newest OS update is not a big deal, if you have a Pascal 10XX GPU and a similar setup to mine I'd not be in a hurry to update. If you already got it installed, then you might see slightly lower performance on some games, but nothing major. 

The OS update itself only contais a few changes here and there, the new awful ""News and Weather"" widget in the Task Bar, and as far as I know nothing else besides a few under the hood optimizations. Unfortunately, it seems none of those under the hood optimizations improve the gaming experience under Windows 10.

In the end, I guess the W10 21H2 feature update later this year will be much more exciting. It includes a crapload of changes and new features, and a new Windows Driver Model (WDDM v2.8 if I recall it correctly), which will surely impact performance in a much bigger way (for better or worse).

&nbsp;

Last but not least, remember this benchmark is done with a Pascal 1070Ti GPU. Cards with a different architecture (be it newer or older) may show wildly different results. 

&nbsp;

Thank you for reading!",lokkenjp,2021-05-28 14:57:39,36,21,0.85
29,Did anyone score a Graphic card in today's sale ?,Affectionate_Code_37,2021-05-28 13:44:21,5,4,0.86
30,I've got a single fan 1080ti card the fan needs replacing? It no longer spins- So I'm assuming the fan needs replaced?,Gator6618,2021-05-28 13:32:51,2,1,1.0
32,"Hi! i'm trying to compile opencv with cuda and cudnn and i'm getting this when running cmake 

https://preview.redd.it/lrfgxw91eu171.png?width=823&format=png&auto=webp&s=39fdb506c40664e8b0e40f521650dc39555e63a9

The configuration output says cuDNN: NO. 

I've found this solution [https://forums.developer.nvidia.com/t/cudnn-8-0-of-jp4-4p-recognized-under-7-5-version-by-opencv4-2-and-4-3/128167](https://forums.developer.nvidia.com/t/cudnn-8-0-of-jp4-4p-recognized-under-7-5-version-by-opencv4-2-and-4-3/128167) but i'm not sure how to implement it. any ideas? thank you!",FluffertonTheSoft,2021-05-28 10:57:22,1,2,1.0
34,Hey is it possible to encrypt the SD card which is running the OS from my Jetson nano? Or something similar like just flash a ubuntu 18.04 LTS?,7s4cv6K,2021-05-28 05:25:24,7,3,0.9
42,"Hi All,

This is a very frustrating post to write but it's a very important one to do especially as we're approaching another [keynote and rumored launch event in just a few days](https://new.reddit.com/r/nvidia/comments/nljbcj/nvidia_geforce_event_may_31st_10pm_pacific_time/). 

We've recently noticed that the level of quality in a certain threads have been taking a nosedive for several months now. I get it, things are tough. You're frustrated because stock situation hasn't really improved since launch. You want a GPU but you can't get it. It's frustrating. Unfortunately, everyone in the industry is facing the same problems. The world is facing chip shortage right now due to varying reasons and the prevalent of cryptocurrency mining certainly does not help.

That said, constantly complaining, memeing, and making shitty (sometimes inappropriate) jokes about cards not being in stock in every product related threads doesn't really solve anything nor does it drive any relevant discussion. Think of this subreddit as your own community park. Hopefully, you'll try to at least keep it clean and not vandalize it for the sake of everyone using this place. 

There are times where discussion about cards being out of stock is appropriate. [Here's an example](https://new.reddit.com/r/nvidia/comments/nm5rdy/nvidia_expects_rtx_30series_supply_shortages_to/). However, even within these sort of threads, please try to keep the discussion at reasonable level and not just mere complaining (e.g. ""it will be OOS anyway""). 

Having said all that, here are some of the steps we're doing:

* For the next several months, we'll be monitoring all our threads for the quality level of discussion. If the discussion quality level can be improved by simply removing unrelated comments, we will do so. Otherwise, the thread will be locked either temporarily or permanently. 
* Individuals who are bringing down our community's level of discussion will not be welcomed here.

Here are some of the steps you can do:

* If you are still looking for cards, join stock tracking discords or other means that can alert you when things are in stock. This applies to most electronics released in the last year or so. CPU, GPU, Game consoles, etc etc. 
* Our Discord community has some channels for people to discuss GPU stocks. [Here's the invite link](https://discord.gg/nvidia)
* If you see low quality comments, please report them to us via report button

Please reach out via modmail if you have any questions.

Thanks",Nestledrink,2021-05-27 16:46:06,0,0,0.5
43,"My razer blade 15 base 2018 model was giving me a BSOD while updating the NVIDIA Drivers. I was told to try to reflash the VBios by a friend and then was given the wrong file to flash. Now my GPU doesn’t show up, can’t be updated through GeForce experience, and I cannot find the original vbios file anywhere. If anyone has a link to download this cards default vbios or if anyone can backup their vbios and send it to me that would be great. My gpu is stuck as Microsoft basic display adapter in the device manager.",CJNXCII,2021-05-27 13:27:18,1,1,1.0
44,"Hey guys,

&#x200B;

I've been looking at graphics cards which of course come in many different shapes and sizes but one thing that I don't understand is what does the ""slots"" mean in how many slots a graphics card is? Like the ASUS ROG Strix GeForce RTX 3090 OC Edition for example is 2.9 slots according to it's [specification's page](https://rog.asus.com/us/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx3090-o24g-gaming-model/spec). What slot's is the 2.9 slots of the card taking up? Also, does a slot have an official size as in let's say 1 slot = (L) x (W) x (H)?",Aceolus,2021-05-27 13:11:58,1,8,0.67
45,"I finally did the thermal pads mod and here are my experiences. I read a ton of posts and I combined all the best resources into this post.

I wasn't planning on doing this, but my 3080 seems to have been even worse than others. It would simply crash within half an hour of playing any game in 4k, sometimes even within 10 minutes. VRAM temperatures were around 103'C, a few degrees lower for slightly older games (but never below 95'C). The only way I could play anything at all was by opening the case and pointing a big ass fan directly at the GPU. VRAM temps dropped to around 92'C then, but the noise was excruciating.

After doing the mod and stress testing for half an hour, VRAM temps hit 88'C at maximum with the average of 77'C. It's amazing to say the least and it didn't crash once.

# Gelid Extreme pads

These seem to be the best, but the price has nearly doubled lately. I bought two 80x40mm packs - 2mm thickness for the front and 3mm for the back. It was barely enough and I used a ruler to cut the exact sizes (check the guide further down).

# Tools

I can't stress this enough - get a good set of small bit drivers. Some of the screws are very small and soft. I was extra careful, but it still felt like the smaller screws wouldn't survive another round of opening.

Apart from that, you'll also need a good thermal paste (I used Noctua NT-H1), a sharp hobby knife, cutting pad and some rubbing alcohol/wipes.

# Disassembly guide

The best one by far is [this one from Optimum Tech](https://www.youtube.com/watch?v=CrSGpzEMNec). Follow his instructions until 3:40 once he starts doing the water cooling thing, that's no longer relevant.

When putting everything back together, I used duct tape to keep the three cables out of way. Be very careful though and don't twist them too much.

# Padding guides

[Front side cutting guide](https://i.imgur.com/9nShJxc.jpg).

[Back side cutting guide](https://i.imgur.com/2TsPW5d.jpg).

Before beginning, I scaled the above photos so that the size on screen was the same as the actual card. This makes cutting the pads much easier, just measure on the screen and cut. I wouldn't recommend scissors as it's too easy to squish the pad.

Since I was cutting the pads to exact sizes, I had a bit left over from the front (2mm). I used these on the back side, otherwise I don't think it's possible to cover everything as shown in the guide by using a single pack of 3mm pads.

As mentioned before, I used 2mm pads on the front and 3mm pads on the back. The cutting guide uses different thickness, but from my experience, the 2/3mm pads don't seem to be too thick. I had no trouble at all putting the plates back on. You have to get a bit creative with the angled shape on the back side, but it's doable.

I didn't bother saving or re-using the original pads. After constant crashing for the past few months, I really don't care about warranty issues any more, I just wanted to be done with it.

For reference, [here's my back side](https://imgur.com/a/7SFeURH) and [the front side](https://imgur.com/a/eE5ki9j).

# Slow down

It took me about 4 hours from start to finish. I double checked everything just to be sure and I worked really slow. There's no room for being impatient here, so set aside enough time.

**Triple check** that you've removed all of the protective plastic from the pads. It's easy to miss them. They also get static and stick to your skin, so be careful that they don't fall back into the GPU somewhere.

# Fan curves

I've seen it mentioned that it's a good idea to do custom fan curves after doing this mod. ~~Unfortunately, I don't know enough about that to offer anything useful here. I'll update this section if/when I find a good explanation and how to actually do it.~~

/u/fartingdoor was kind enough to send me  [this video guide on doing fan curves.](https://www.youtube.com/watch?v=9eIITS_H0oA)

# Final thoughts

Overall, this was actually much easier than I expected. Sure, you're potentially screwing up a very expensive card, but it's literally only a few screws (12 I think) and three cables. If you're slow and careful, anybody can do this.

# Acknowledgements

A special fuck-you goes out to Nvidia for saving half a cent on shitty pads and forcing us to fix their mistake.",hobbyhoarder,2021-05-27 12:45:36,35,32,0.82
46,"Greetings everyone,

&#x200B;

as I'm back on the green side after several years on team red (Switched when the R9 390 was recent) and was able to grab a 3090 (Palit, GamingPro) for myself, I was quite shocked how hot this big boy can get. As many have pointed out, I've decided to swap the Thermal Pads (Went for the Thermalright Odyssey), had some bad experiences with varying Thicknesses (As some informations online are outdated, the Palit Support sent me a recent Diagram showing the thicknesses are around .75 - 1mm) I've finally got it to a point at which I was somewhat okay. (Around 90-96° Celsius). But I still wasn't fine with that. I know, I know.. GDDR6X will get quite hot even with optimal surroundings, but I'm just not comfortable with that.

So I've tinkered alot, got some heatsinks at my Backplate, tried laying some Fans on top of it.. without any good result. Then I've finally decided to give a better case a try, since my NZXT S340 Razer Edition had some years on its back.

&#x200B;

Today my new case - a Lian Li Lancool 2 Mesh came in and I'm super happy about the change. Dropping the Temps of the Memory Junction by about 8-10° Celsius and the card itself is also pretty smooth now.

&#x200B;

So, even tho many of you out there probably got nice cases and a well thought out airflow already, there might be some people like me that just added new components to their old rig and struggling with temps. 

&#x200B;

TLDR:  
\- Got a RTX 3090 Palit GamingPro

  
\- Super Hot (duh)

  
\- Swapped Thermal Pads (Thermalright Odyssey)

  
\- Re-Pasted the Thermal Paste ( Thermal Grizzly - Kryonaut)

  
\- Addes Heatsinks to the Backplate

  
\- Changed my Case from an old NZXT S340 Razer -> Lian Li Lancool 2 Mesh

  
\- Profit

&#x200B;

If you got similar experience, or wanna share your Stories - I'm open for it and gladly listen!",KrydanX,2021-05-27 12:26:05,7,31,0.69
48,"Hello!

I'd like to setup a fanless PC but the most difficult component is the GPU.  
Do you know if there're good fanless Nvidia card? I found a 1650 Palit Kalmx but the product has been discontinued.

Moreover, i'd like a 1660 super equivalent, do you know if there'are branded card or specific heatsink?

Best regards;

Math",mathrddt,2021-05-27 11:13:27,0,11,0.33
50,"Anyone call Nvidia support's phone line and get a message saying it is currently outside their support hours without any information on when those hours are (followed by an immediately hangup)?

Looks like their chat also says they are unavailable. Do they not have an email or some other option than waiting and seeing if their support opens up?",snagglestudy,2021-05-27 09:46:34,1,0,0.67
53,"I've never really been able to figure this out. Are you supposed to switch to YUV420 since that is what movies are used with? Or will a YUV 420 video look fine on a monitor that is set at RGB Full?

In other words, can you watch YUV 420 content in RGB?",ThatFeel_IKnowIt,2021-05-27 00:39:33,2,17,0.75
54,"Ok, i have an AORUS GEFORCE RTX 3090 XTREME WATERFORCE WB, because the thermal pads are so bad on these cards, what size and how much will i need to re-pad the front and back?

is it 2mm on the front and 3mm on the back for Thermalright?",Fi77on,2021-05-26 22:46:54,0,4,0.33
55,"just wondering about this and couldn’t really find an answer. I know about overclocking but is that it, and what kind of difference in performance are we talking about?",JustLearnToPlay,2021-05-26 22:42:31,3,26,0.62
56,"**NVIDIA's Q1 2022 Fiscal period**

# [Earnings Call - May 26th @ 5pm ET / 2pm PT](https://event.on24.com/wcc/r/3082046/BCB1110BDCFBE0E5F66A6714C1B7778A)

# Documents

## [Press Release](https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-first-quarter-fiscal-2022)

## [Revenue Trend](https://s22.q4cdn.com/364334381/files/doc_financials/quarterly_reports/2022/Q122/Rev_by_Mkt_Qtrly_Trend_Q122.pdf)

## [Financial Statements](https://s22.q4cdn.com/364334381/files/doc_financials/quarterly_reports/2022/Q122/Q1FY22-CFO-Commentary.pdf)

## CEO Comments

>“We had a fantastic quarter, with strong demand for our products driving record revenue,” said Jensen Huang, founder and CEO of NVIDIA.  
>  
>“Our Data Center business continues to expand, as the world’s industries take up NVIDIA AI to process computer vision, conversational AI, natural language understanding and recommender systems. NVIDIA RTX has reinvented computer graphics and is driving upgrades across the gaming and design markets. Our partners are launching the largest-ever wave of NVIDIA-powered laptops. Across industries, the adoption of NVIDIA computing platforms is accelerating.  
>  
>“Mellanox, one year in, has exceeded our expectations and transformed NVIDIA into a data-center-scale computing company. We continue to make headway with our planned acquisition of Arm, which will accelerate innovation and growth for the Arm ecosystem. From gaming, cloud computing, AI, robotics, self-driving cars, to genomics and computational biology, NVIDIA continues to do impactful work to invent a better future,” he said.

## Summary

* **Total Revenue** is **$5.661 billion** up 84% YoY and Up 13% QoQ
* **GAAP** Gross Margin is at **64.1%** (down 100 bps YoY and up 100 bps QoQ)
* **Non-GAAP** Gross Margin is at **66.2%** (up 40 bps YoY and up 70 bps QoQ)
* **GAAP** EPS **$3.03** (up 106% YoY and up 31% QoQ)
* **Non-GAAP** EPS **$3.66** (up 103% YoY and up 18% QoQ)

## Revenue by Market

&#x200B;

|**Segment**|**Fiscal Q1 2022**|**Fiscal Q1 2021**|**% YoY Growth**|
|:-|:-|:-|:-|
|Gaming|$2,760M|$1,339M|\+106%|
|Datacenter|$2,048M|$1,141M|\+79%|
|Professional Visualization|$372M|$307M|\+21%|
|Automotive|$154M|$155M|\-1%|
|OEM & IP|$327M|$138M|\+137%|
|**Total**|**$5,661M**|**$3,080M**|**+84%**|

&#x200B;

* Gaming revenue was up 106 percent from a year ago and up 11 percent sequentially, reflecting higher sales in GeForce GPUs, with both desktop and laptop setting records, as well as in game-console SOCs. We continued to benefit from strong sales of our GeForce RTXTM 30 Series based on the NVIDIA Ampere architecture. We believe Gaming also benefited from cryptocurrency mining demand, although it is hard to determine to what extent.
* Data Center revenue was up 79 percent from a year ago and up 8 percent sequentially. The year-on-year revenue growth was driven primarily by the Mellanox acquisition and the ramp of NVIDIA Ampere GPU architecture products into vertical industries and hyperscale customers. Sequentially, growth in Data Center came from both compute and networking products, primarily driven by hyperscale customers.
* Professional Visualization revenue was up 21 percent from both a year earlier and sequentially. The year-onyear increase was driven by record sales of notebook workstation GPUs. The sequential growth reflects sales of GPUs for both desktop and notebook workstations.
* OEM and Other revenue was up 137 percent from a year ago and up 114 percent sequentially, primarily reflecting the addition of Cryptocurrency Mining Processors (CMP), which generated revenue of $155 million.
* NVIDIA paid quarterly cash dividends of $99 million in the first quarter. It will pay its next quarterly cash dividend of $0.16 per share on July 1, 2021, to all shareholders of record on June 10, 2021.
* On May 21, 2021, the company’s board of directors declared a four-for-one split of NVIDIA’s common stock payable in the form of a stock dividend, with the additional shares expected to be distributed on July 19, 2021. The stock dividend is conditioned on obtaining stockholder approval at the company’s 2021 Annual Meeting of Stockholders on June 3, 2021, to increase the number of authorized shares of common stock from 2 billion to 4 billion.

**Recent Highlights**

NVIDIA achieved progress since its previous earnings announcement in these areas:

**Gaming**

* First-quarter revenue was a record $2.76 billion, up 106 percent from a year earlier and up 11 percent from the previous quarter.
* Broadened the wave of laptops powered by NVIDIA’s second-generation RTX graphics with the launch of [GeForce RTX™ 3060 Laptop GPU systems](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-3060-laptops-available-now/) starting at $999, and the announcement of [GeForce® 3050 Ti and 3050 Laptop GPU systems](https://nvidianews.nvidia.com/news/nvidia-transforms-mainstream-laptops-into-gaming-powerhouses-with-geforce-rtx-30-series) starting at $799 and aimed at gamers and creators.
* Accelerated [RTX momentum](https://www.nvidia.com/en-us/geforce/news/april-2021-rtx-dlss-game-update/) with now over 60 games, including [*Call of Duty Modern Warfare*](https://www.nvidia.com/en-us/geforce/news/april-2021-rtx-dlss-game-update/)*,* *Crysis Remastered* and [*Outriders*](https://www.nvidia.com/en-us/geforce/news/outriders-nvidia-dlss-out-now/)*.*
* Took steps to improve gamers’ access to GeForce GPUs by [reducing the Ethereum hash rate on newly manufactured RTX 3080, 3070 and 3060 Ti graphics cards](https://blogs.nvidia.com/blog/2021/05/18/lhr/) \-- which carry a “Lite Hash Rate,” or “LHR,” identifier -- in addition to [previous steps to lower the RTX 3060’s hash rate](https://blogs.nvidia.com/blog/2021/02/18/geforce-cmp/).
* Announced that [NVIDIA DLSS is available now in Unreal Engine 4](https://www.nvidia.com/en-us/geforce/news/february-2021-rtx-dlss-game-update/) and soon in the [Unity game engine](https://www.nvidia.com/en-us/geforce/news/unity-engine-adding-dlss/).
* Announced that [NVIDIA Reflex](https://www.nvidia.com/en-us/geforce/news/april-2021-rtx-dlss-game-update/), which reduces system latency, is now incorporated into *Call of Duty Warzone*, [*Overwatch*](https://www.nvidia.com/en-us/geforce/news/reflex-april-2021-games-mice-monitors-update/) and *Rainbow Six: Siege*.
* Announced that [GeForce NOW™](https://blogs.nvidia.com/blog/2021/03/18/geforce-now-priority/), now in its second year, has over 10 million members in more than 70 countries and is approaching 1,000 games in its library.

**Data Center**

* First-quarter revenue was a record $2.05 billion, up 79 percent from a year earlier and up 8 percent from the previous quarter.
* Hosted its largest-ever [GPU Technology Conference](https://blogs.nvidia.com/blog/2021/04/12/gtc-keynote/), virtually, with more than 200,000 registrations from 195 countries, and an opening keynote with over 14 million views.
* Unveiled [NVIDIA Grace™](https://nvidianews.nvidia.com/news/nvidia-announces-cpu-for-giant-ai-and-high-performance-computing-workloads), its first Arm-based data center CPU, designed for giant-scale AI and high performance computing, which will deliver 10x the performance of today’s fastest servers and power the [world’s most powerful AI-capable supercomputer](https://nvidianews.nvidia.com/news/swiss-national-supercomputing-centre-hewlett-packard-enterprise-and-nvidia-announce-worlds-most-powerful-ai-capable-supercomputer) at the Swiss National Supercomputing Centre.
* Collaborated with Amazon Web Services to deploy [NVIDIA GPU inferencing](https://nvidianews.nvidia.com/news/nvidia-and-partners-collaborate-on-arm-computing-for-cloud-hpc-edge-pc) through GPU-accelerated, AWS Graviton2-based Amazon EC2 instances, enabling GPU-accelerated games to run natively on AWS and allowing greater performance for Arm-based workloads.
* Unveiled the [NVIDIA® BlueField-3® DPU](https://nvidianews.nvidia.com/news/nvidia-extends-data-center-infrastructure-processing-roadmap-with-bluefield-3), the first data processing unit built for AI and accelerated computing, with support from VMware, Splunk, NetApp, Cloudflare and others.
* Announced the [new NVIDIA DGX SuperPOD™](https://nvidianews.nvidia.com/news/nvidia-announces-new-dgx-superpod-the-first-cloud-native-multi-tenant-supercomputer-opening-world-of-ai-to-enterprise), the first cloud-native, multi-tenant supercomputer, with customers in conversational AI, drug discovery, autonomous vehicles and more.
* Announced that its AI inference platform, expanded with [NVIDIA A30 and A10 GPUs](https://nvidianews.nvidia.com/news/nvidia-and-global-computer-makers-launch-industry-standard-enterprise-server-platforms-for-ai) for mainstream servers, set records across every category in the latest release of the MLPerf benchmark for AI performance across a range of workloads.
* [Announced the ](https://nvidianews.nvidia.com/news/nvidia-unveils-ai-enterprise-software-suite-to-help-every-industry-unlock-the-power-of-ai)[NVIDIA AI Enterprise software suite for VMware vSphere](https://nvidianews.nvidia.com/news/nvidia-unveils-ai-enterprise-software-suite-to-help-every-industry-unlock-the-power-of-ai), enabling scale-out, multi-node performance and compatibility for a range of applications and data science.
* Introduced the [NVIDIA Morpheus AI](https://nvidianews.nvidia.com/news/nvidia-launches-morpheus-to-bring-ai-driven-automation-to-cybersecurity-industry) application framework to enable cybersecurity providers to instantly detect cyber breaches using AI and NVIDIA BlueField DPUs.
* Announced availability of [NVIDIA Jarvis](https://nvidianews.nvidia.com/news/nvidia-announces-availability-of-jarvis-interactive-conversational-ai-framework), a framework for interactive conversational AI, and [NVIDIA Maxine™](https://blogs.nvidia.com/blog/2021/04/12/ai-real-time-video-maxine/), a framework for real-time video-based experiences.
* Unveiled [NVIDIA TAO](https://blogs.nvidia.com/blog/2021/04/12/ai-workflow-tao-fleet-command/), a framework for accelerating the creation of enterprise AI applications.
* Expanded its work supporting [drug development and discovery with NVIDIA Clara Discovery](https://nvidianews.nvidia.com/news/nvidia-partners-with-schrodinger-to-further-accelerate-drug-discovery-worldwide), announcing a partnership with Schrödinger to support the pharmaceutical industry with AI software to speed drug-discovery workflows.

**Professional Visualization**

* First-quarter revenue was a record $372 million, up 21 percent both from a year earlier and the previous quarter.
* [Launched NVIDIA Omniverse™ Enterprise](https://nvidianews.nvidia.com/news/nvidia-launches-omniverse-design-collaboration-and-simulation-platform-for-enterprises) software for real-time 3D design and collaboration, with BMW Group, Foster + Partners and WPP as early customers.
* Unveiled [NVIDIA RTX™ GPUs](https://nvidianews.nvidia.com/news/new-nvidia-rtx-gpus-power-next-generation-of-workstations-and-pcs-for-millions-of-artists-designers-engineers-and-virtual-desktop-users) for next-gen laptop and desktop workstations, including the NVIDIA RTX A4000 and A5000 for desktops and the A2000, A3000, A4000 and A5000 for laptops.
* Revealed [GANverse3D](https://blogs.nvidia.com/blog/2021/04/16/gan-research-knight-rider-ai-omniverse/), an AI model for creating 3D object models from standard 2D images.

**Automotive**

* First-quarter revenue was $154 million, down 1 percent from a year earlier and up 6 percent from the previous quarter.
* [Unveiled NVIDIA DRIVE Atlan™](https://nvidianews.nvidia.com/news/nvidia-unveils-nvidia-drive-atlan-an-ai-data-center-on-wheels-fornext-gen-autonomous-vehicles), an AI-enabled processor for autonomous vehicles with 1,000 TOPS and data-center-grade security, targeting automakers’ 2025 vehicles.
* Announced [NVIDIA DRIVE Hyperion™ 8](https://blogs.nvidia.com/blog/2021/04/12/nvidia-hyperion-8-autonomous-vehicle-platform/), the latest generation of a fully operational, open platform that reduces the time and cost to outfit vehicles with AI and surround sensors.
* Announced that [NVIDIA DRIVE™ will be powering intelligent new energy vehicles](https://blogs.nvidia.com/blog/2021/04/12/new-energy-vehicles-power-nvidia-drive/) from SAIC R Auto, IM Motors, Faraday Future and VinFast, starting in 2022.
* Revealed that Cruise is the latest [robotaxi company selecting NVIDIA DRIVE](https://blogs.nvidia.com/blog/2021/04/12/robotaxi-companies-hail-rides-nvidia-drive/), following announcements by Amazon Zoox, DiDi, Oxbotica, Pony.ai and AutoX.
* Announced that [Volvo Cars will use NVIDIA DRIVE Orin™](https://nvidianews.nvidia.com/news/volvo-cars-zoox-saic-and-more-join-growing-range-of-autonomous-vehicle-makers-using-new-nvidia-drive-solutions) to power the autonomous driving computer in its next-generation cars, beginning with the XC90, to be revealed in 2022.
* Announced that the [NVIDIA DRIVE platform](https://blogs.nvidia.com/blog/2021/04/16/mercedes-benz-eqs-hyperscreen/) powers MBUX Hyperscreen, the AI cockpit in Mercedes-Benz’s new EQS sedan.
* Announced that TuSimple and Navistar will build [self-driving trucks powered by the NVIDIA DRIVE AGX™ platform](https://blogs.nvidia.com/blog/2020/08/05/tusimple-navistar-build-autonomous-trucks-nvidia-drive/), and the self-driving truck company [Plus will use NVIDIA DRIVE Orin](https://blogs.nvidia.com/blog/2021/03/09/autonomous-trucking-startup-plus-next-gen-platform-nvidia-drive-orin/) for its upcoming autonomous vehicle platform.

**Q4 Fiscal Year 2021 Outlook**

* Revenue = $6.3 billion (plus minus 2%)
* GAAP Gross Margin = 64.6% (plus minus 50 bps)
* Non-GAAP Gross Margin = 66.5% (plus minus 50 bps)",Nestledrink,2021-05-26 20:51:49,35,50,0.9
57,"I'm having an issue. I upgraded my box (i9-9900k, Gigabyte Aorus Xtreme Z390 mobo) to a 3090 FE.  From a load perspective the PSU should be fine - it's a Seasonic Prime Titanium 750W PSU.  Under heavy load I look at the power draw on my UPS and it's not ever more than 500W for the system (and about 50W for the monitor).

However, recently I've seen the box ""blip"" - there's a click and it reboots. I suspect the PSU - this seems to happen when there are sudden spikes in load.  My main game is Destiny 2, so this is usually in the case of loading in to zone/activity, or if I switch away from the game to a browser and then switch back. 

I've heard other folks talk about similar issues with Seasonic PSUs.  One guy switched to a bequiet 850w PSU and it went away, for example.  So does anyone else have a brand or model of high quality PSU that they're using with a 3090 with no problems?",Meatwad650,2021-05-26 20:21:31,6,53,0.72
58,"I need to add this GPU card to my company's price list for some high-end image processing. Will be installed in customers HP Z6 purchased through us (specs may be available if needed)

But, I found two different Item numbers for NVIDIA RTX6000 24GB:

 5JH80AA and 5JH80AT 

Can anyone in this sub tell me how they differ? Does one of them come with an adapter or other connection type difference?",Tink_Tinkler,2021-05-26 19:41:19,5,2,0.73
59,Title says it all,mgtube,2021-05-26 18:28:49,3,8,1.0
63,"hi, my 1060 laptop died and replaced it with a 3060 laptop, luckily with a 130w variant. i have figured a way to modify my TGP and was wondering which method was better...

there are two approaches,

1. standard is base clock (115) + dynamic boost (15) = 130W

2. disabling dynamic boost to raise base clock to 130W

my understanding is dynamic boost works on available resources between cpu and gpu, while just raising the base clock will use as much power as possible. i'm assuming the 2nd method is preferred, but it being a laptop. i was wondering if maybe dynamic boost is more beneficial due to limitations. my cpu is a i7 10875h with TDP 45W and a 230W power supply.",mc711,2021-05-26 14:33:37,3,9,0.68
64,"Hey guys, my card doesn't run too hot when gaming, but I use it for mining at night and other times when I'm not using it and while mining the memory temps get pretty hot (100+). I've read that there's a pretty easy fix by adding thermal pads and have a couple questions about this process. 


1) is there any way to do it without voiding the warranty?

2) how hard is the mod in general? I'm fairly handy and have built many computers over the years; but never done any kind of hardware mod to a device

3) would particularly like to talk to anyone that has done the mod with my specific GPU (or any with the same PCB layout)


Any other tips or advice is greatly welcome and appreciated! Thank you.",need4speeds,2021-05-26 14:29:20,0,8,0.5
65,"I recently saw that you can automatically overclock your GPU and i was wondering if i am able to do it with my ""NVIDIA GeForce GTX 1660 Ti"". I saw a comment that only series 20 and up can do it that's why i am asking. Thanks.",Antwan691,2021-05-26 11:43:13,4,5,1.0
67,"Alright folks. I've searched everywhere for these measurements and could not find anything definitive. I decided to ask MSI. It was not easy, but I got them: [MSI RTX 3090 Suprim X Thermal Pad Measurements](https://imgur.com/a/kc84a0R).

It took 3 months of going back and forth with MSI. A dozen pages of emails were exchanged. Constant stonewalling and misinformation from MSI's RMA department. Finally, I had to resort to threatening an FTC complaint, to which MSI *finally* responded with the requested information. [Here is a link to my email conversation with MSI.](https://imgur.com/a/ozHghWw) It's equal parts entertaining and frustrating.

Another very important takeaway for MSI RTX 3090 Suprim X owners: during my discussions with MSI, I requested information on the availability of replacement GPUs in the event I sent mine in for RMA. The response I received was that they did not have any of these GPUs available. That's right--**If you send the 3090 Suprim X in for RMA, they do not currently have any to send back as a replacement.** In other words, DO NOT use their RMA process if at all possible, because you may not ever get the replacement you are entitled to. They did not bother to tell me this information in advance; I had to tease it out through numerous emails and questions.

By the time I received the measurements from MSI, I had already replaced the thermal pads using a ruler and a combination of Fujipoly and Thermalright pads. I was very careful and meticulous and achieved, under heavy loads, up to 20 C improvement on the VRAM temps. Luckily, I got everything right on the heatsink side the first time. On the backplate, I had to go back in two additional times to ensure full contact everywhere.

PLEASE NOTE: if you rely on these measurements, please be aware that the measurements (i.e., thicknesses) are not the only variable. The other important variable is density/hardness of the thermal pads. The pads on this GPU are quite soft relative to Fujipoly and Thermalright pads. This means that just because you use a pad with the exact same thickness, it may not compress to the same extent as the OEM pads and your mileage may vary.

EDIT: It's been brought to my attention that another Redditor was able to obtain this information from MSI about a month ago. It seems the main story here is that the individual I was in contact with at MSI (initials TH, you know you who you are), was simply giving me the runaround FOR THREE MONTHS. Who knows, maybe my initial inquiry to MSI back in March was what sparked MSI to develop the information for the other Redditor, so I still deserve all the credit! /s",scarecrawfish,2021-05-26 03:04:19,598,80,0.97
68,Did NVIDIA ever improve on the thermal pads they were installing on these cards? I am seeing no more than 88 degrees on memory junction during superposition. I think the only time I've ever seen over 90 is on FFXIV. I did get mine way later than launch.,jfa100200,2021-05-26 00:27:07,1,16,0.53
69,"Hello lovely community. My previous GPU (GTX 1080) died. I've been looking for a new one and have 2 options:

\- RTX 3070 (ASUS TUF and Strix)

\- RTX 3080 (ASUS TUF)

3080 would cost me $300 more than the 3070 (1k for a 3080 in total).

My current system is this:

10900k 5GHz all core, 4.7GHz cache

16GB 4400MHz memory

850w PSU

VG279QM (1080p, IPS, 280Hz monitor)

I'm no 'pro-gamer' but I truly prefer higher framerates/more fluid motion than higher resolutions. Despite having a 27"" 1080p, which a lot of people would hate or ignore, I just keep a little more distance from the monitor and still enjoy it, the smoothness of high refresh rate and high FPS really kills it for me.

I'm thinking about those 2 GPU's, in theory, the 3080 is 'overkill' since it is intended for 4K. I've heard people saying that at 1080p any CPU would bottleneck the 3080. While I don't have the best CPU, the 10900k still kicks some punch, I hope its mild 5GHz overclock could help with that. I mostly play warzone, e-sports and some AAA games here and there (fps/modded Fallout/sim racing). 

Any thoughts?",ikindalikelatex,2021-05-25 20:19:07,6,32,0.71
70,"Hi, sorry if this is a common question, ive been looking for an RTX 3050/3050 Ti laptop, but i cant seem to find models that include those gpus currently available.

Googling only shows articles from Nvidias reveal a couple of weeks ago that seemed to indicate the laptops where now available, but apart from that i cant find any other information, and out of the laptops listed on Nvidias website the only one thats available is the MSI Pulse GL66 which is a bit out of my price range.

I checked a couple of weeks ago on Amazon and found a preorder for the Gigabyte G5 which indicated that it would release on the 16th of may, but when the day came it wasnt available for purchase.

I also asked a couple of local retailers but i couldnt get a precise date or even confirmation that they would have any.

Are the laptops simply out of stock or have they not been released yet by the manufacturers?",Leoz96,2021-05-25 18:30:00,11,9,0.91
71,"Was able to snag a EVGA GeForce RTX 3080 FTW3 Ultra Gaming 10GB.

Little bit of research seems to indicate that the card has decent thermal pads and compound on the front of the card but lacks anything in the back. I've ordered 3mm Gelid pads for the backplate and some individual copper heatsinks to spread around the VRMs.

Just curious but is replacing the front of the card with Gelid pads and repasting with MX-2. Pretty comfortable taking it apart but not sure about the VRM putty situation.

EDIT:

Did the mod, very easy to take apart the cooler but just be careful with the 4 plugs. For me, was totally worth it, dropped VRAM temps 6c at peak, GPU 3c at peak with 20% drop in fan speed. 

For me, that's a significant improvement.I didn't mess with the putty, just left it as is, seems to be making good contact, and reused the same pads on the VRMs. I don't see how the putty is ""one time use"", it's just much thicker thermal grease.

I also added Alphacool copper heatsinks on the backplate (with the old pads) exactly where the VRAM chips undersides are. I don't know how effective it is but they get scalding hot during load.",FlyPenFly,2021-05-25 17:00:55,0,14,0.36
73,"Hi, I'm switching out my thermal pads on my 3070 FE. To get to the point and avoid ""Why are you doing that its not necessary etc"" lets just say I have to. So now that's out of the way.

What thickness do you guys know of or recommend? I know its also dependent on hardness, but if i'm using something with a hardness of 35-45 is 2mm fine?

Was thinking about getting these:[https://www.amazon.com/gp/product/B08KWLY4LB/ref=ox\_sc\_saved\_title\_4?smid=A18A7ZNFNR8255&psc=1](https://www.amazon.com/gp/product/B08KWLY4LB/ref=ox_sc_saved_title_4?smid=A18A7ZNFNR8255&psc=1)

I've heard mixed opinions that thickness varies per side, but some people use the same thickness throughout.

My logic was that if I get a great quality soft bad I could go with 2mm thickness and be able to have it squish down and make good contact and spread out a little.

My other logic was adding a little more thermal pads when you ope n the outside cover, there's like this tiny piece on the underside and was thinking of extending it out more. I'm not saying i'm going to plaster thermal pads all over but is it bad to use more than what the card used?

Also does conductivity matter, some are 13 some are 17.

&#x200B;

Thanks",SaddamsKnuckles,2021-05-25 16:25:22,0,14,0.4
74,"As the title says, full 3D binaural audio can already be fairly compute-heavy, and I know multipath is an issue with signals in general. Could the RTX cores, combined with Nvidia audio drivers, be used for full 3D audio or is this overkill?",Vaudane,2021-05-25 15:02:15,32,30,0.92
78,"Full Article Here: [https://nvidia.custhelp.com/app/answers/detail/a\_id/5196?linkId=100000046248571](https://nvidia.custhelp.com/app/answers/detail/a_id/5196?linkId=100000046248571)

GeForce Hotfix display driver version 466.55 is based on our latest [Game Ready Driver 466.47](https://www.nvidia.com/en-us/geforce/news/days-gone-geforce-game-ready-driver/).  
The hotfix addresses the following issues:

* \[RTX 20 series\]\[GTX 16/10 series\]\[HDMI\] 4K @ 120Hz display mode is not available from display settings \[3312401\]
* If GPU is connected to a 4K UHD TV, system may freeze when launching a VR game \[3313315\] 

Click the appropriate link to download:  
Windows 10 64-bit Standard Driver - [Click Here](https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Finternational.download.nvidia.com%2FWindows%2F466.55hf%2F466.55-desktop-notebook-win10-64bit-international.hf.exe&data=04%7C01%7CMGuzman%40nvidia.com%7C52a267867e4e4f3c4a0e08d91f118f3a%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C637574982542522254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=MIXL%2FsgjRHalBs%2FHtbPR0jwGabHydH%2FduVjYh2pcPPQ%3D&reserved=0)  
Windows 10 64-bit DCH Driver - [Click Here](https://international.download.nvidia.com/Windows/466.55hf/466.55-desktop-notebook-win10-64bit-international-dch.hf.exe) 

For assistance with choosing between Windows 10 Standard and DCH display driver, please visit the FAQ below:  
[NVIDIA DCH/Standard Display Drivers for Windows 10 FAQ](https://nvidia.custhelp.com/app/answers/detail/a_id/4777/session/L2F2LzEvdGltZS8xNjIxOTA3MTY4L2dlbi8xNjIxOTA3MTY4L3NpZC9mVTk0bTdBVm9CbEVXcEpfaG9fV01vX0s2MF9XeE5wJTdFWGx1R3dwZ3RFeFg0SVlhYVVoNmZsb3lBYmc0R05CaHFhbThDRDREZFNibVFNTnhYSXpqcXBqWk9BbE5kOWxPUzhwZERhTUo5N1U4b25XSlZmV202NzJOdyUyMSUyMQ%3D%3D)",Nestledrink,2021-05-25 01:47:21,39,54,0.87
79,I have a Dell 3090 from R10 Alienware and it has memory overheating temperature and wanted to know if this GPU AIO would fit before buying.,KAPtain1234,2021-05-24 21:28:16,1,11,0.57
80,"I am getting an RTX 3090 FE and was wondering which waterblock to get. I would prefer it have some sort of active backplate cooling, however if the backplate is good then I may stick with that. I have seen people use Bykski but can't find much about the performance and opinions, I am leaning towards the EK Quantum Vector, but can not find any reviews. The bitspower is also in my mind, however I am going to mount the 3090 vertically and I'm worried the VRAM cooler may interfere. Any other suggestions are welcome.",Sir_Bacon_Master,2021-05-24 20:52:45,1,10,0.56
82,"So apparently Dell isn't aware that a VBios is a real thing. I purchased one of their ghetto G5000 system for the 3070 inside. I've been looking for updated firmware for weeks. They created a firmware updater for their 30xx series cards BUT only for their Alienware systems. So it won't update my 3070 they made. I've contacted their support and they have no idea what I am talking about. They told me that they BIOS is for the motherboard LOL. I said I know this, but I need to update the VBios in order to get Resizable BAR support. They literally had no clue what I was talking about. I spoke to several of their ""techs"" and even shared with them their firmware updater for their Alienware builds so they could understand. They had no idea still. I've contacted Nvidia and they keep telling me only Dell can provide the VBios update. I am at a loss. I have no idea where to go. Any help here?",Lunar_Jimmy,2021-05-24 15:28:45,66,63,0.9
83,"[https://imgur.com/a/f3SPPOv](https://imgur.com/a/f3SPPOv)

I decided to test out if installing things on VRAM actually made any difference, and I was shocked to find out that it actually does. I tested it multiple times to make my results more accurate, and with 3DMark installed on my 970 EVO Plus, I got an average GPU score of 11318, and with 3DMark installed on my VRAM, I got an average GPU score of 11384. I should mention, I am running an overclocked EVGA 3090 K|NGP|N. Now the difference you see here is not a gigantic difference, but it has the potential to be a noticeable difference nonetheless. However, the read and write speeds of the 3090 were surprisingly low compared to a normal RAM disk, the RAM disk I used was over twice as fast, with 3600mhz CL13-15-15-15-32 sticks. However, I would imagine that the VRAM disk has potential to be faster than a normal RAM dk if the program uses a lot of VRAM, but I have not tested yet and could be completely wrong.

Here is the link to the tool I used to do this, if anyone is interested, it is really great!

[https://github.com/prsyahmi/GpuRamDrive/releases](https://github.com/prsyahmi/GpuRamDrive/releases)",FutaLoliLoverXOXO,2021-05-24 07:00:38,0,13,0.3
86,"Hi

  
I can't find any information about the RTX 3000 series GPUS inregards to LUT tables?  Is there more than 1?",DuncanIdaho_PDG,2021-05-24 00:29:47,2,14,0.58
88,"Hello everyone !

I use nvidia smi for locking the gpu core and the power limit ( some of my game crash with evga precision X ou msi afterburner so with this way i have no problem ).

But i need some information about these command, can i change the gpu memory value with nvidia smi ? like from 1750mhz to 1800mhz ? or there is a way to use a command for oc memory without using a software ?

i'm sorry about my ugly english.. i'm from belgium and i learn by myself..

have a nice day !",MookaaaSeinsei,2021-05-23 22:44:47,1,6,0.6
89,"Hi, I have a question about a used card I bought a week ago, it games fine, benchmark doesn't crash, temps doesnt spike, the only think that worries me is that when i start a benchmark or video game a red led starts blinking on the gpu and near that led it says 12v, the card is zotac 980 amp omega. does anyone knows what that 12v red led means? cant find any info about that.",Gold_Problem5607,2021-05-23 21:41:33,3,1,0.8
94,"I haven't seen any posts here about this yet. If you have an Asus TUF 3080 (3090 probably applies too), there is one thermal pad I added that lowered my VRAM temperatures 20C. It's on the stickers right next to the GPU die.

[https://imgur.com/a/xi16glY](https://imgur.com/a/xi16glY)

If you carefully remove the stickers and put a 2mm pad on the metal there it looks like it'll transfer the heat from the small passive heatsink for the VRAM to the much larger heatsink with fans blowing through them. The thermal pad is squeezed between this piece of metal and the heatpipes coming out of the GPU cold plate.

I was using my GPU to mine ethereum before the mod at 840MHz core and 8400MHz mem with 100% fans and was averaging around 95C. After the mod if I try the same clocks and fan speed I get on average 82C.

I highly suggest you give this a try if you have thermal pads, its only about 4cm x 1cm and you only have to take off the main heatsink/shroud. You can leave the small heatsink and backplate on for this mod.

In case you want to replace all of the pads as well, check out this comment on a similar post. I did this mod about a month ago and got a 4C improvement. Needs a lot more thermal pads and time [https://www.reddit.com/r/nvidia/comments/ll44s5/asus\_tuf\_3080\_thermal\_pads\_thickness/gnnitma?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/nvidia/comments/ll44s5/asus_tuf_3080_thermal_pads_thickness/gnnitma?utm_source=share&utm_medium=web2x&context=3)",SomePan,2021-05-23 06:44:16,5,8,0.65
97,"Should i get a 850w psu for a 3070?
And is it safe if i use it?",Seismiclawyer14,2021-05-23 04:30:01,3,26,0.64
101,"I've been looking for old cards for machine learning, and the K80 stuck out as it is relatively cheap, around like 3060 prices these days, with 24 gb of Vram, which is a good amount for most machine learning. However, I given that Nvidia isn't supporting it anymore, what would be the successor to the K80 in terms of price, and amount of Vram? The M60 only has 16gb, which can be limiting at times, and I can't find any good alternative.

As for price, I was referring to the price n the used market, so currently, around 300 dollars. I would be willing to spend up to 600 dollars on a older but used GPU with more Vram than the current consumer cards in that range(3070 with only 8 gb, not enough for machine learning).",Stanley_C,2021-05-22 21:49:55,5,11,1.0
108,"Currently, Rx 580 8gbs are selling for up to £420 used on eBay (I paid £165 2 years ago for mine) and with the new LHR versions coming out later this month I want to know whether selling my current GPU for a profit and buying a new card is better, my main issue is that I don't have onboard graphics so I would need the new 3060ti before I could sell my 580. I'm concerned it will devalue due to the release and I won't be able to switch.",doritofeet23,2021-05-22 02:35:37,14,22,0.77
111,"It's not completely finished (still waiting for RGB header for the top fans) but I'm too excited not to share! Specs below: 

CPU - i7 10700K

MOBO - ROG Strix Z490-E

GPU - TUF Gaming RTX 3080 OC

SSD - 1TB Samsung

RAM - 32GB Corsair Vengeance

CASE - Lian Li O11 Dynamic mid sized

&#x200B;

https://preview.redd.it/a5ixku0qkj071.jpg?width=4032&format=pjpg&auto=webp&s=b2769f80b8d190325fc1399ebcd549aa540af4b0",Traditional-One-7659,2021-05-21 21:32:40,11,10,0.68
112,"I recently saw this video from Linus Tech Tips [https://www.youtube.com/watch?v=ToTWaZt](https://www.youtube.com/watch?v=ToTWaZtGOj8)

Which basically tells about how the VRAMs on the back of 3090 runs too hot over 90C

I own a Gaming X Trio 3090 and I am very concerned about the longevity of the graphics card after going through this video.

What I am most awestruck is does this means the super expensive cards like Gaming X Trio and Strix are not good at all because they are not having active backplate cooling.

Can anyone of more knowledge guide me on my concern.",Dr-Xperience,2021-05-21 18:16:08,2,55,0.56
114, I want to increase my GPU wattage to 100w as I have an insane ammount of  headroom after LMing and changing thermal pads. I have tried the RBP  vBIOS from 2019 but I get a GPU mismatch error in NVFlash even after  using the id mismatch mode disabled version and --protectoff.,JHizzleMyNizzle,2021-05-21 15:08:20,1,1,1.0
117,"Hi all,

I've had this card for over 7 months and recently i bought a CPU good enough to pair it with. Have done a lot of testing and below are my results. Some things to note are that i was not necessarily for highest overclock or least voltage. I tried to see how much frequency can be gained in the same voltage envelope and after a lot of testing i settled for the below numbers. I also wanted to make sure the fan was not too noisy as i live in a quiet neighbourhood and sometimes game without audio and hence the fans would be audible. Considering these, one can either set a more aggressive fan curve and get better thermals or choose a more aggressive undervolt.

Lastly, as you all know each card will differ depending on the quality of silicon and the type of cooling associated so your mileage may vary.

&#x200B;

Ambient/Room temperature - 28C (Average)

Case - Cooler Master Haf 912

CPU - 3600xt (Gaming temperature - 62C to 75C) with Deepcool Gammax and NTH1 paste

GPU - Inno3d 2070 Super Twin X2 OC (Dual fans)

All runs with custom fan settings - 60C = 60% fan speed ramping up to 70C = 80% fan speed, 80/90 and 90/100.

Game benchmark - HZD (Epic games version), Ultimate quality and Vsync off, 1440p 144hz panel

GPU driver - 466.27

OS - Win 10 pro 2009

Software used - MSI Afterburner

Background softwares - Epic Games, GOG games, MSI Afterburner, Notepad++

&#x200B;

Default settings

Voltage - Between 1.031 and 1.050v

Starts off at 1935mhz and drops to 1890 stable with increase in temperature

Max temperature - 71c

Max FPS - 133

Average - 77

&#x200B;

Custom profile 1 - Target 1920mhz

Voltage - 925mv

Starts off at 1935mhz and drops to 1920

Max temperature - 67c

Max FPS - 129

Average - 78

&#x200B;

Custom profile 2 - Target 1980mhz

Voltage - 1v

Starts off at 1995 mhz and drops to 1980 and then to 1965 for a few secs after temperature reaches 70C

Max temperature - 71c

Max FPS - 126

Average - 79

&#x200B;

&#x200B;

Custom profile 3 - Target 1950mhz

Voltage - 0.962mV

Starts off at 1965 mhz and drops to 1950 (I use this setting for gaming)

Max temperature - 70c

Max FPS - 136

Average - 78

&#x200B;

&#x200B;

Custom profile 4 - Target 1860mhz

Voltage - 0.875mV

Starts off at 1875 mhz and drops to 1860

Max temperature - 65c

Max FPS - 130

Average - 76

&#x200B;

&#x200B;

Custom profile 5 - Target 2040mhz

Voltage - 1.025mV (I dont believe this voltage is enough for the target frequency, would recommend increasing the voltage by 1 point on Afterburner)

Starts off at 2070 mhz and drops to 2055 and then to 2040 stable

Max temperature - 73c

Max FPS - 133

Average - 80",razeil,2021-05-21 11:24:07,7,3,0.77
118,"I just got mine and noticed the VRam is hitting 92c on temps.  Has anyone replaced the thermal pads on this model?  What size pads do I need?  Is it only on the front side of the PCB, or are there ones on the backplate too?

Thanks!",Kreavan,2021-05-20 21:56:59,2,21,0.58
120,"Do you guys know of any tutorial that could guide me ?

I have taken GPUs apart in the past but since the FTW3 uses thermal puddy I'm not sure what sizes/brands I should pick.

Appreciate any help ! Thanks alot.",GutBeer101,2021-05-20 13:54:58,6,27,0.71
121,"Those of you who have managed to get an RTX 3070, how did you do it? I finally have the money to start seeking for one and I want to know which online stores I should be keeping an eye on for stock

Edit: Thank you for all the informative responses",Jonathan570,2021-05-20 13:42:09,23,139,0.74
123,"some ~2 years ago [i made a post here](https://old.reddit.com/r/nvidia/comments/bzgtwy/what_is_the_new_fullscreen_onoff_flicker_thing/) about this issue, which i unfortunately would only be able to fix a while later after persistent testing.

the reason i'm making this post is that even after the post was locked, i've still had 5 people PM me asking if i managed to get it fixed, which implies it's significant enough that people felt the need to PM someone for help, so i can only imagine the number of people that just gave up on it instead.

so this is supposed to be a public archive of the solution to this problem.

#the reason for the problem:

> it happens when you use some 3D program specific settings in NVCP that differ from the global ones, so every time you alt-tab in/out you are reloading these problematic settings which makes the screen flicker.

>  ---

> i didn't care to make a list of all the problematic settings because i only cared about my personal use-case, so if you have this same problem but you don't use g-sync, you will have to do trial-and-error to figure out which options are screwing you.

> ---

> so in my case the problematic setting was g-sync, but ironically not g-sync per se. when you change g-sync settings per application NVCP will also force change some other 2 unrelated options even though you didn't choose to (you can see what they are when they go **bold** after changing g-sync and before hitting apply), and it's one of those options that cause the flicker on alt-tab.

#the solution:

> in the past i could change the g-sync and then force those other 2 unrelated options back to ""inherited global"" before hitting apply, but at some point driver updates made this no longer possible (thanks NVidia, very cool).

> ---

> i found a workaround to this by changing the 3D-app settings for g-sync from nvidiainspector instead of NVCP, so the only thing i ever change in NVCP are the global settings, doing it like this will, as you expect, not forcefully change those other 2 options.

> ---

> in my case i had g-sync globally on, and to disable in games without flicker i used the nvidiainspector option of ""g-sync application state: forced off"".

> ---

> i actually would rather use g-sync global off and turn it on for specific games, but for whatever reason g-sync would simply not work unless it was on globally, so i had to configure the inverse (thanks again NVidia, very cool).",Railander,2021-05-20 05:46:55,420,79,0.97
124,Are they super bad or just like all the 3080s ?,OpportunityNo1834,2021-05-20 05:34:08,6,35,0.76
125,"Hi gamer/miner here.

I replaced my thermal pads and thermal paste on my 3080 FE and now get about 80C for memory junction temperature when mining eth. It's fantastic. Used 2mm thermalright pads. I know softer pads like 2mm gelids would produce a better result. I suspect the thermalright pads are just slightly hindering my GPU from efficiently contacting the cooling unit.

&#x200B;

My gaming GPU temperatures are 73C when playing COD Warzone. I suspect the GPU temperature should be lower due to better pads and thermal paste. The old paste was crusty.

&#x200B;

If you replaced the pads on 3080FE, what are your GPU gaming temperatures?",GoldenTrout69,2021-05-19 17:36:58,8,22,0.68
126,"Obvisously the chip shortage is very different than previously. I don't think we have a clear sight of what's happening. 

Do you think Toyota could be buying more gpus in the world, as they claim they don't have chip shortage?

That's a huge shift from the just in time paradigm",BananaGhul,2021-05-19 15:26:43,0,24,0.4
128,"There is plenty of ***speculation*** that Jeff Fisher who unveiled the 3060 along with several other key gaming technologies at CES 2021 will also unveil upcoming Tis at Computex on June 1.

[https://www.businesswire.com/news/home/20210518006243/en/NVIDIA-to-Deliver-a-Keynote-on-The-Transformational-Power-of-Accelerated-Computing-at-COMPUTEX-2021-Hybrid](https://www.businesswire.com/news/home/20210518006243/en/NVIDIA-to-Deliver-a-Keynote-on-The-Transformational-Power-of-Accelerated-Computing-at-COMPUTEX-2021-Hybrid)

>Jeff Fisher, Senior Vice President of NVIDIA’s GeForce Business Unit, will present on June 1 at 1:00 pm Taiwan time on the massive opportunities that GeForce PC gaming represents for the Taiwan ecosystem.”  
>  
>Manuvir Das, Head of Enterprise Computing at NVIDIA, will then address “The Coming Democratization of AI.”

More info from Nvidia's blog:

[https://blogs.nvidia.com/blog/2021/05/18/computex-executive-keynote/](https://blogs.nvidia.com/blog/2021/05/18/computex-executive-keynote/)

> NVIDIA’s Jeff Fisher, senior vice president of GeForce gaming products, will discuss how NVIDIA is addressing the explosive growth in worldwide gaming. 

&#x200B;",apoppin,2021-05-19 12:57:12,16,15,0.82
129,"I repasted and repadded my RTX 3080 FE 10 days ago and the memory temps have been great since then.
Went from 110C at 100% whiny fans (in Control at 4K) to low 90s at 50% fan. Temps can be lower than 90C if fan speed is >80% but then you have noise.

The stock thermal pads on the 3080 FE are terrible. Their performance at 27C ambient + AC turned on (thus lowering the ambient to 22-23C) + extra fans below the GPU are equivalent to gelid thermal pads at 32C ambient without AC or extra fans below the GPU for just 10% extra fan speed.

I have my performance data in the table here - https://imgur.com/SKdxudf

Guides I followed - 

1. https://www.youtube.com/watch?v=CrSGpzEMNec - OptimumTech has the easiest to follow guide. Especially on how to deal with the connectors

2. https://www.youtube.com/watch?v=WWhqmP5eE_0 - igor's lab

3. https://www.youtube.com/watch?v=OX9Eh_NaC5c - gamers nexus teardown

Thermal pads needed - 1x 2mm Gelid Extreme for the front. One pad is sufficient if you measure twice and cut once. There is no scope for mistakes with one pad. 1x2mm for the backside IF you do not remove the stock pads. If you want to redo stock pads + add extra pads below memory then you will need 2 of those. I did not go for 3mm because I feel that it would be too tight for the backplate. 2mm fits great and makes excellent contact with the backplate. Though the back side thermal pad mod only helps 2-3C.

Everything you need to know is covered in the 3 youtube videos and here is my experience - 

1. You can SAVE the original thermal pads (for warranty stuff) by letting the card cool down completely before you open it up. Put it in AC if need be. Open it slowly and with consistent pressure. Pads will tear if you put unequal pressure while opening up. Then using a blade/knife pull the ends of the thermal pads up a bit and slide a thread under. Then using the thread separate the pads from the cooler. Do one half from each side. Do not use your hand to pick up the pads. Use a tweezer. Put the pads in a zip-lock bag. I don't know how long they will survive though. Storing them in a cool and dry place and crossing my fingers that I never have to claim warranty. Here are mine - https://imgur.com/a/acIUvIU

2. I installed 2x Arctic P12 PWMs below the GPU even after the thermal pad mod to help with lower temps and fan noise. This may not be necessary for gaming but helps with my machine learning workloads.

3. Do a custom fan curve in MSI Afterburner even after repadding. The stock fan curve does not really pay head to memory temperature till they are out of control. It sticks to 30-40% fans while memory is at 95C

4. I used Gelid Extreme thermal paste to avoid the pump out effect. It's been 10 days since application and temps are holding steady. The included flat nozzle helps with spreading because this paste is a PITA to apply.

5. Be careful with the black fan cables. They are thin and tiny and easy to tear. I had a lot of trouble putting the bottom fan cable back in. You require patience and steady hands. Conversely, I had no trouble with the RGB cables. Watch the optimumtech video to see how to remove that cable.

6. Watch out while putting the metal plate back on. The silver square thing which attaches the GPU to the cooler. It requires force to install and be very careful while installing. One of my screws went flying and took me an hour to find. If you lose these screws you are in for a heap of trouble.

7. Use the correct screw driver bit or you will strip the screws. Not fun to deal with stripped screws. The existing screws are low quality.

8. GPU temps will go up on stock fan curve. More heat is being dumped into the heatsink from memory and also the fan is not ramping up as fast. I saw a 10C temp increase but equalizing for fan speed the GPU temps start lining up with the previous data. That is why I said to do a custom fan curve in #3.

9. Watch the hotspot temps. Ensure that GPU temp and hotspot temp delta is equal after repadding. Otherwise you missed a small piece of thermal pad somewhere around the single modules of memory. For me the delta is a consistent 10-11C.

Here are some more pictures - https://imgur.com/a/J2F4LfG

EDIT - TLDR of the amount of thermal pads needed. 1 pack means the 80mmx40mm of Gelid Extreme Thermal pads (Model number for 2mm is TP-GP01-D)

- 1 pack of 2mm for front if you don't make any mistakes. The pad is exactly enough to do the entire front of the card.

- 1 pack of 2mm for back if you do not remove stock thermal pads and only add new pads around the memory

- 2 packs of 2mm for back if you want to replace stock pads AND add more pads around the memory in the back given - 
 - You cannot remove the ultra thin pad on the back capacitors.

EDIT 2 - /u/falkentyne added some good context around the delta - https://old.reddit.com/r/nvidia/comments/ng4hyt/rtx_3080_fe_repadding_and_repasting_saving_the/gyq3ayq/",fartingdoor,2021-05-19 12:30:14,1127,240,0.97
130,"Ok so, i'm going to buy that monitor VG279QM, and i want to run 1080p HDR at 280hz, is it possible?  
B550M PRO4 with 5800X, 16gb of ram at 4000mhz.",Agile_Ordinary6788,2021-05-19 02:33:17,0,21,0.39
131,"I had opportunity to buy Asus Rog Strix but it went out of stock - was late 1day. 
Which one of following would be the best choice for pc,
Compare ROG STRIX RTX3070:
- ASUS TUF Gaming
- MSI SUPRIM X
- MSI Ventus X

I appreciate help :)",HI_its_Yoshi,2021-05-18 21:57:45,1,24,0.54
133,Is a 2080-ti and a i9-9900 enough for a 360hz monitor?,JamJar1337,2021-05-18 21:10:02,3,45,0.59
134,I’m considering using it to encode movies to save space on my NAS.,crussel7,2021-05-18 20:12:12,14,15,0.86
136,"Hi all,

I have an RTX 3070 and a Benq zowie xl2731 - I have enabled free sync premium in my monitor's settings. The monitor is not supported by Nidia and is listed as 'display is not validated as g-sync compatible' in the Nvidia control panel. 

Should I also force enable g-sync too despite its lack of support or will this cause issues?

Thanks!",nobleflame,2021-05-18 18:10:29,1,7,1.0
138,"Hi all, I finally was able to grab a 3060ti, the ASUS Tuf, off BB. I pick up soon, and want to make sure I take all the correct steps before swapping my cards, so I don’t damage anything or make anything harder on myself. If anyone has input it’d be great!

Also, for anyone who has this card, what is a good overclock setting for this card?",camo2488,2021-05-18 15:04:34,9,22,0.77
139,"Hello.

I installed Nvidia Omniverse to check out Marbles RTX.  


Now that I'm done, I want to remove it all from my PC.  


While I was able to uninstall both Marbles RTX and Nvidia Omniverse,
I can't get rid of the Omniverse System Monitor.

It doesn't show up under ""Uninstall a Program"" or under ""Apps and features"", and the program's folder doesn't have an uninstall.exe



But it keeps booting up in my Windows Tray, and even if I would disable it to boot up with my PC, I still want it completely removed.

What can I do?",SCG_2018,2021-05-18 14:24:37,4,4,1.0
140,"&#x200B;

https://preview.redd.it/uvy00o0w0wz61.png?width=940&format=png&auto=webp&s=174c4f44cb1c2c2cec36d7daf07561e63dfc3c90",xDevi69,2021-05-18 14:18:05,10,33,0.78
142,"Hello guys,

Should I set ignore film grain option value to 0 or 1 to make sure that it fully ignores film grain that some games causes. I've seen that people are confused which value is the fully working one.",BoskoMi,2021-05-18 13:39:09,14,5,0.9
144,"# Game Ready Driver 466.47 has been released.

# New feature and fixes in driver 466.47:

**Game Ready** \- This new Game Ready Driver provides support for the launch of **Days Gone on PC** with increased levels of detail, higher foliage draw distances, native 4K rendering, a configurable field of view, ultra-wide monitor support, unlocked frame rates, and more. Additionally, this release also provides optimal support for **Knockout City**.

**New Features and Other Changes**

* This driver version is required for GeForce RTX 3080, RTX 3070, and RTX 3060 TI graphics cards with LHR, which ship starting late May, 2021.

**Game Ready Driver Fixes** (For full list of fixes please check out release notes)

* \[Tom Clancy's Ghost Recon Breakpoint\]: The game experiences low performance / low frame rate when launched with Bar1 enabled in the SBIOS. \[200721940\]
* \[Starbase\]\[GeForce RTX 20/GTX 16 Series\]: The game may crash. \[3293977\]

**Game Ready Driver Important Open Issues** (For full list of open issues please check out release notes)

* \[NVIDIA Ampere GPU\]: Colors may appear incorrect in games if sharpen Freestyle filter is used with HDR enabled. \[200658208\]
   * **This issue will be resolved in the next NVIDIA driver release**.
* \[HDR\]: Some specific HDMI displays might show some flickering in HDR mode. \[200729987\]
   * If you experiencing flickering issues, reboot the system.
* \[World of Warcraft: Shadowlands\]: Random flicker may occur in certain locations in the game \[3206341\]
* \[Batman Arkham Knight\]: The game crashes when turbulence smoke is enabled. \[3202250\]
* \[Steam VR game\]: Stuttering and lagging occur upon launching a game while any GPU hardware monitoring tool is running in the background. \[3152190\]
* \[YouTube\]: Video playback stutters while scrolling down the YouTube page. \[3129705\]

# Driver Downloads and Tools

Driver Download Page: [Nvidia Download Page](https://www.nvidia.com/Download/Find.aspx?lang=en-us)

Latest Game Ready Driver:  466.47 WHQL

Latest Studio Driver:  462.59 WHQL

DDU Download: [Source 1](https://www.wagnardsoft.com/) or [Source 2](http://www.guru3d.com/files-details/display-driver-uninstaller-download.html)

DDU Guide: [Guide Here](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)

**DDU/WagnardSoft Patreon:** [**Link Here**](https://www.patreon.com/wagnardsoft)

Documentation: [Game Ready Driver 466.47 Release Notes](https://us.download.nvidia.com/Windows/466.47/466.47-win10-win8-win7-release-notes.pdf)

Control Panel User Guide: [Download here](http://us.download.nvidia.com/Windows/466.47/466.47-nvidia-control-panel-quick-start-guide.pdf)

NVIDIA GeForce Driver Forum for 466.47: TBD

**RodroG's Driver Benchmark:** [Link Here](https://babeltechreviews.com/geforce-466-47-driver-performance/)

[r/NVIDIA](https://new.reddit.com/r/NVIDIA/) Discord Driver Feedback for 466.47: [Invite Link Here](https://discord.gg/y3TERmG)

# Having Issues with your driver? Read here!

**Before you start - Make sure you Submit Feedback for your Nvidia Driver Issue**

There is only one real way for any of these problems to get solved, and that’s if the Driver Team at Nvidia knows what those problems are. So in order for them to know what’s going on it would be good for any users who are having problems with the drivers to [Submit Feedback](https://forms.gle/kJ9Bqcaicvjb82SdA) to Nvidia. A guide to the information that is needed to submit feedback can be found [here](http://nvidia.custhelp.com/app/answers/detail/a_id/3141).

**Additionally, if you see someone having the same issue you are having in this thread, reply and mention you are having the same issue. The more people that are affected by a particular bug, the higher the priority that bug will receive from NVIDIA!!**

**Common Troubleshooting Steps**

* If you are having issue installing the driver for GTX 1080/1070/1060 on Windows 10, make sure you are on the latest build for May 2019 Update (Version 1903). If you are on the older version/build (e.g. Version 1507/Build 10240), you need to update your windows. Press Windows Key + R and type winver to check your build version.
* Please visit the following link for [DDU guide](https://goo.gl/JChbVf) which contains full detailed information on how to do Fresh Driver Install.
* If your driver still crashes after DDU reinstall, try going to Go to Nvidia Control Panel -> Managed 3D Settings -> Power Management Mode: Prefer Maximum Performance

If it still crashes, we have a few other troubleshooting steps but this is fairly involved and you should not do it if you do not feel comfortable. Proceed below at your own risk:

* A lot of driver crashing is caused by Windows TDR issue. There is a huge post on GeForce forum about this [here](https://forums.geforce.com/default/topic/413110/the-nvlddmkm-error-what-is-it-an-fyi-for-those-seeing-this-issue/). This post dated back to 2009 (Thanks Microsoft) and it can affect both Nvidia and AMD cards.
* Unfortunately this issue can be caused by many different things so it’s difficult to pin down. However, editing the [windows registry](https://www.reddit.com/r/battlefield_4/comments/1xzzn4/tdrdelay_10_fixed_my_crashes_since_last_patch/) might solve the problem.
* Additionally, there is also a tool made by Wagnard (maker of DDU) that can be used to change this TDR value. [Download here](http://www.wagnardmobile.com/Tdr%20Manipulator/Tdr%20Manipulator%20v1.1.zip). Note that I have not personally tested this tool.

If you are still having issue at this point, visit [GeForce Forum for support](https://forums.geforce.com/default/board/33/geforce-drivers/) or contact your manufacturer for RMA.

**Common Questions**

* **Is it safe to upgrade to <insert driver version here>?** *Fact of the matter is that the result will differ person by person due to different configurations. The only way to know is to try it yourself. My rule of thumb is to wait a few days. If there’s no confirmed widespread issue, I would try the new driver.*

**Bear in mind that people who have no issues tend to not post on Reddit or forums. Unless there is significant coverage about specific driver issue, chances are they are fine. Try it yourself and you can always DDU and reinstall old driver if needed.**

* **My color is washed out after upgrading/installing driver. Help!** *Try going to the Nvidia Control Panel -> Change Resolution -> Scroll all the way down -> Output Dynamic Range = FULL.*
* **My game is stuttering when processing physics calculation** *Try going to the Nvidia Control Panel and to the Surround and PhysX settings and ensure the PhysX processor is set to your GPU*
* **What does the new Power Management option “Optimal Power” means? How does this differ from Adaptive?** *The new power management mode is related to what was said in the Geforce GTX 1080 keynote video. To further reduce power consumption while the computer is idle and nothing is changing on the screen, the driver will not make the GPU render a new frame; the driver will get the one (already rendered) frame from the framebuffer and output directly to monitor.*

# Remember, driver codes are extremely complex and there are billions of different possible configurations. The software will not be perfect and there will be issues for some people. For a more comprehensive list of open issues, please take a look at the Release Notes. Again, I encourage folks who installed the driver to post their experience here... good or bad.",Nestledrink,2021-05-18 12:47:17,171,424,0.99
145,Should i trade my used 3070 KO for a 3060 XC sealed and 1660Ti ventus xs like new? Thanks in advance!!,6hchill,2021-05-18 09:43:59,0,16,0.29
146,"Hi guys,

So, quick question.

I'm feeling like my 3080 is underperforming. In this example I'll use RDR 2. At the moment I'm getting around 70 to 75 FPS with dips to low 60's. The game is running at 1440p, max settings using vulkan.

System:
Mobo is an MSI Z390 Tomahawk

I7-9700K @ 4,9 ghz (overclocked)

RTX 3080 suprim X

32 gigs of Dominator RAM at 3200 Mhz - CL16

850W gold psu from Coolermaster

Latest drivers are installed


I tested both stock and overclocked setting with MSI afterburner ( +100 core clock, +500 mem clock).

During gaming the core clock goes up to 2040 MHz and is stable.

Usefull feedback would be greatly appreciated!",BoizzNoizz,2021-05-18 07:52:29,4,43,0.76
147,"Ok so I’m trying to undervolt my GPU for the first time and I think I’ve got it down after watching Optimum Techs guide. However, looking at my voltage/freq curve I noticed that the highest node in terms of frequency is at 2025 (starts at 1156 mV and ends at 1250). Now I’m REALLY new to this so it might be a stupid question but the thing is that looking at the specs of my GPU it really shouldn’t go that high so I’m afraid that if I start lowering the voltage from 2050 I might break my card or something.

What am I getting wrong or is there something that I’m missing. I’m on MSI Afterburner.",SledgehammerRampage,2021-05-18 07:40:35,6,12,0.81
148,"Being unable to source a GPU at decent price, I decided to give a try to GeForce Now, Nvidia's cloud gaming solution.

Unlike Stadia and other cloud gaming solution. GeForce Now allows you to play games you own from your Steam library or Epic game store with a caveat.

I found the experience very pleasent and seamless. The icing on the cake was that I was able to play my games on my smartphone.

For 10$ per month, this is really a good deal. Instead of upgrading every two years, I just pay 120$ per year and get to play with an up to date GPU.

You can try it for free (it s limited to 1h per day)

The caveat is that some AAA games are not available due to game publishers being greedy (Bethesda, Rockstar)

Pros:

Allows you to play games you own from Steam / Epic without having to buy them again.

Allows you to play games if you cannot get a GPU.

Allows you to play PC games on mobile devices/tablets/weak laptops.

As of today, it is cheaper than buying and maintaining a gaming PC.

Cons:

Some games are not available due to game publishers being greedy (Bethesda, Rockstar)

Limited to 1080p as of today but 4k will be implemented.

You need a decent internet connection (25MBps)",Just-Tune-Master,2021-05-18 06:26:06,383,225,0.93
149,"I'm only really writing this to serve as my experience with NVIDIA's RMA process, since I had a lot of hope that it would have gone as quickly as a lot of the RMA posts on this subreddit indicated.

**CONTEXT**
I was lucky enough to get a 3080 FE in a best buy drop in late March, and, until it's death, it was a wonderful card. In mid April while playing a game, War Thunder for those curious, I noticed a significant drop in frames. I checked HWINFO and the card was pulling way less watts then normal. I figured it might be a driver issue or some windows hangup since the computer had been on for a few days in a row. I updated drivers and restarted my computer, once shut down the card would not power on. I tried it in my second PCIE lane, and in a friends computer, but it was dead. I had decided to RMA with NVIDIA instead of returning it to Best Buy since it seemed more likely that I'd be able to get a card rather than a refund, and, as I mentioned above, most posts about the RMA process are rather glowing.

**NVIDIA CUSTOMER SERVICE**
I live chatted with NVIDIA customer service on the 20th of April, explaining the problem. They asked me to do some more basic troubleshooting to verify the cards condition, then submitted me for an RMA. The customer service representative said the replacement card would be sent immediately upon the warehouse receiving my card which seemed to line up with subreddit experiences. I got my RMA number and postage that night and sent my 3080 FE out the next day, but in that email the RMA team (guessing since it's from a different @NVIDIA source) stated that it would take 5-7 business days for the replacement to ship out, which is what I had expected. From that point onwards I've heard nothing from the RMA team, and only bits and pieces from the NVIDIA customer service when I explicitly ask a question.

After the original 7 business days had passed I had asked about the status of the replacement, which is when I was told by a CSR that: the warehouse had received the card, a replacement would be shipped in 5-7 days(new statement), and I would receive an email update when it happened. Long story short, those 7 days passed with no email and no updates. My last chat with NVIDIA occurred last week when a different CSR said they would check in the the RMA team for an update on my replacement, and an update 2 days later that they had not heard back from the team but had not forgotten about me and thanking me for my patience.

**THE POINT**
I want to let anyone who was like me and was looking for info into how NVIDIA handles RMA's to have a complete understanding that just because many posts show NVIDIA doing RMA's at light-speed, that there's a chance for it to go on way longer.

I'm quite happy with the customer service I received since I know these guys really can't do much, and was surprised when one updated me without me having to essentially bump my own support ticket. The RMA number issuance was also pretty fast being the same day and all.

I'm really not happy at being told two different times, or three depending on your point of view, when my card would ship only for nothing to happen.

I'm also astonished that the last CSR seemingly can not get ahold of the RMA team at all, since it has been a few days since they last reached out to me I've got to assume nothing has changed and they still haven't heard from them.

**TL;DR**
RMA takes a long time compared to others posted on this subreddit, been told multiple times when a replacement card would ship only for it to not happen.


I'll end up updating this post whenever my replacement actually ships.

**Edit:** I told you guys I’d return when my replacement shipped, and that day is today 05/25. I also figure that I can give a timeline of events since it’s less likely someone can try to impersonate me for my card.


04/20: Graphics card died, contacted CSR got RMA acceptance and number the same day. RMA email says replacement will ship come 5 business days after they have my card.

04/21: Shipped Card, prepaid FedEx provided by NVIDIA

04/28: My card is delivered to NVIDIA

05/03: First contact with NVIDIA, I ask if there’s any update with the RMA since I haven’t heard anything from them yet. I don’t mention the tracking number. CSR responds the same day saying that both the RMA and tracking number show that the warehouse received the card, and that the replacement would be shipped in 5-7 business days. There’s a bit at the bottom that asks me to reply to the email if I need any more assistance. I only mention this bit since this is the last I hear from the first agent.

05/10: I reply back asking about the status of the replacement.

05/11: CSR 2 responds saying that they’ve sent an email asking for an update from the “relevant team” (this gets mentioned a lot and I assume this means RMA team)

05/13: CSR 2 updates me, they haven’t heard back from the team yet but the CSR has not forgotten about me. This is the last time I hear from CSR 2.

05/17: I don’t remember which order I did this in, but it doesn’t really matter. Reddit post created and live chat with new CSR, CSR 3. CSR 3 says essentially the same thing CSR 2 said. They sent an email to the relevant team asking for an update and would notify me when they are updated. This is the last I hear from CSR 3.

05/20: I reply to the original email the RMA team sent in an effort to get ahold of them. I technically receive a response today, but that is mainly down to events today.

05/25: New week, new CSR, CSR 4. I ask a lot from CSR 4. First, if there’s an update to my case (no, relevant team will now contact me when there’s an update). Second, when should I hear from this team, since multiple CSR’s and myself have already tried to contact them to no result (sorry, but no eta). Third, if there was a reason for the delay itself (“Seems the team is checking about the RMA but do not have much info about it” actual response to that question). Fourth, if there was a way to contact the team directly, since I don’t want to keep bothering CSR’s every week (basically no, CSR 4 would request that the team follow up with me directly so I can get in contact with them).

I was kinda fed up at this point, seemingly getting and endless run around with none of my questions ever getting answered, so I went to the Better Business Bureau to lodge a complaint. Basically gave them this summery and the chat logs. It’s not up yet since they give NVIDIA a chance to respond first, but it could pop in a few days if you’re curious. I take a little nap, also got my second COVID-19 shot today. By the time I’ve gotten up I see an email from FedEx saying a package is on its way and one from the RMA team only mentioning the shipment is out now.

I’ve got to assume the BBB complaint is what kicked things off since I did contact them earlier that day and nobody mentioned it would be shipped anytime soon. None of the CSRs have contacted me for those updates from the RMA team, and the RMA team never really contacted me back either, but it doesn’t really matter at this point since the card is officially shipped.

Thanks for the kind words you guys commented when I originally made this post.",kyppki,2021-05-17 18:33:46,41,16,0.89
150,"Hi due to the pandemic I have been stuck at home and would like to build a gaming pc.
My friend has offered me to sell his galax 2080 ti for 800 dollars or I could buy a eagle oc 3080 for 800 more dollars.
Is the performance difference worth 800 dollars? Thank you for the responses.",MagicKoreanLv32,2021-05-17 17:34:58,0,36,0.5
151,"hey all, more of a discussion than a question but I've recently purchased a HDR monitor now, upgraded from a 34inch Ultrawide, anyway, I've noticed GeForce Experience continues to turn off when HDR is enabled, but when I turn it off it stays on, any particular reason why I'd does that? I've tried looking elsewhere but most threads I've found only date back to 2019. Thanks in advance.",Chris_Lickytung,2021-05-17 13:04:15,11,9,0.87
154,"The Zotac AMP has a reputation that the Gigabyte Vision doesn't, but the Vision has two HDMI ports, 1 8-pin connector, and three fans. Is the Vision rightfully enticing, or will I be stuck with poorer quality components down the road?",abelian424,2021-05-17 10:59:02,2,22,0.6
155,"I have the above GPU in Lenovo legion Y540.
I stopped gaming about half an year ago and I've been using the lap for normal purposes and will continue to do so for now.
My doubt is that should I leave the GPU on?(it's been on). Will it affect GPU's future performance (if I start gaming someday) or should I switch to basic graphics?",no_cap23,2021-05-17 07:10:42,2,6,0.75
156,If yea how complicated was it and how much temp reduction did u get,Goldeneye07,2021-05-17 05:15:21,6,2,0.75
159,"These are the steps I took to get rid of the coil whine on my Gigabyte gtx 1060 Xtreme. 

Using Evga precision x1 I reduced my clock speed to 1800 mhz on the voltage clock curve which you can see in the image below.

https://drive.google.com/file/d/1NJNrhDonvczzUuwG8QOQgnAl_oXArYH7/view?usp=drivesdk

The second thing that also helps with coil whine is thermal pads screwed tightly over the capicitors. You need to buy a GPU with a decent cooler & you should find the thermal pad on capicitors.

Take a look at the image with thermal pads next to the vrm which screws on top of capicitors.

https://www.techpowerup.com/review/gigabyte-gtx-1060-xtreme-gaming/4.html

My card never had what some people may call bad call whine but above 2000 mhz it was an annoying buzzing sound. With me reducing the clock to 1800 mhz and tightening screws over capicitors the coil whine is completely gone.",philosopherzen,2021-05-17 01:18:41,7,17,0.69
161,hey guys hello do any one have a printable Nvidia rtx sticker that should be high res and not pixelated and if possible in svg format,H_a_M_z_I_x,2021-05-16 23:49:52,0,0,0.44
162,"My frame of comparison is a MSI Ventus 3080 OC with a triple fan setup.

Both cards got the 15mwk pads from Gelid. The 3mm pads are too thick for the front of the MSI so I had to use 2+.5 for the die side of that card.

The MSI is a far larger card with a big cooler. It’s board design is also somewhat larger.

The dell card uses a very compact design with copper vapor chambers. It requires some additional steps such as thermal compound on its bracket plate.

After changing out thermal pads and repasting with Thermal Grizzly. The Dell card actually runs both cooler and quieter during 24hr benchmarks and stress tests. 

It’s about a 2-3% difference but I’m shocked how good the Dell Alienware card can run in a much smaller and quieter form factor.",FlyPenFly,2021-05-16 23:08:28,19,48,0.86
163,"I found a patent from late April, and it also referenced a patent from September 2020, it appears they have been overlooked

https://www.freepatentsonline.com/10991152.html https://www.freepatentsonline.com/10769076.html

Some screenshots of interesting slides:
https://imgur.com/a/qdWjY9H

I understand there have been leaks of a similar SM redesign, but the maco architecture looks different from the second patent link

https://twitter.com/0x22h/status/1365222611802710019?s=19

That leak is more in line with the first patent, however this appears to be more data center focused. Instead of each SM getting its own load/store and register, its shared between many more SM's, and it appears the SM only contains cores (fp, int). 

The second patent is something I haven't seen anywhere as far as I'm aware of. Each SM is still unified, but it gets its own register, load/store, l0i cache, scheduler, and other custom accelerators (likely tensor cores and rt cores). A plurality of SM's can do into something called a DPC (data processing cluster), which also includes a primitive engine, which is very gaming oriented. This is similar to the modified RDNA2 architecture in consoles I believe

Then a plurality of DPC's can fit into a GPC, which has a raster engine connected to each DPC, a pipeline manager, and prerop. Then multiple GPC's can fit into a PPU (parallel processing unit). 

Each GPC is connected to a high speed, low latency crossbar, which connects to a memory partition unit, which has l2 cache and memory phy. In this configuration I believe nvidia can set up the l2 to act like a victim cache, similar to infinity cache. There can be multiple memory partition units, which I found interesting.

All of this (and a few other things) go into a PPU (parallel processing unit), which multiple PPU's can be stacked or connected to one another via nvlink on the same package

I belive Lovelace is either a datacenter architecture, or its a gaming architecture consisting of one of these PPU's. Hopper will have multiple smaller PPU's. I'm no expert, and I don't guarantee all of my speculation is correct, but this is what I see. What are your thoughts",AwesomeShizzles,2021-05-16 22:01:31,19,6,0.89
164,"Based on the discussion in [this thread](https://www.reddit.com/r/Amd/comments/ncjonn/amd_should_add_a_setting_indicating_if_sam/) I added a detailed PCIe ReBAR report to GPU-Z -> Advanced Tab, or just click on the Resizable BAR readout on main screen.

[Screenshot](https://img.techpowerup.org/210516/snmnty8kzx.jpg)

[Download](https://www.techpowerup.com/wizzard/GPU-Z_BAR4.exe)

Not 100% sure yet if I got all these detections implemented correctly.

Could you guys test this on your systems (with and without BAR enabled/support) and let me know your thoughts?",WizzardTPU,2021-05-16 21:45:27,32,39,0.92
165,"Title says most of it, I know how intricate the design is for the 3080 FE.. So, what's the safest way to make sure I can clean it? Compressed air kind of worries me because of that fan exhausts directly out.. I'm guessing Q-tip/alcohol is probably the only safe option? Anyone else take a stab at cleaning theirs yet?

&#x200B;

Edit: Nevermind, it's been awhile since I actually looked at the card and I see that I can tape down / hold the fans and used compressed air. But still, anyone have thoughts on a robust way to clean out the heat sinks aside from just compressed air?",Opirr,2021-05-16 18:53:48,0,8,0.5
168,"TLDR; Scroll to the bottom of the post for links to all my sources and flashing directions. I have had zero issues with flashing any of the bios I posted and as long as you have sufficient card cooling this is the fastest way to enable resizable bar on your 3090 without waiting for Dell. If you are sticking to the stock cooler you MUST take the stickers off from the underside of the heatsink and add thermal paste to keep temps more reasonable. DO NOT flash an unlocked bios without improved cooling. I am **not condoning** anyone flashing a power unlocked bios here as it can very easily damage your card.

\-----------

When I first bought the Alienware Aurora R10 I had intended to keep it as my main machine, thinking I would be ok with not tinkering anything but clearly that didn't work out. The R10 was too noisy, odd looking and felt like it was underperforming for the components that were installed. I bought a new case and motherboard (I had another CPU AIO and PSU as well) and gutted the components from the R10 to make a new system. Everything went really well!

I bought an AIO, good thermal pads and passive backplate with a heatsink on top for the 3090 to significantly improve thermals. See the links at the bottom of the post for each thing I purchased. GPU temps went from mid 80s max to low 60s max and memory temps dropped from 90s to 70s max (30 minutes of stress testing with mostly Superposition 8K). Idle temps are in the 30s for both gpu and memory. I have a feeling the installation of the cooling solution is imperfect so the temps can likely be improved but these are much more within spec for card longevity.

One thing that has felt missing as of late is Resizable BAR support on my 3090 since my motherboard already supports it. After a lot of reading and stress I finally tried bios flashing on my Dell RTX 3090. Initially I was only interested in getting BAR unlocked so I read up on a few forum posts including one in the Alienware subreddit (see links at the bottom) to figure out what could be flashed safely on this particular 3090. I spent a long time looking up PCB pictures and comparing to the ones I took of my card. The Dell 3090 has a barebones reference design that's very dense so cooling is very important. The closest matching cards are the GALAX, KFA2, Gainward and Palit base 3090 models.

After reading the OCN 3090 Owners thread you can see people like to live on the edge with their $3000 cards. Suggestions range from 'stick to matching PCBs' to 'if the card has 2x8-pin connectors then any 2x8-pin bios will work'.  I went with the base locked KFA2 bios since someone had already reported success here on using a KFA2 bios. It worked perfectly and so did the Resizable BAR patch from KFA2! No changes in thermals or clock behavior but every benchmark went up a couple percent.

I felt encouraged by the previous successes and stability and decided to gamble further. Anyone sticking to stock cooling please do not proceed beyond this point! The OCN forum has a lot of unverified unlocked bios linked in their 760+ page thread. Several newer links are ReBAR enabled already so you could go directly to these bios if you choose to, I went the long way around by going with the stock KFA2 one first. An unlocked and overclocked GALAX Gaming OC bios is the one I settled on with a base power target of 370W and unlocked to 390W. No issues flashing or stress testing for 30 minutes. Thermals definitely went up as you can see in the HWINFO screenshot about 5-10 degrees max. This HWINFO session was only during the final Superposition 8K run so the numbers are a little skewed from the AIO being maxed out thermally. Benchmark numbers went up significantly more than the original stock to KFA2 rebar flash.

I am still building up the courage to overclock the card and push the power limit but honestly I have no reason to do it. This was an exercise in jailbreaking the card from Dell's bios schedule because who knows if they ever will enable bar support. Maybe someday if I get an actively cooled backplate or make a custom water loop I will really push the card but overall I am very happy with the additional 1-5% performance boost by this bios exercise. Keep in mind that this flash is fully reversible if you don't do anything stupid like pushing too much power or overclocking above thermal thresholds.

&#x200B;

**Flashing Instructions:**

1. Download your selected bios and NVFLASH.
2. Extract all files to a simple to type location like C:\\BIOS.
3. Open an administrator Command Prompt and get to the directory in the previous step (`cd C:\BIOS`).
4. Backup your current BIOS by typing the following and hit enter: `NVFLASH --save backup.rom`
5. Start the new bios flash: `NVFLASH -6 <YOURBIOS.ROM>`
6. You will be given a series of scary prompts that you have to reply to with 'Y'. These include accepting mismatched IDs and confirming the flash.
7. Hold your breath for 10 seconds.
8. You get a confirmation that you need to restart for the bios to take effect. Exhale. This is your final chance to flash back the original bios without any consequence. Once you reboot the new bios will be enabled.
9. Say a prayer and reboot Windows.
10. If your display comes up after rebooting you are good to go!
11. Confirm that ReBAR is enabled by opening GPU-Z or checking System Info in the Nvidia Control Panel. You may need to clean reinstall the nvidia drivers for resizeable bar to be correctly recognized, I only had to do this the first time.
12. If you flashed an overclocked or unlocked bios its highly suggested you do stress testing to ensure stability, if it is unstable then flash a more stable bios. A locked stock bios should not need this but it won't hurt to test it.

[KFA2 ReBar BIOS](https://preview.redd.it/k7l0afje0iz61.png?width=383&format=png&auto=webp&s=99e1ca027b03c127278c1a124061b3eac0e36009)

https://preview.redd.it/ah1tepnhroz61.png?width=383&format=png&auto=webp&s=1efb26d77c175cd563470836dab6521981689cf5

[KFA2 ReBar BIOS](https://preview.redd.it/edxzoije0iz61.png?width=548&format=png&auto=webp&s=35c8dd0ff5b7a98983362adac1975b62ba8fef0f)

https://preview.redd.it/5idth63groz61.png?width=548&format=png&auto=webp&s=8bd6e96ebb79f374161481d8e709788f51066c96

[GALAX ReBar Unlocked BIOS](https://preview.redd.it/etn1q8je0iz61.png?width=383&format=png&auto=webp&s=b1f6bf44906ea0745bfaa095fa3606a4f930f06e)

https://preview.redd.it/q2gq6vvkroz61.png?width=383&format=png&auto=webp&s=0c62316394e398462387f6213c707cc972f16d55

[GALAX Last Superposition 8K run](https://preview.redd.it/jafz1oje0iz61.png?width=504&format=png&auto=webp&s=cbe063fb7b351123933f12005b1b248b23d01b67)

https://preview.redd.it/l4nrqi6mroz61.png?width=504&format=png&auto=webp&s=80682acc4ce058c73cc44182b23d9a02ac35c383

[PCB Front](https://preview.redd.it/faacs4zqyhz61.jpg?width=4032&format=pjpg&auto=webp&s=30cea2cdc8e3aadf684e17387b0505f2967fc219)

https://preview.redd.it/o2yakq1oroz61.jpg?width=4032&format=pjpg&auto=webp&s=70ad5c0efe8e4641c5a06cbd382aa247a357604c

[PCB Back](https://preview.redd.it/g12aq5zqyhz61.jpg?width=4032&format=pjpg&auto=webp&s=1997fc222e4a56c4ec7c63903c239514180be926)

https://preview.redd.it/3x9agreproz61.jpg?width=4032&format=pjpg&auto=webp&s=3b93cbfb2e21228238b3fd4dd9467f56416e637e

[AIO Mounted Block](https://preview.redd.it/jxsfe7zqyhz61.jpg?width=4032&format=pjpg&auto=webp&s=5348ed8baa979d8711d30f7774d346d249b59e90)

https://preview.redd.it/w0mk6o3rroz61.jpg?width=4032&format=pjpg&auto=webp&s=dc79aaf46d4a900768ff5b638d231fdde8ee3b6d

[Full Build](https://preview.redd.it/1hxww8zqyhz61.jpg?width=2716&format=pjpg&auto=webp&s=724f27d1a2239492e93ff5a8996c47191c20d26d)

https://preview.redd.it/rvfcfkgsroz61.jpg?width=2716&format=pjpg&auto=webp&s=b062b266c03c8741d32ed26111b125d0823824b8

[Side View](https://preview.redd.it/rz3rd7zqyhz61.jpg?width=2268&format=pjpg&auto=webp&s=f23942dec04b18b40913742d3c60047b9ff0714b)

https://preview.redd.it/pdu6q8rtroz61.jpg?width=2268&format=pjpg&auto=webp&s=6bd7be671b4fe0ddd9d48e95baabf902c90a6d11

&#x200B;

**Links**

NVFlash: [https://www.techpowerup.com/download/nvidia-nvflash/](https://www.techpowerup.com/download/nvidia-nvflash/)

Stock locked KFA2 BIOS that can be BAR enabled: [https://www.techpowerup.com/vgabios/226355/kfa2-rtx3090-24576-200911](https://www.techpowerup.com/vgabios/226355/kfa2-rtx3090-24576-200911)  ReBAR Patch: [https://www.kfa2.com/bar-gtm-update](https://www.kfa2.com/bar-gtm-update)

GALAX Gaming OC Unlocked ReBAR BIOS with 370W base + overclocked: [https://www.techpowerup.com/vgabios/231600/231600](https://www.techpowerup.com/vgabios/231600/231600)

AIO + Backplate: [https://www.aliexpress.com/item/1005001500419835.html](https://www.aliexpress.com/item/1005001500419835.html)

Thermal Pads (1.5mm 120x120): [https://www.aliexpress.com/item/1005002063415554.html](https://www.aliexpress.com/item/1005002063415554.html)

Backplate heatsink (mounted with cheap thermal tape): [https://www.amazon.com/gp/product/B07VMMJCLY](https://www.amazon.com/gp/product/B07VMMJCLY)

Cooling and flashing guidance: [https://forums.redflagdeals.com/dell-alienware-aurora-r11-r10-3080-3090-mod-thread-cooling-case-swap-2445451/](https://forums.redflagdeals.com/dell-alienware-aurora-r11-r10-3080-3090-mod-thread-cooling-case-swap-2445451/)

Previous Brave Soul (who likely lost his card to an unlocked bios with the stock cooler): [https://www.reddit.com/r/Alienware/comments/m619vm/alienware\_3090\_custom\_bios\_flashed\_and\_power/](https://www.reddit.com/r/Alienware/comments/m619vm/alienware_3090_custom_bios_flashed_and_power/)

3090 Overclocking and Flashing Forum: [https://www.overclock.net/threads/official-nvidia-rtx-3090-owners-club.1753930/](https://www.overclock.net/threads/official-nvidia-rtx-3090-owners-club.1753930/)",Haibius,2021-05-16 15:05:25,10,10,1.0
169,"Since replacing my motherboard and cpu, my FTW3 3080 was showing significantly higher temperatures, averaging 10-15 celsius. I tried a variety of fan speeds and taking the side off the case, but it wasn't until I removed a support I was using to prevent GPU sag that my temps immediatly fell and returned to normal. 

I was using one of the supports that lifts up on the end of the card, but I am guessing this was compressing the pads too much, or making them uneven. If you're using a sag bracket, I recommend looking at your temperatures with and without it.",Bitzooka-Mato,2021-05-16 15:02:49,12,24,1.0
170,"[https://images.finncdn.no/dynamic/960w/2021/5/vertical-0/03/9/217/349/919\_780285930.jpg](https://images.finncdn.no/dynamic/960w/2021/5/vertical-0/03/9/217/349/919_780285930.jpg)

&#x200B;

[https://images.finncdn.no/dynamic/960w/2021/5/vertical-0/03/9/217/349/919\_428414026.jpg](https://images.finncdn.no/dynamic/960w/2021/5/vertical-0/03/9/217/349/919_428414026.jpg)

&#x200B;

So the specs are identical to the RTX 3080 Founder's Edition and I found the latest VBIOS with the same specs here: [https://www.techpowerup.com/vgabios/231658/nvidia-rtx3080-10240-210304](https://www.techpowerup.com/vgabios/231658/nvidia-rtx3080-10240-210304)

I assume it's safe to use this VBIOS?

&#x200B;

EDIT: Zotac's Trinity VBIOS worked   
[https://imgur.com/a/ChPbQVs](https://imgur.com/a/ChPbQVs)",Kololoss,2021-05-16 14:28:44,7,15,0.89
175,"Hi all,

I’ve been away from PC gaming for around 15 years. I’ve recently purchased a new PC with a 3070. My question is: where does the 3070 sit in relation to other cards on the market now?

Obviously the 3080 and 3090 are high end, but seen in relation to the 3060 and 20 series, where would you place the 3070?

Additionally, how many years do you think I’ll be good for with this card?

Thanks!",nobleflame,2021-05-16 09:55:24,24,121,0.74
176,"When I google it, the only results I can find are related to the rtx 3060 ti and above cards. I swear I've seen someone mention it before but I can't seem to find any guides or posts on any website discussing rtx 3060 undervolting and performance related to it.",Starbuilder5,2021-05-16 08:49:44,3,13,0.71
177,"Hey Guys,

Like the title says, is there any apps out there that can show the 3rd fan on my  ASUS TUF Gaming GeForce RTX™ 3060 OC Edition.

I've used HWINFO64, HWMONITOR, GPU-Z, MSI AFTERBUNER but all of them only shows 2 of the 3 fans.

It just bugs me that I can see the 3rd fan anywhere. Any help would be appreciated.",Professional-Ad-7325,2021-05-16 08:06:51,2,3,1.0
178,"I’m curious on what people have seen with the 3080 FE with overclocking. What is a good % to over clock the memory and core clocks in MSI afterburner to increase FPS in games like GTA5, CODMW? Thanks in advance for the input!",cartoonist2734-,2021-05-16 07:28:55,2,26,0.75
185,"Just wanted to get an idea of what everybodies undervolt is, curiosity more than anything else. My 3080fe is at 1890mhz @856mv.",manooko,2021-05-15 18:25:06,2,37,0.67
187,"Hi guys! So i have been looking at 3060s GPUs for a couple of months now. I'm trying to get a 3060, but i don't know the difference between a double and triple fan GPU. Is the difference big or small.

Thanks

PS English is not my first language",PlushieDuck,2021-05-15 16:21:23,0,6,0.5
195,"Hi,I have couple of questions and i really want to know the answers so i can if something went wrong.

1- Is the RTX 3090 Asus OC has dual BIOS ?

2- What does the switch on the GPU mean? there are Quite mode and Performance mode, Does that mean both of them has individual BIOS or both of them same BIOS?

3- Is there a way that i update both BIOS at the same time or do i need to update one then turn off the PC then flip the switch to the other BIOS then update it ?

4- If one of them fails during update, can i flip the switch to other BIOS and restore the broken BIOS that has failed during update ?

Thanks in Advance !",Mohxmedz,2021-05-14 22:12:00,0,7,0.5
197,"https://www.nvidia.com/en-us/drivers/nv-uefi-update-x64/

That tool just solved all my headaches regarding my motherboard failing on graphics initialization if CSM was disabled (the default on my board). I'm running an EVGA 1080 Ti SC Black Edition, so even if you got your card later in Pascal's life cycle, you may still need the update.

I had no clue this thing existed for the entire time I've owned this card, it was only after upgrading my other hardware recently that I experienced this trouble, which makes sense. I would make a suggestion that this fix is made more visible and maybe included with driver updates in the future, though. Posting here so hopefully others can find the fix.

EDIT: Apparently, this works for 900-series and some 700-series cards, too.",GloryBoy1349,2021-05-14 19:28:50,67,13,0.98
198,"Hi all,

Looking to upgrade the thermal pads of my RTX 3090 and was wondering if these ones would do the trick:

I read that the back of the GPU is supposed to have 2.5mm thickness and the front of the card is supposed to have 1.5mm thickness. Can anyone confirm if this is right? 

If so, I'm planning of using the Thermalright Extreme Odyssey pad's but they don't seem to come in 2.5mm thickness. Will the 2mm or 3mm be better?

Thanks!",TraditionalAd4010,2021-05-14 17:52:51,0,8,0.5
201,Don't know where to post questions on here. Does anyone have a website where you can see the accurate comparisons between cards?,oAvaxi,2021-05-14 16:17:35,1,15,0.54
202,I’m looking to get the most fps playing Call of Duty on 4k using my EVGA 3099 ftw3 ultra. Can someone share some OC settings I can try to get the most fps?,brandobot89,2021-05-14 14:58:17,0,12,0.22
204,Thanks!,WindyDizzel,2021-05-14 13:24:36,1,18,0.53
208,"As the title says does anyone know if this is a thing as my minimum rpm in AB only shows a min of 30% but i've seen elsewhere that you can have it at 0db up to 50 degree Celsius. Or does my card not have that?

Any help would be great thanks!",Hotsmithy2016,2021-05-14 05:51:42,3,4,0.81
209," Used Nvidia's performance automatic tuning to get a light overclock on my GPU (no intention of overclocking my card as much as possible with it, just want a nice safe little boost is all). Having already scanned it, and gained 119Mhz, is it safe to leave it on all the time? Either way, is it best to stick with NVidia's overclock, or recreate it with something like MSI Afterburner?",nik0121,2021-05-14 04:40:48,5,3,0.86
210,"https://twitter.com/nvidiageforce/status/1393022067667214339?s=21 I just saw this post that a 144hz reflex on has the lowest latency with a mouse click, does this translate to a controller?

If I’m on Modern Warfare with 144hz reflex on but I’m playing with a controller is the reaction trigger pull reduced too the same as the mouse click?
Thanks guy",tomj834,2021-05-14 02:20:21,4,7,0.75
211,"Hey guys.

I've tried googling where the current sweet spot is for visual smoothness and responsiveness, but most articles and posts are a few years old.

I'm wondering if anyone can provide some insight on where things currently stand.

I have an older 165hz 1440p IPS (AOC AGON AG271QG)

Ran great, but it's not perfect in the blur department, so Id used ULMB for that. However the screen tearing was terrible. Turning on vsync was an option, but I'd need a GPU that can push frames up to 120 (ulmb's refresh rate), which my 1070 could not. And then I'd also have to deal with input lag.

Fast forward to present day.

Now there's low latency mode tech, and I have a 3080 that can push frames.

Is there any draw backs to running a set up of settings as stated in the title? Mainly wondering if low latency mode cleans up a lot of vsyncs input lag. Playing with these settings feels fine, but I'd just like to learn more!

I find the 120hz ULMB+VSYNC+LLM to be way more visually smooth than 165hz GSYNC+VSYNC+LLM",SwingPoynt,2021-05-14 00:39:27,4,16,0.83
212,"I'm getting a pc with a 3060ti and I want to know how nvenc works. Does it do what an elgato would? And if it does allow for high quality streaming and recording gameplay, will it affect performance? Also I want to know if it would reduce the life of my gpu or other parts in the pc. I'm new to the pc community and would really appreciate some help.",AbuzzCreator252,2021-05-14 00:24:05,9,6,0.77
213,"In my quest to find a cheaper RTX 3000 Series, to use in my main PC, I came across an Acer Predator Orion 3000 prebuilt. I  bought it from a local retailer for approx. 1400 EUR (same price scalpers and some retailers are asking for an single RTX 3060 TI or RTX 3070). 

None of the reviews I found YouTube were of any good to me to see what components are used in the Orion 3000, especially what type of graphic card is inside. 

They use a reference design RTX 3060 TI, but with a blower style cooler: 

more details: [https://youtu.be/MWq5Blkelbs](https://youtu.be/MWq5Blkelbs)",CyberThug975,2021-05-13 20:12:25,2,6,0.75
215,"Im planning on resurrecting my old damaged laptop (had some bad outer shell damage from falls and battery isnt charging anymore because of something damaged in the motherboard or something idk) and im going to try and make it a htpc to store movies on and also stream stuff like youtube and netflix

it was an asus k55vd which had nvidia g610 graphics, intel i7 3630QM, 8 gb of ram and a small ssd with 256gb (might upgrade to another hdd with like 1-2 tb if needded to store media

can that old rig be used as a streaming device? only planning on 1080p with hdmi so nothing too fancy but still... 

&#x200B;

btw, obviously i checked everything even after reconstruction of the laptop itself and everything still works properly , i just dont want to invest too much time and some money on something that wont work as intended",geler1,2021-05-13 16:01:11,3,7,0.81
217,"Hi guys, I was just wondering does anybody know what date the EVGA que is on? I got in line on 9-27 for the 3080. How much longer do you think it will be? Anybody join around the same time as me recieve their email yet?",NeVrDarK,2021-05-13 12:33:51,12,103,0.73
218,"Hello,

The other day I repasted my RTX 2080 ventus OC because the fans where ramping up and it was sounding like a jet engine.  while i took off the back plate of the card one of the thermal pads on the side of the GPU die got ripped . I put it back the best way i could and finish mounting it. The repaste worked and now the card is way more silent. Anyway in the future ide like to replace the original thermal pads. Anyone knows which thickness i should get ?

Thanks",milka0673,2021-05-13 12:27:50,1,4,1.0
219," I spent a few hours trying to figure out what was wrong since I had my monitor at 75Hz before formatting my PC, and when I installed Windows again I couldn't get any custom resolutions to show up. I thought ""It can't possibly be because when I first set it to 75Hz it was in Landscape mode... can it?""

Well... If you want to choose a higher refresh rate on your Portrait mode monitor, set it to Landscape first, then enable the custom resolution with the higher refresh rate, and then set it back to Portrait mode.",dudjent,2021-05-13 10:57:20,0,1,0.5
220,"In the performance overlay, is GPU Utilization referring to VRAM, or is it just referring to how much general work the GPU is doing? If not, is there a way to display VRAM usage?",nik0121,2021-05-13 10:04:48,3,6,0.81
221,I currently have an outdated 2005 pc same year that the xbox 360 came out and i was wondering whether to get a brand new pc an rtx 2080 ti or stick with my old outdated pc any ideas on what i should do?.,Cloverfield887,2021-05-13 09:52:35,0,31,0.38
222,yea that\^\^\^,Waldo_19,2021-05-13 09:51:19,1,8,0.54
223,"Hello,

I have been trying to buy a 3080 since launch. I have had multiple retailers cancel my orders. 

I read on another post about stock monitoring groups. Can anyone point me to such a group for France?

Thank you!",ikukuru,2021-05-13 08:33:19,1,5,1.0
224,Is okay if the radiator/ Fan has the pipes on the side and being lower than the GPU? Or should I rotate it and orient the top of the radiator high as or higher than the GPU?,tatsu901,2021-05-13 01:38:30,0,18,0.5
225,"At the turing launch, the market material was that tensor core will denoise the RT image to give the best result.

Fast foward today, Tensors are only used for DLSS and some temporal technique is used in all RT game to remove the noise.

of course using tensor for denoise and dlss might have overload it and tank the fps but what about using it only for denoising  while running native res ?",pat1822,2021-05-12 19:49:56,12,13,0.72
228,"I'm new to machine learning and have a GeForce RTX 3090 The support matrix for cuDNN ([https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html](https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html)) apparently shows that r450 cuda driver is more compatible than r455 and r460, since you can use it with 11.0,11.1,11.2:

11.3: r465 

11.2 update 1: r460, r455, r450 

11.1: r450, r455 

11.0: r450

Does this mean I should get a ""nvidia driver"" version 450 to use 11.0,11.1 and 11.2? Or do the new ""nvidia drivers"" come with all of these ""cuda drivers""? I'd like to be able to use as many cuda versions as I can because a lot of code is using older cuda versions.",asi_takeover,2021-05-12 18:10:40,1,11,0.6
229,"https://twitter.com/Blackmagic_News/status/1392375156262064131

https://forum.blackmagicdesign.com/viewtopic.php?f=21&t=141034

> Support for decoding AV1 clips on Windows.

>Accelerated AV1 decodes on supported Intel, NVIDIA and AMD platforms.

>Support for decoding MKV clips.",GPUNV,2021-05-12 17:31:56,243,54,0.98
230,"Hi everybody,

I am using a Nvidia RTX2080 with a Asus G-Sync monitor. When I use G-Sync on default with V-Sync on in Nvidia control panel and ingame settings V-Sync off I get bad FPS performance. When I use G-Sync with V-Sync all off I get much better performance. 
My question is do I still get any G-Sync advantages or is it useless with these settings?",Blaqside,2021-05-12 15:58:14,6,38,0.69
231,"Hello everyone. I have been racking my brain on this, and probably overthinking it, but I was wondering if you guys can help me. 

My build is in a 4000D Airflow Corsair case. I have (3) 120MM fans for the intake, (2) 120MM fans on the top exhausting hot air from my Corsair 240MM CPU Rad and one 120MM fan in the rear exhausting. I just ordered a Evga Hybrid Kit for my RTX 3080 FTW3. 

Should I do a push/pull front set up on the Hybrid Rad or should I get a new case, thinking 5000D Corsair, that allows for side mounting. 

Computer is used for gaming and mining while I'm sleeping or at work so I am trying to keep temps as low as I can. Let me know your thoughts. I do appreciate it.",NewEdgeMan,2021-05-12 15:25:48,4,14,0.83
232,"So basically I'm looking to buy a new prebuilt pc and want it to fit my triple monitor set up. Looking online I suspect  it has 3 dp however the advert states 1 (do they even make 3080s with only 1 dp? I suspect it's a mistake but they have no model of the 3080 for me to check or picture or the io. Any help would be appreciated, advert linked to see what what I'm looking at.[pc advert](https://www.currys.co.uk/gbuk/gaming/pc-gaming/gaming-pcs/pcspecialist-tornado-r9-gaming-pc-amd-ryzen-9-rtx-3080-2-tb-hdd-1-tb-ssd-10217080-pdt.html)",alewthwaite123,2021-05-12 12:54:24,0,34,0.5
233,"Hello - I recently replaced the thermal pads and paste on my Gigabyte RTX 2060 Super (3x). The GPU is now thermal throttling and staying at 88C at full use. Have manually set the fan to 100% as well via MSI Afterburner, but it continues with the same temp. I did not have these high temps prior to my pads and paste, so I must have missed something. I double-checked that I didn't miss any pads and paste looks good. Pads are 2mm, which look to be slightly thicker than the ones that came with it stock. Those looked to be flimsy 1mm. Any help is appreciated!",FreeSeaweed1644,2021-05-12 01:03:30,6,4,0.87
234,"Hi all. I am a graphics card novice, and I've been searching a lot, but most info i find for graphics cards are gaming. 

I will buy a new computer and use mainly for 3d modelling. The decision is between Quadro rtx 4000 and Geforce rtx 3070. I've seen Quadro described to be for non-gamer-related tasks, but it is also older than rtx 3070. Should i get the geforce then? It seems extremely potent, i guess it will translate to 3d, too? What would you recommend?

Thanks so much in advance!",KeepLearningMore,2021-05-11 19:47:13,3,22,0.8
236,"Hey guys,

Just got my hands on a ventus 3x oc 3070 and was wondering if anyone has a stable undervolt for it? Pairing it with a 3700x.",gotxkornx,2021-05-11 19:21:19,4,8,0.84
238,"I'm getting one soon and I was looking for info on VRAM temps and overall impressions but could only find stuff about the Revel version.  I'm not even sure how they compare- it looks like the Uprising is bigger?

Anyway, I was hoping to hear from people who own the card to get their impressions, especially if they did a thermal pad mod.",aoifhasoifha,2021-05-11 17:17:23,2,3,0.63
239,Does anyone have this already in Canada? Is anyone lucky enough to have this?,Mysterious_Dentist69,2021-05-11 17:02:19,7,6,0.89
242,"Greetings fellow nerds!  I come as a layperson regarding the line of RTX GPUs in laptops.  I've got a fair budget to use, but still want to get the best bang for my buck but not exactly break the bank.

I'm sure there is the instant pull to say to get/build a tower.  With that, I do a lot of traveling, and at this point dont have the space to build a battle station yet.  One day...

I've been looking at the different options currently available, suck as the 30X0 series and the Max Q of the 20X0 series.  I'm not as knowledgeable about a lot of the inner workings, but my mind says 30 series is newer/better, but even then some of the 20 series are just as much if not more than the prior. 

Currently looking at Asus, MSI, and Razer as likely candidates to replace my much loved and used Nitro 5, but want to get into the RTX series and take advantage of those features with some of my games.  Any advice on which direction to go would be greatly appreciated!

Thanks!

Update:  thanks for the info!  I appreciate the all of the replies, and feel more confident in what to look for moving forward.  Also, thanks for the silver!  First of those!",maneastj,2021-05-11 03:42:02,14,5,0.95
244,"Hoping someone can provide a more technical explanation of what render latency is and answer a few of my questions about it.

Why does dividing 1000 by my render latency not equal the current FPS? If my render latency is 10ms, I would assume that my system can render 100 frames each second, each frame taking 10ms (assuming frames are rendered sequentially, one by one, which may be a wrong assumption). However this is not the case and the reported FPS is usually much higher than the ""expected"" framerate that we get from doing this simple division. For example when my display reports 165FPS, the expected latency is 6.06ms, but the latency generally never even touches 6 and instead hovers in the 7-9 range (111-142 expected FPS). 

Some games push this to an extreme and report >100FPS while the render latency is >20ms. In these cases I can feel a difference in smoothness. Even though the game may be reporting 120fps, it feels like 60. How does this ""false"" framerate occur and what is actually happening here? Are some frames being shown twice, but the system is still counting it as two frames so the FPS is wrongly inflated? Are some frames literally being displayed longer than others (using a gsync display so not sure if this is even possible)?

Aside from the obvious ""turn the settings down"", is there anything I can do to push my render latency as low as possible? Do some settings affect it more than others? Does the CPU play a role?

Sorry if this is super technical, but it's become apparent that render latency plays a huge role in how smooth a game feels, even superseding FPS in some cases.

Running a 2080 Super and 5900X btw. Posting this thread because RE8 has been hitting me with higher than average latency (12-15ms in some spots) and it makes the game noticeably less smooth even though the framerate generally hovers around 120-130. Trying to figure out if this issue is possible to solve.

Thanks!",HesBackAgainAgain,2021-05-11 02:36:23,6,6,0.88
245,"My friend purchased the RTX 3080 in Canada through Bestbuy Canada's website and received it the next day. However, for those who don't know it seems that all rtx 3080 strix through BestBuy Canada ship [like this without any additional box..](https://i.imgur.com/2cuefwN.png) (confirmed with few others who ordered the same card). We thought it was ok and the GPU started up normally. It's idle temperatures were a bit high (mid 50 Celsius degrees) but we shrugged it off. Then the GPU suddenly died after *SIX* days of usage. Not even a week and the GPU is completely dead. We've tried inserting the GPU into different PCs and they all gave the same result: No LEDS, no fans spinning, black screen. It's like the PC was never turned on. We reached out to ASUS for the RMA process and it went pretty smoothly.

ASUS gave my friend a prepaid shipping label but he had to pay for it, and it was roughly $90 CAD. My friend dropped off the GPU at a FedEx location on Tuesday, and it arrived in Asus Markham the next day. They told my friend the process will take 7-10 business days but then he received an update on Friday the same week and ASUS says they will provide him a new GPU with the warranty transferring over to the new card. Great news! FedEx didn't deliver over the weekend however so he received the card today on Monday. The GPU came in and everything is up and running, also the idle temperature is significantly lower on this card than the previous card. The whole RMA process took less than a week and we were very pleased with it. ASUS communicated with my friend and made the entire process hassle free.",Willy156,2021-05-10 22:56:56,10,14,0.75
248,"This question has stood on my mind for a long time, assuming we have achieved perfectness in the models poly count and details (with UE5 Nanite tech or similar) which is still obviously rasterized, is enhancing the lighting quality the only barrier to attain near (near because I know that a few rays per pixel even with denoisers aren't gonna achieve 100% parity with something like hundreds of rays per pixel) pre-rendered CGI like graphics ? or are the shaders laking too ? in other words let's hypothetically assume that we have unlimited power on a PC then would a scene using rasterized environment/models along with their textures + all the rest like the lighting and stuff using ray-path tracing be of the same quality as a scene with full ray-path tracing rendering ?

anyone here with knowledge that can help ? and thanks for diving in !",dinodad2,2021-05-10 20:38:56,15,14,0.95
249,"I picked up a 3090FE at the end of February to use in my PC, primarily for gaming, but also for mining to recoup some of the cost.

As with most on here, games like Jedi Fallen Order were hitting 90+ on mem junction temps, and as soon as mining started (even with no mem OC), she would thermal throttle.

After messing with fans, heatsinks and other unsightly methods, I bit the bullet and repadded ONLY the back (i.e by removing the backplate, and applying to the locations shown on the CryptoAtHome video) using Thermalright Oddysey 1.5mm pads from Amazon, and saw a massive improvement, with temps ranging from 90-96 degrees (depending on the ambient temps), which at 123mh/s was a great success.

We managed to score my partner a 3090FE at the end of April, and again, thermal throttling. So another order of Thermalright Oddysey 1.5mm pads from Amazon later, we re-did the back of his.

Sadly, we didn't see as much as an improvement as we did with the first card, with temps hovering around 100-104 whilst mining (same settings, in my PC case (so same airflow etc)), so whilst it was no longer thermal throttling, it was certainly less than ideal.

I figured that there must be something on the front of the card causing the high temps, so studied YouTube vids, ordered a bunch more pads (120mm x 120mm x 1.5mm from Ali Express and another 80 x 45 x 1.5mm from Amazon), and re-did the front of the card at the weekend (re-pasting with Arctic MX-5 too).

Whilst temps were improved (96-100), it still wasn't the magic 84 degrees that i've seen bounded around here quite a lot, nor what I had on the card bought back in Feb, so I figured I mustn't have done the back correctly (despite using the same size cutouts and pads).

Fast forward to tonight, I've just re-done the back, and still no difference, \~100 degrees. Same PC, same airflow,same settings, still high temps.

Has anyone seen behaviour like this? I've seen posts about people having redone their cards and it making no diff, but whilst this made a diff in that its not thermal throttling, it's still pretty toasty. Could this be the silicon lottery people speak of?

It seems I don't have many pics of the pads on the new card, but a couple of pics are [https://imgur.com/a/NUtadJq](https://imgur.com/a/NUtadJq)",p14c08,2021-05-10 20:04:38,4,25,0.64
250,"I am currently considering getting a gaming laptop with a 3060/3070 since it's impossible to buy a gpu in my country below 2k euros.  

How long do you guys think it will take to see how the GPU market changes?

&#x200B;

It's been two years now that I need to upgrade so I'm really tempted, but I don't wanna regret this purchase in a couple of months.",Gravega,2021-05-10 16:20:48,11,50,0.68
251,"Hello,

So I want to try to buy a new 3080/3070 Ti FE card when it comes out. However I am from Belgium and I know they don't sell them here, but I do live very close to the French border. Is there an option to buy and FE card on the French NVIDIA webstore and deliver it to something like a parcel shop/ box?  (That way I can just drive there and get it)

I know it's quite optimistic but I want to try and to do that I need to know if I can ship it to a parcel store or parcel locker etc.

Thanks in advance",tiger3131,2021-05-10 15:39:53,4,11,0.75
252,"Hi,

Wanted to see if anyone tried to put a fan on top of the backplate of the 3090FE where the memory modules sit without putting heatsinks on top (like this: [https://imgur.com/a/bG63inK](https://imgur.com/a/bG63inK)). On my card, they got hot to the touch, and my options that aren't repadding or going on water are limited since I also rock a big CPU cooler:

[https://imgur.com/a/FpYS649](https://imgur.com/a/FpYS649)

I mounted a extra fan I had lying around vertically which helped drop temps 2-4C depending on game, but I'm wondering if I just jam a super slim fan between the CPU cooler and GPU (I think Noctua's 14 or 15mm fans may fit, definitely not the 25mm ""normal sized"" fans), if that will reduce temps a bit better.

I know this works on some AIB cards since the backplate is perforated and has holes, so pointing a fan downward on the backplate have gotten some people great results, but not sure on the FE cards. Anyone try this?",preciseman,2021-05-10 14:25:25,14,61,0.79
255,"Hi everyone.

As everyone probably already has read/heard, the 3090FE suffers from some pretty poor vram temps.

Even under gaming loads, when the core is super cool (<70C), VRAM can hit 102C on demanding games at higher resolutions (3840x1600 or 4k) that hit power limits (dirt 5 is a great example), resulting in fans ramping up quickly and much higher than desired.

Everything I've read online suggests to immediately change thermal pads on the card, but I wanted to make sure that was the absolute last resort. Other people were applying raspberry pi heatsinks on the backplate itself and then putting a fan on top (like this: [https://imgur.com/a/JuaSuYm](https://imgur.com/a/JuaSuYm)), but due to having an air cooler, there isn't enough space between the CPU tower and the GPU for me to fit fans/larger heatsinks.

I had a extra 140mm fan lying around, and just literally mounted it vertically so a little bit of air can get between the CPU cooler and the gpu, and rested it on a small magnet so that it basically ""fit"" between the cpu cooler and the PSU shroud like this:

[https://imgur.com/a/FpYS649](https://imgur.com/a/FpYS649)

In dirt 5/cyberpunk2077/black ops cold war with ray tracing on and at 3840x1600, it typically dropped temps down about 2-4C on the memory junction, which for me, resulted in both a lower GPU fan rpm and a slower fan rpm spinup.

It seems like if you have a CPU tower with one of these cards, there's quite a bit of heat that gets trapped between the cpu tower and the backplate, so adding a bit of airflow helps, at least in my testing.

I'm probably going to end up repadding, but figured I'd just write this up, as since I had the extra fan lying around (and wouldn't have used it for anything), it was the most non-invasive ""free"" help to at least cool down the vram temp a little.",preciseman,2021-05-10 08:31:29,2,26,1.0
258,I been on a single player campaign cinematic voyage. Looking to get the best picture and color. I’m looking to apply a filter(s) to enhance the image. I noticed some games are grainy or looks washed up. For specs I’m using a 3090 and 2K monitor at 165hz. Please let know any recommendations.,SenorCandy,2021-05-09 17:54:02,0,2,0.5
260,Hello is RTX 2070 Super for 660$ a good deal at the current market status ?,notdave07-_-,2021-05-09 14:28:37,9,12,0.91
261,"Does the new Nvidia performance menu overwrite my current GPU settings?  
I use EVGA Precision X1 to set my GPU OC and fan curves but the new Nvidia performance menu doesn't have an obvious on/off button.

Does this effect my current settings?",tjnuttall,2021-05-09 15:28:18,7,9,0.89
264,"I just started playing Control as one of the games in the bucket list to play when I got my RTX 3080. First game that I’ve had the chance to play with actual RTX settings. I was SO blown away I wanted to share it with my fellow Nvidia boys!

I am so amazed how ray tracing makes the games so much more atmospheric! It really adds another layer of realism and texture to this game. Little things like light diffusing on floors/walls and the projectors silhouette really does it  for me. Not to mention that using DLSS makes it’s run so smooth at 4K/60fps.

Super keen for this playthrough and to see other games with RTX settings in the future.

EDIT: Thank you for the kind silver stranger! I’m glad to see some of y’all enjoying RTX same as I.",13V1_,2021-05-09 10:36:57,54,60,0.83
266,"I have a 2060 super oc x3 with a usbc port, are you able to tell me if it is usb 3 or 3.1 or 3.2?",trshittt56,2021-05-09 00:26:46,6,1,0.88
267,"Hi,
I currently have a EVGA FTW3 3070 and it comes in at a crazy 300mm long. Unfortunately I didn't anticipate this and as a result my gpu actually runs into the middle radiator fan I have so I had to remove it as a result. That being said, I was going to wait for the RTX 3080 TI and try my luck before watercooling the gpu  but with everything the way it is, I'm going to instead try and trade my FTW3 for a shorter 3070 and hopefully get that fan installed back where it should be. My only issue thus far is I know that a good portion of the time, removing the stock cooling for a block can actuslly shrink the space that the air cooler currently takes up and sometimes a gpu will actually loose length because the pcb is smaller then the stock cooler. All that said I'm having a hell of a hard time trying to find which 3070's will be approx. 285mm or less in length after removing the stock cooling.

Does anyone know of any RTX 3070 that is less then 285mm with the stock cooler removed? (Aside from the obvious 2 fan designs)

Thanks",vulcanrvn90,2021-05-09 00:23:09,5,7,0.86
269,What exactly is the difference on the PCB other than the 2 extra power pins? What has been changed to warrant the extra power? I can't find any info on this.,LessLipMoreNip,2021-05-08 19:11:08,4,0,1.0
271,"Title. Currently trying to decide on a laptop, and the one with the 3070 is like a thousand bucks cheaper. Trying to decide between Area 51m R2 and Lenovo Legion 5 Pro btw :)",DarkSenf127,2021-05-08 17:41:34,6,21,0.88
272,"Hello, I currently have a board that has ""open"" (no back to block larger cards) PCIE 1x slots, that currently has a Nvidia GT 710 in it for my server. I am looking to up it to something that can do NVENC encoding if possible, currently looking at the P400.  


There doesn't seem to be any information if these cards can operate their NVENC encoding at 1x or even work on a PCIE 1x slot, so any info would be greatly appreciated!",cantremembermypasswd,2021-05-08 13:54:21,4,14,0.67
273,Is that card a good deal for 200 for gaming?,milkandavacado,2021-05-08 13:46:07,3,6,0.8
276, Is DSR completely removed as a feature? Or is it just not available on Quadro RTX GPUs? I have tried seemingly everything and feeling disappointed that I can't use DSR anymore. It's really useful for a lot of games and an RTX 4000 is quite capable of running DSR on a 1080p screen. Any ideas?,Monkey1970,2021-05-08 08:24:38,9,7,1.0
278,I'm guessing this thing is a reference design pulled from an HP machine.  It works fine but I'd really like to put a hybrid water kit on it.  Any suggestions? Links?,F34RTEHR34PER,2021-05-08 03:05:39,4,7,0.83
283,"&#x200B;

https://preview.redd.it/w4dnkvgyfrx61.jpg?width=2857&format=pjpg&auto=webp&s=e1cf4c94b21ff538669cc707f34f8218086be8a3",happyjunki3,2021-05-07 20:45:13,9,14,0.58
284,You have make some changes to the omniverse kit file if you have less than 11000MB of GPU memory.  I ran it on a RTX 2060 Super but it’s pretty slow and not really playable.  See link for more details: https://forums.developer.nvidia.com/t/gtc-2020-nvidia-marbles-rtx/123906/11?u=sltoscano,syntax22,2021-05-07 20:35:50,17,14,0.87
285,"Since I can't find the Corsair Hydro X Series XG7 RGB 30-Series Ventus water block in stock, I started looking to see if anyone else made one that was compatible with the MSI 3090 Ventus. This one made by Byski is all I could find: 

https://www.amazon.com/dp/B08Q7RL154/?coliid=I38M509AWX3DCN&colid=2P3TJE0LSSHHB&psc=1&ref_=lv_ov_lig_dp_it

I'm trying to find if anyone has a review (preferably in English) for this brand on this card, but I'm coming up empty. I was kind of confused that a water block for a card that's hard to get in the first place would be out of stock, but yet here we are.",NeauAgane,2021-05-07 18:32:39,1,5,1.0
287,"The Netflix app shows atmos as a sound format. The Nvidia website says Atmos is supported, but in the Nvidia control panel and in Windows there’s no mention of Atmos anywhere",Luna259,2021-05-07 19:41:55,3,21,1.0
288,"I am new to CUDA an recently i installed it on my windows pc.

I have been running a small test with some memcpy's and they weren't working. I tried running `cuda-memcheck tst.exe` and oh surprise there were errors.

This is one of the error i get (The rest are the same but with other functions like memcpy and launchkernel):

    Program hit cudaErrorUnsupportedPtxVersion (error 222) due to ""the provided PTX was compiled with an unsupported toolchain."" on CUDA API call to cudaMalloc.

My nvcc version:

    > nvcc --version
    nvcc: NVIDIA (R) Cuda compiler driver
    Copyright (c) 2005-2021 NVIDIA Corporation
    Built on Sun_Mar_21_19:24:09_Pacific_Daylight_Time_2021
    Cuda compilation tools, release 11.3, V11.3.58
    Build cuda_11.3.r11.3/compiler.29745058_0

Other command i found:

    > nvidia-smi
    Fri May  7 14:30:55 2021
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 470.14       Driver Version: 470.14       CUDA Version: 11.3     |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |                               |                      |               MIG M. |
    |===============================+======================+======================|
    |   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |
    | N/A   58C    P3    24W /  N/A |   1417MiB /  6144MiB |     33%      Default |
    |                               |                      |                  N/A |
    +-------------------------------+----------------------+----------------------+

Any help is greatly appreciated!

&#x200B;

Edit: 

Nvidia Forum Link: [https://forums.developer.nvidia.com/t/the-provided-ptx-was-compiled-with-an-unsupported-toolchain-windows/177328?u=a01704320](https://forums.developer.nvidia.com/t/the-provided-ptx-was-compiled-with-an-unsupported-toolchain-windows/177328?u=a01704320)",ber0210,2021-05-07 19:37:24,2,2,0.75
292,"Hey guys

I want to try evga's step up for the 3070 ftw3..

but how long is the queue? there does not seem to be a spreadsheet like the 3080 one

Is there even a point to trying this late?",ramenshoyu,2021-05-07 16:07:50,0,6,0.5
294,"hello guys, as many (of the quite rare) 3080 owners seem to struggle with this, i would like to share my experience with the memory junction temperature issue. my card is a msi 3080 suprim, but it should be more or less the same with other models (just make sure to use the correct thickness of the pads).

I had some issues while gaming: when the GPU consumed more power, the whole unit produced more heat (obviously). as a result, the VRAM junction temps climbed up to around 100 degree C. this might be within the expected range, however, my feeling is, that this will damage the VRAM on the long run, or at least let it die earlier. i heard that this issue gets way worse when mining, so i tried it. result was thermal throttling due to memory temps reaching the 110 degree mark. after some tweaking i was able to maintain 95MH without throttling with memory temps at around 108C. I read a few things about micron's gddr6x chips and found out that the presumably safe operating temperature of these chips is below 95C, however there was no further information if this is the junction or case. but nonetheless, cooler should be almost always better when it comes to longevity. so i decided to replace some thermal pads on the card, as the stock ones seem to be quite bad usually.

long story short, had great success. went **from 70MH with 94C TJ at 85% fans** (or 95 MH with 108C at 100% fans) **to 70 MH with 76C TJ at 85% fans** (or 95MH with 80C TJ at 100%). Or in other words: I got way more MH with lower temps and way less noise, when we combine things a little bit: 95MH with 88C TJ at fans below 70%.

At first i only changed the pads below the backplate (used 3mm 8w/mk, EC360) and added some small heatsinks on top of the plate above the VRAMs and VRMs. furthermore i optimized the airflow and added some fans on top of the card to move the hot air away from the backplate. this didnt change that much: at the same settings i got like 2 degrees less at max.

I used the card for a few weeks like that, with 75MH at 94C TJ just do be sure to stay below that 95C mark.

Today my new thermal pads arrived. went with 2mm and 1mm at 12,8w/mk from thermalright. I was a little worried because they seem quite hard when compared to the EC360 or the stock ones. i cleaned the card and cooler and changed the VRAM with the 2mm and the vrms with 2 layers of 1mm, as the stock pads seemed to be very soft 2mm ones (what a sticky mess, the stock pads sticked between the cooler fins). after repasting the GPU itself and mounting the cooler on the pcb again, i realized a quite heavy bending of the pcb and decided to open it up again. then i removed one layer of the VRM pads, but i am not sure if i managed to make good contact with only one layer. however, cleaned and added paste (mx2 btw) to the gpu again, made sure everything has as good contact as possible and mounted the cooler again. still some bending, but that was gone after adding the backplate again.

test results of my two reference settings:

&#x200B;

|settings|TJ before|TJ after|
|:-|:-|:-|
|70P, +0/+850, 100%Fan|108C|80C|
|50P, +0/-500, 85%Fan|94C|76C|

i am quite happy with the outcome, no matter how far i push the card now, i cant trigger any throttling due to memory temps anymore. I just hope that VRM mess wont do any damage on the long run. for the moment it seems fine, but dont know how hot these modules get under load as i cant find any sensor data about them. Does anyone know if they can overheat and if there is some safety mechanism?

The process was quite easy and i would recommend to try it out if you have problems with your VRAM junction temps. however keep in mind that this might void warranty and you might damage your card if you are not careful. i think it is quite a shame that these high end cards dont come with proper thermal pads. especially cards like the suprim series, where the cooling solution is actually the main selling point.",phsma,2021-05-07 13:29:30,0,5,0.5
296,"Taiwanese Gigabyte 3080 VISION owner discovered thermal pads placement issue. ([source](https://www.ptt.cc/bbs/PC_Shopping/M.1620363620.A.354.html)) 

[https://imgur.com/64FZdDF](https://imgur.com/64FZdDF)

According to the user, a shorter strip of thermal pad tailored for 3 VRAM chips was used on 4 chips, resulted in partial coverage (marked in yellow). Instead, an extra thermal pad was provided for a single empty VRAM chip slot (marked in red).

Though this might be a rare single incident, Gigabyte 3080 owners with unreasonable high VRAM junction temperature and low mining hashrate (50\~55MH/s according to the op) should check their thermal pads.",evl619,2021-05-07 09:03:51,17,22,0.83
298,"The ray-traced lighting is beautiful and brings a whole new level of realism to the game. So much so, that the odd low-resolution texture or non-shadow-casting object is jarring to see. If 4A opens this game up to mods, I’d love to see higher resolution meshes, textures, and fixes for shadow casting from the community over time.

But the under-appreciated masterpiece feature is the DLSS implementation. I’m not sure if it’s 2.0 or 2.1 since I’ve seen conflicting info, but oh my god is it incredible.

On every other game I’ve experimented with DLSS, it’s always been a trade-off; a bit blurrier for some ok performance gains.

Not so for the DLSS in ME:EE. I straight up can’t tell the difference between native resolution and DLSS Quality mode. I can’t. Not even if I toggle between the two settings and look closely at fine details. 

AND THE PERFORMANCE GAIN.

We aren’t talking about a 10-20% gain like you’d get out of DLSS Quality mode on DLSS1 titles. I went from ~75fps to ~115fps on my 3090FE at 5120x1440 resolution.

That’s a 50% performance increase with NO VISUAL FIDELITY LOSS.

+50% performance. For free. *Boop*

That single implementation provides a whole generation or two of performance increase without the cost of upgrading hardware (provided you have an RTX GPU).

I’m floored. 

Every single game developer needs to be looking at implementing DLSS 2.X into their engine ASAP.

The performance budget it offers can be used to improve the quality of other assets or free the GPU pipeline up to add more and better effects like volumetrics and particles.

That could absolutely catapult to visual quality of games in a very short amount of time.

Sorry for the long post, I just haven’t been this genuinely excited for a technology in a long time. It’s like Christmas morning and Jensen just gave me a big ol box of FPS.",Gred-and-Forge,2021-05-07 04:05:06,1152,486,0.97
300,"We all like to argue about how ""miners / gamers / etc are eating up *my* GPU supply"".  However, it's not exactly easy to determine where the GPUs are *actually* going.

I took the data available to us, and tried to make an educated guess on where GPUs are going. (All of the data I collected is available in ridiculous spreadsheet format [right here](https://docs.google.com/spreadsheets/d/1dSg4ywzDV-fhH2uZG6K3WArQGtPnREDYv9cxN-O-dHQ/edit?usp=sharing))

First off, a raw count of the GPUs that logged into Steam on a month-by-month basis. (EDIT: Fixed x-axis labels being off by 1 month)

https://imgur.com/ljwdiGc

This uses Steam's statement that they had 95 million monthly users in 2019, and 120.7 million monthly users in 2020.  Using that data, and extrapolating that user growth to future months, you can extrapolate the results of the monthly [Steam Hardware Survey](https://store.steampowered.com/hwsurvey/videocard/) into actual numbers.

Using those numbers, you can then calculate Ethereum-mining power of all of the GPUs on Steam, and compare that to the actual Ethereum mining that is going on at any given time.  

https://imgur.com/NCOBGCn

It appears that the sheer GPU processing power going to Steam gamers outweighed what ETH miners were getting...  

**...until sometime between March and April.  Since then, Steam gamers have apparently only been acquiring** ***less than half*** **the GPU processing power that miners are getting their hands on.** 

&#x200B;

**Of course, this data is not without** ***several*** **limitations:**

* It assumes linear monthly growth on Steam, which may not be true.  Also, we don't know if the 2019-to-2020 Steam user growth has continued through 2021.
* AMD's current-gen GPUs are so sparse that they don't even make a blip on Steam's Hardware Survey.  Is this due to truly low production, or are miners snatching them up *that much more* than gamers? As a result, I had to round the new AMD GPU numbers up to the minimum-reported percentage on the Steam Survey.  This means my numbers overestimate the AMD GPU mining power available on Steam.
* I had to extrapolate the numbers between a new GPU's release date and the month they finally logged into Steam enough to break into the monthly charts
* My data assumes that miners only mine Ethereum, and no alt-coins.  This means my numbers underestimate the number of GPUs going toward mining.
* Someone might use a GPU for mining *and* gaming.  There's no way to account for this.
* And plenty of other limitations, I'm sure.
* ADD: Doesn't account for ASIC mining.
* ADD: Stats don't account for AMD 570 mining, which appears to be substantial, according to HiveOS stats.  (though not a lot of 570s are likely being bought anymore, so these may have all been mining for awhile)",RxBrad,2021-05-06 21:29:45,34,71,0.73
301,In another comment thread on here there was a little mini debate between who’s the worst AIB so I thought let me ask the whole sub. Who do you think is the WORST AIB?,Dashurius,2021-05-06 18:05:08,11,120,0.68
307," 

To start I'm based in New Zealand so know that the price will not be comparable to US pricing due to the various taxes we have (amongst other reasons) There's a few specifics here so my apologies for the wall of text.

I initially ordered a 3080 gaming X trio in December of last year (roughly 6 months ago). I was placed in a backorder queue, and so I paid what was at the time a reasonable-ish price (1450 nz dollars, approx 950 usd).

Initially, the estimate was that the card would arrive some time in February, but was pushed back until May. At this point prices hadn't shifted much at all, but all 3080's from other manufacturers had a similar wait, so I chose to stick with my order and wait it out.

I'm sure some of you will have seen that gaming x trio orders from europe have been cancelled, with the gaming x trio being replaced with the marginally different, but drastically more expensive gaming z trio.

Following up with my store I've been informed that the overseas supplier was unaware if they would recieve x trio, or z trio cards for this shipment, but more importantly, the supplier stated that msi only gives the msrp for sale while the cards are in transit.

Today I received an update. The shipment to my store would be the z trio model, and that they would be far more expensive, although the estimate may increase further (and based on other store msrp's I'm inclined to agree).

The price I'm being suggested is 2203 new zealand dollars. Over 50 percent more than the initial 1450 dollar price I had expected and agreed upon back in December. 

The store I ordered from has made it clear that they have no part in the price increase, and that the increase in msrp is directly from msi.

\--

So here's my quarrel.

1 - I placed an order in the hopes that I would be able to attain a card at the price I paid for it, and get in before prices would increase if they did.

2 - If I had known msi had no intent of supplying me the card I ordered and intended to charge me more, then I would have cancelled my order months ago, and bought a different model, or order a card from another manufacturer.

Now I'm stuck in a situation where the entire market has increased drastically in price (To put this into perspective, most of the 3060ti models are now also in excess of 1500 nzd, they used to be around 900 dollars) My current options are to accept this new price, or go without the card that I expected for the foreseeable future.

Finally, (this isn't part of my quarrel as this is fully out of the hands of anyone else and entirely my fault. but it's part of the shitty reality of the situation.):

I ordered this gpu as part of many other upgrades (cpu motherboard and ram). I currently have a gtx 1070 which wasn't bottlenecked by my previous setup. If I had known the situation I wouldn't have needed to upgrade at all.

\--

My question is, is there anything I can do about this?

Is there anything I can do to achieve some compensation for the time wasted, or the lack of a product at the price it was listed at?

--

EDIT

I've been really surprised by the response this post has had, and at the very least it seems to have been the final straw in pushing some people away from purchasing with MSI in future. 

As for what I can do, thanks so much to those who have dug into NZ consumer law to see if there's anything I can do. I've looked into the consumer protection service, as well as called up the ministry of business, innovation and employment for advice, here's the gist:

The NZ retailer is not at fault (and I agree) they've acted in good faith and could not have reasonably predicted the circumstances. The fault is with MSI and possibly the supplier, but international companies are unfortunately outside of the reach of consumer protections for individuals in New Zealand (it would take hundreds of affected New Zealanders to pursue).

I have been recommended to ask the NZ supplier to meet me half way with pricing, as I've been patient and reasonable, and I've only really suffered for it despite their efforts. Whatever the price they would continue to add their markup, and (according to MBTI advice) it would be fair to cut into that markup to share the burden somewhat. That said I'm not sure how successful that will be. I'll keep you posted.",Raz0rLight,2021-05-06 09:40:41,1250,380,0.97
308,"Hi Guys i got lucky and got a 3080 FE and aside from Gaming i want to take some more profit from it.

So im a PC noob in general, i got a sence for technical thinks but that GPU and mining stuff is way too deep so i need some explanaitions and advises.


When i finished my build i wanted to undervolt anyways because i wanted the GPU to be more effficient.

so i Read some Tutorials and choose a Setting for Afterburner. I used  the Custom Curve and set it to 775mV and 1740MHz (i took it down and then press somting so the whole curve is nearly even)

I straight forward dont know what i have done .. but it takes less Watts and its cooler so i was fine with it.

sooo now im here and try to use NiceHash but at the same time keep my GPU Safe.

I did some research but i dont get it... so i think i ask u guys .

The Safety of my GPU/PC is at the 1st spot im not a pro miner but im very busy so if i can leave my PC on for like a week if im not at home or at night when i go to bed then im more than happy.. maybe i get some of my mony back or even make profit :)


ATM i try settings i find here on reddit  Powerlimit: 67% (Temp Limit 75% (Preselectet by Afterburner)

Core Clock -350 and Mem Clock +0 ( Did not change that) Fans Spining at 64% (dont want to go much higher if its not nessesary because of that noise ...) But i put therefore i put the casefans at 1200 rpm 

 The Nicehash ""Shell"" shows between 78,xx to 85,xx at Hashrate / Eff/Watt around 390-395

Temps are 

GPU max. around 50c Hotspot 63c and Memory is like 88-90 (AVG 89.7 atm) i have seen 1-2 peeks at testing the settings but now its like solid 90 since more than 1 H 

Board Power Draw Shows 210-214W

So What more can i optimise?

and whats about my power consum and temps? are they any good? is 90c ok for the long run and safe?.. i read many thinks about the DDR6X getting too hot on the 3080 FE and that some people done the Termalpad mod from IgorsLab.

I also read that nVidia has secretly adress that problem and the newer productions already get fixed with termalpads so a Mod is no longer neccessary..? i ordered mine GPU at February of this year and got it in March... so i think its safe to asume that i got the new revision that are fixed right?

anyways, is the Mod still better (maybe nVidia used cheap and crappy thermalpads) how much would the Temperature benifit? and whats about the warranty is it gone when i replace the pads?

sry maybe i put to many topics in that one Thread but i hope its ok like that.

Thank a lot in advance!  I appreciate your help guys Cheers! :)",TheAbuReem,2021-05-06 09:20:11,0,28,0.47
310,So for some people the most common build that i see is for some people on a budget is the 1050 or 1080 but in my case they pay around 250 for the card in recent prices but one card that is overlooked is the 1660 as the card needs a little more attention as it's the most common in laptop builds but not in home built systems for the same price to around 600 (since prices went up) this card is a last stand before rtx came into play I love this card as it holds it's ground when playing some of the toughest games at max settings which is incredibly successful but it's overshadowed by its little brother a little too much. I have the MSI 1660 oc armour as this card is a great little thing to overclock at times when needed runs vr titles like a dream too with little stutter more or less I would take a look into grabbing one of these little wonders as they are like I said overlooked on budget builds as they hold up really nicely,OriginalInstruction1,2021-05-06 02:22:52,0,10,0.17
311,"*I posted the same in r/NZXT but couldn’t get any response so reposting here. Any help would be appreciated.*

So I have seen some post where folks have put Asus TUF 3070 (or its equivalent like gigabyte 3070 gaming OC) in their NZXT H210. I have a chance of getting the mentioned GPU at a decent price but I am worried about the temps since it will almost touch the PSU Shroud (I have an ATX PSU). The ambient temperature where I live is around the 27-32 celsius range (right now, in summer). Since the availability of GPU is so short and this is a limited time deal, can anybody let me know if I should go with it?

Also, I would surely undervolt the card to reduce the temperature. Thank you so much for the help :)

Update: So I pulled the trigger and bought the TUF 3070 Oc. Will update once I get my hands on it. Thank you to everyone who replied. :)",samtlink,2021-05-06 01:35:59,6,23,1.0
312,"[ Fourier Transform In Python Using Numpy.fft](https://pythontic.com/visualization/signals/fouriertransform_fft)

This problem has been solved using NumPy. Do you know how to solve this using CuPy ? I'm learning CUDA right now and stumbled upon this problem. Would really appreciate all your help.

(GPU : RTX 3090 Founder's Edition, CUDA : v11.2, Jupyter Notebook : v6.3.0, Python : v3.9.4, NumPy : v1.20.2, SciPy : v1.6.3, Matplotlib : v3.4.1, CuPy : cupy-cuda112 v9.0.0 and SymPy : v1.8)",eastsideseattle,2021-05-06 01:16:18,5,3,0.86
313,"Hi, I cant choose between MSI GF65 10UE with rtx 3060 75w and MSI GE66 with rtx 2070 non max-q. Which one will perform better in 1440p (external monitor)? Any help appreciated",hungry_ape,2021-05-05 21:08:46,1,14,0.6
314,"Hello there guy's i've been wondering if they forgot me, if the system didn't get my request for the step up program or I just need to wait again.

I did all i had to do properly to get in the queue, i received an e-mail saying I am in the first step of 5 but it's been since  Wed 2020-10-07 10:29 AM that i received that e-mail and still got nothing, I even got  **EVGA** **Product Availability Update Notification – 10G-P5-3897-KR** that was reserved for me when i did the notification on release (way before I did the step up program) 

And of course i didn't want to buy the card since I already paid the rtx 2080 so here I am thinking they forgot me.

&#x200B;

Anyone of you can help me out?",Dreamruiners,2021-05-05 19:17:06,0,24,0.46
317,"So I had noisy fans on my Zotac 3080 AMP HOLO

And contacted Zotac to replace some of my fans and the told me they would send whole unit which is 3 fans and the cooler which perhaps cost like 200€ on local market.

The replacement part is already heading my way, without me sending in whole card and waiting forever. Unlike Asus that didn't provide any replacement fans for one noisy fans I had with Asus Strix 3080 OC as they told me to send in whole unit, which I disagreed.

I know everyone likes to shit on Zotac for any reason, but this is at least some positive outcome.

And now this isn't shilling for Zotac as I have proof if needed.

P.S.

No I dont have two cards at the same time btw.

also why the downvotes ?",Molasses100,2021-05-05 16:24:51,12,17,0.68
318,Has anyone tried this pad instead of paste on their GPU?,Fluid_Study_2339,2021-05-05 15:57:22,5,40,0.78
319,"Being a desktop gamer, I don't follow whats going on in the laptop world.  

I'm curious about getting a gaming laptop.  From my cursory research, its seems the biggest limitation of mobile RTXs is power and cooling.

I can't seem to find much benchmarking.  But how does a mobile 2080 super at 150w (with its own separate power brick) compare to a mobile 3080  running at 100w or less??

Clarification: I know laptop gpus will never compare to desktop, which is why I did not ask how they compared to desktops. I have a desktop for that purpose.  I'm merely asking for comps from various flavors of mobile RTX's since there doesn't seem to be a whole lot of info out there.  Specifically if there is huge difference between a mobile 2080 vs 3080, which by the little info I have dug up does not seem to be, and does not justify the huge price difference.",buttscopedoctor,2021-05-05 15:44:52,2,12,0.75
320,"Hi! I'm looking for a decent gpu, but not too pricey. I was looking for a RTX 3060 Ti (msi ventus 2X), but it was a bit over my budget.. So I thought a rtx 2070 would be nice, but it was too expensive!! Do you guys think it is a good idea to buy a msi geforce rtx 2060 super gaming x?",Ahegao_4545,2021-05-05 14:35:35,5,35,0.65
321,"Hi,

i could get my hands on one of the both cards, to the same price.

I dont know what to do. From what i hear, ASUS has the better card design, better cooling system und better OC performance/general performance, but a really really bad customer service.

EVGA has a good customer service, from what i read on reddit.

But im based in the EU in Germany, so i dont know if thats the case or if this good customer service/bad customer service-thing only applies in other countries.

Could you please help me ?

Thank you !",Tight-Savings-1784,2021-05-05 14:26:36,3,13,0.64
322,"Hi guys,

I need help. I recently changed the thermal pads on my 3080 Suprim X, the temps kept getting higher overtime and since after mining it would be good to have her around a few more years so I tried to do some good for her.

So, I changed all the pads for the Grizlly's, on the front for the VRAM made 2x 1mm on top of each other (couldn’t find 2mm available), I made it on top of each other because it worked for a friend of mine Gigabyte 3080’s.

For the other's 1,5mm I made the same, 1mm and a 0,5 on top of each other too.

For the back plate I rand out of 0,5mm pads so I made it with 4mm(4x1mm) witch I saw some guys doing it on some videos aiming to put a bit more thickness even if the backplate offers a bit of resistance to attach or bend a little.

Result: Made it worse, A LOT worse. It now jumps quickly to 100ºC and a few seconds later 110ºC overthortling.

What I did after as reduce 1mm on the back plate making it 0,5mm thinner dan the original 3,5mm could be a pressure problem but no, still the same.

Is adding layered thermal pads a huge mistake? Does it make it hotter?

I intend to change the front one’s(VRAM’s etc..) to Iceberg Thermal DRIFTIce Thermal Pad 2.0mm and 1,5mm to get the right thickness on one pad.

And for the backplate add Thermalright Thermal Pad 3mm and the same 0,5mm on top of each other to achieve the 3,5mm original size.

Is this a better path?

What do you guys think? Did any of you ran across the same problem?

Thank you in advance.

\-------------------- UPDATE -------------------  


I ordered some new pads for the front VRAM with the right thickness but while the wait for them to arrive we did something crazy:

[MrDankky](https://www.reddit.com/user/MrDankky/) suggested to open the GPU and see if all pads were squeezed and we opened the GPU again and saw 3 pad's weren’t squeezed by the chip's including 2 of the 2mm VRAM even with layered pads to achieve the right height, and 1 pad in the middle of others. So we added 0,5 to all VRAM pad witch did 2,5mm on VRAM and added +1mm to the other pad not squeezed. 

Results: 

Stable temps on VRAM memory on 88º/90ºc spikes sometimes to 92ºc but the room temp tends to get higher during day around +4ºC. ( before pads 99º/100ºc and in the first wrong replacement instant +110ºc)

Although the GPU Core temp raised from a averaged 43º to 55º but stable ( maybe the height of 0,5mm+ doesn’t let the core be totally squeezed in the dissipator?) and the GPU hot spot temperature is in 74º stable too. 

So I did the test and let her mine over night and all stable so far. 

What do you guys think? Should I let her like this for now even when the new pad's arrive as long as it keeps this temps stable? 

I didn’t mind testing over and over new things but the price on the pads and the pain in finding stock doesn’t make this operation fun. So as long as its keeps this way Iam thinking in letting her like this.  


Thank you all for the ideias and comments, learned alot! ",LegoPixel,2021-05-05 13:48:39,1,24,0.55
323,"Hey all, I’m looking for a monitor suggestion not sure if I should go 1080p 144hz or 1440p 144hz my specs are 

Rtx 3070 gigabyte gaming oc 8gb
I7-9700k
16 gb ram 
 
Thanks I’m advance all!",CoolSp00ns,2021-05-05 13:46:45,3,31,0.72
324,Do we expect the temps to creep back to stock levels or do we think they can stick around making a new long term baseline?,Either-Researcher681,2021-05-05 12:21:11,2,8,0.63
325,"I know, there are plenty of 3080/3090 undervolt threads already but I'm pretty sure none of the awesome results presented are actually stable using the CUDA, Tensor and RT cores at once.

On raster benchs my 3090 can happily do 1840 / 0.8v all day. But with everything active at the same time (Cyberpunk 2077, and to a less extent Control are the best tests imho, let's see tomorrow if Metro can be even worse) I can barely do 1710 / 0.8v.

What are your best perfectly stable RT+Tensors+CUDA undervolts ?",JustFinishedBSG,2021-05-05 12:21:02,20,83,0.74
327,"i got this asus gtx 1660 ti asus dual oc model and i have to say that the heat sinks and fans on this card are an absolute joke i wonder if they even do anything as my temps are around 80 sometimes spike up to 88...  
anyways i'm looking for a good aftermarket cooler that will fit on my card, any good advise ?",noobProgrammer_2000,2021-05-05 07:25:06,6,10,0.75
328,"I ordered a 1080ti recently but I do not have a clue which one it is. Does it matter if it's gigabyte, Asus, MSI, evga etc? Will it mean it might not be compatible with certain things?

Sorry if it's a stupid question I have very basic knowledge about this.",Yourlolm100,2021-05-05 06:20:26,11,27,0.76
329,"Intel has what they call  software developers manuals that go into great detail about the details of their architectures. For example you can find some of them here:

[Intel® 64 and IA-32 Architectures Software Developer Manuals](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html)

They also have documents about how to optimize for intel processors:

[Intel® 64 and IA-32 Architectures Optimization Reference Manual](https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-optimization-reference-manual.html)

Is there anything similar for nvidia gpu's? In particular, for the Maxwell line of GPUs would be ideal. I can't seem to find anything specific to Maxwell that is substantive.",maxmax4,2021-05-05 03:12:21,12,6,0.87
330,"I repadded 3090 FE but the Memory Junction temps are still 104-106, I see people are adding heatsinks to the backplate with good results. 

I have Arctic Accelero Twin cooler that I am not using. Would it work as a cooler? 

Has two fans on top and bottom that looks [like this](https://images-na.ssl-images-amazon.com/images/I/51vOyWWVQRL._AC_SL1000_.jpg). I  guess I could just stick this copper into the backplate via a thermal pad. However I am not sure how I could actually secure the Accelero on the backplate, the thermal pad is obviously not adhesive enough.

Or should I just use a strong adhesive tape? In this case  I am concerned that the vibration from the fans will eventually move the heatsinks.. 

Any insight is appreciated.",myreptilianbrain,2021-05-05 01:29:59,0,33,0.5
333,I just scored a 3060,yAmIDoingThisAtHome,2021-05-04 19:42:20,21,40,0.89
334,"I got a problem with undervolting my ASUS RTX 3070 Dual OC.

Whenever I set up my clock curve, it still boost up to 30 Mhz (2 bins) higher then my settings are.  
Im running it @ 900mv and 1890Mhz and it sometimes boost up to 1920 and then it crashes. It never crashes @ 1890Mhz or 1905, but sometimes at 1920Mhz.

Maybe there is a setting for this behavior?",Tschungle,2021-05-04 19:20:04,6,11,0.76
336,"Follow up to this post [here](https://www.reddit.com/r/nvidia/comments/n476c4/1080ti_or_2080/?utm_source=share&utm_medium=ios_app&utm_name=iossmf), another card has been offered to me this time it’s an EVGA 2070S Hybrid Water Cooled for just £20 under. I’m coming from a water cooled RX Vega 64 so I’m sceptical of how cool & quiet modern air coolers really are - which would you choose?",idontbuygames,2021-05-04 16:30:56,4,7,0.83
337," 

i'm setting my eyes on a gtx 1660 super rog strix gaming, however most important thing for me is fan noise since it's in my bed room and i can't find any reveiw for that so any clues ?",noobProgrammer_2000,2021-05-04 16:10:43,2,11,0.75
339,"Can the zotac 3070 amp + 10900k hit 360 fps in fps games like rainbow six ? Low setting


Edit: yes i got 405~410 fps on low setting 1080p",Delicious_Plantain28,2021-05-04 10:51:31,2,16,0.55
340,"Anyone with this monitor has tested g-sync?

Hi, Im planning on going 1440p 144hz 32in with an rtx but its impossible to find a monitor thats officially g-sync compatible where I live. Ive found mixed information on the g-sync compatibility of this monitor like here:

 [G-SYNC Compatibility Test: Using FreeSync Monitors With An NVIDIA Graphics Card - RTINGS.com](https://www.rtings.com/monitor/tests/motion/g-sync-compatible) 

Where it says its not compatible but Ive seen a couple of people on forums saying it works. I dont want to buy it and find out theres something wrong. Its honestly the best monitor option ive found with these specs and the lack of concrete info on g-sync compatibility is making me crazy, thought I should make a post for someone to finally answer this for the future. Any help please?",AlexZuni,2021-05-04 03:37:29,1,13,0.67
341,"I would like to program the RGB on my MSI 1660 Super Gaming X GPU in a way that it never turns on. Even on cold boot.

Actually, using OpenRGB, I can turn off the lights. But if I turn the computer off then on again, the default Rainbow mode is loaded before even going to Windows. What software can save the settings ""on"" the card?

My previous GPU, an Aorus RX 580, kept the RGB settings even after removing the card and putting it on another computer.

Edit - Solution:

Tried Mystic Light 3, but it doesn't detect the 1660 Super. Tried Dragon Center, but it doesn't write the data _in_ the card's memory. So it always resets when you turn off the computer. Finally, I removed the RGB plugs from the PCB. There are two of them on the MSI 1660 Super Gaming X. One on each side. They are small and black.",DarthJahus,2021-05-04 01:23:20,2,12,0.67
342,"My goal here is just to make sure  there aren't crazy regressions in performance from one version to the  next. I try to test DX11, DX12, Vulkan, OpenGL, DLSS, and RT with a  focus on getting results for 4k resolution, as my target in most games  is to run at 4k with minimum FPS around 55-60.

&#x200B;

I  don't do any frametime analysis or any of that. I don't intend to  either. I most likely could never do as good a job as the other  benchmark posters here anyway.

&#x200B;

I do repeat tests if I see results that might be outliers in order to confirm results.

&#x200B;

Stock means stock clocks but changes in nvidia control panel (set power for max performance, disable g-sync).

&#x200B;

oc means bumping up power limit to 107%, temp limit to 88, mem clock +200, and a core clock curve generated by MSI AB.

&#x200B;

&#x200B;

[ Core clock v\/f curve generated by MSI AB ](https://preview.redd.it/78b2rsf870x61.png?width=796&format=png&auto=webp&s=3dddb304047af86ae2c03f93c4cc578867ef9fa3)

 

I do my best to keep everything the same for driver version to driver version comparison. Minimal background processes, etc.

&#x200B;

I  don't re-do my benchmarks with upgrades other than GPU drivers for the  most part, though, so its possible software upgrades, windows updates,  or BIOS updates could have some effect here.

&#x200B;

Have uninstalled prior drivers etc with DDU for as clean as possible install.

&#x200B;

System Specs:

* EVGA GeForce RTX 3080 XC3 Ultra
* AMD Ryzen 7 5800X
* 32GB RAM - Crucial - DDR4-3200 - dual channel
* Gigabyte B550 Vision D - Bios ver. F12
* Samsung 980 Pro NVMe - Pcie 4.0 speeds
* Windows 10 version 20H2 build 19042.928
* Resizable BAR is enabled/possible (although probably doesn't impact any of these benchmarks as far as I know)
* HAGS is disabled in windows display settings

&#x200B;

Tests I run:

* 3DMark DLSS - 4k - performance
* 3DMark DLSS - 4k - quality
* 3DMark - Port Royal
* 3DMark - Port Royal - 4k
* 3DMark TimeSpy
* 3DMark Time Spy Extreme
* GFXBench Aztec - High - 4k - DX11
* GFXBench Aztec - High - 4k - Vulkan
* Heaven - Extreme - DX11
* Heaven - Extreme - OpenGL
* Superposition - 4k Optimized - DX11
* Superposition - 4k Optimized - OpenGL

&#x200B;

Here are some results.

&#x200B;

466.27 - stock

* Average comparison to prior (466.11) drivers: 99.91% (negligible decrease in performance) 

&#x200B;

[466.27 - stock - with comparison to previous driver release \(466.11\)](https://preview.redd.it/nwzzfucz70x61.png?width=619&format=png&auto=webp&s=04f7f0d1293b50c2f43686e3b0ebb106f0e5f1b3)

&#x200B;

466.27 - oc

* Average comparison to prior (466.11) drivers: 100.00% (no change in performance)
* Average comparison to stock clocks/settings: 103.37% (slight increase in performance... approximately +2FPS at 60 FPS)

&#x200B;

[466.27 - oc - with comparison to previous driver release \(466.11\) and stock clocks\/settings](https://preview.redd.it/c74socvx80x61.png?width=820&format=png&auto=webp&s=f9111ced4b1919bfacb2bf878adff5f7195ce556)

&#x200B;

Conclusion: no meaningful regression in performance with 466.27 driver release.",Whiteboyfntastic1,2021-05-04 01:19:13,55,15,0.9
343,"[This PC](https://www.amazon.com/Dell-7020-Performance-Desktop-Computer/dp/B08BS123FW/ref=sr_1_21?dchild=1&qid=1619550977&refinements=p_n_feature_five_browse-bin%3A13580790011%2Cp_n_feature_four_browse-bin%3A2289792011%7C2289793011&rnid=676578011&s=pc&sr=1-21) is what i am looking at (Please dont lecture me about how bad it is, i am NOT looking for super computer graphics, If something with more powerful goes for about the same price, ill get it). I just would like to know if it is a DDR4 or GDDR5 GT 1030, if possible at all.",Bill_Cipher42,2021-05-03 22:26:57,0,27,0.43
344,"I have a Dell OEM 3080 with short cooler that they put in the Alienware systems coming to me. I also have a MSI 3070 Ventus 3x OC in my current system. What I would like to do is change out the coolers, if that is possible... I believe the Dell 3080 is a reference design built by MSI, just a different shittier cooler to fit a small case.

So, I guess that's the question, can I move the cooler on the 3070 to the 3080 and vice versa?

Some pics of the Dell 3080: [https://www.reddit.com/r/Alienware/comments/m8k0rh/alienware\_3080\_adding\_paste\_to\_memory/](https://www.reddit.com/r/Alienware/comments/m8k0rh/alienware_3080_adding_paste_to_memory/)",FlyPenFly,2021-05-03 21:12:12,1,5,0.6
345,"Hi I’m torn between buying an EVGA 1080ti SC2 Hybrid and a PNY 2080 XLR8, on paper the 1080ti seems to be more powerful however it’s 4 years old now so would I be better off buying the 2080? There’s a £50 difference in price and they’re both used. Thank you",idontbuygames,2021-05-03 20:59:40,1,25,0.57
347,"Hi r/nvidia,

I built a new computer about a month ago, and I have my heart set on a MSI GeForce RTX 3070 Gamer X Trio, but today's Newegg Shuffle features a Gigabyte Aorus 3070 Master. Should I wait on the MSI card or pull the trigger on the Aorus?   


I've looked for comparison videos and on [versus.com](https://versus.com), but nobody compares these two cards specifically.",Plato_Karamazov,2021-05-03 18:18:27,6,12,0.71
348,"Anyone having success with Nvidia Performance Overlay? I am new to this but not trusting what I see.

Control w/ full ray tracing - 59-60 fps.

Control w/ medium ray tracing - 59-60 fps.

Control w/ no ray tracing - 59-60 fps.

Am I doing something wrong?",CanisGenome,2021-05-03 18:19:05,2,9,0.58
350,"Hello everyone!  
I'm an Industrial Design Engineer on the search for a workstation laptop for professional use that will replace my current desktop (AMD 3900x + 2080 Super). I want a laptop for 3D modeling and rendering.  
I am constantly travelling for work and currently, I'm using my desktop through ""Chrome Remote Desktop"" which enables me to share screen and use the PC wherever I am. The issue with this method is mainly the dependency on the internet connection. Therefore I have decided to sell the desktop and buy a laptop. I use **Solidworks** and **PTC Creo** for 3D modeling and **Keyshot** for rendering. I am not going to use the pc for gaming or any other thing rather than these 3 softwares. I would like to have a 2k/4K screen to be able to see in detail the image renderings. I am not interested in the touch options some manufacturers give. I also don't care about the weight of the laptop. I prefer big and bulky with excellent performance, rather than thin and low performance.   


Requirements:  
\- Run as similar to my current desktop as possible or even better!  
\- Smooth running in Solidworks/PTC Creo  
\- Keyshot BEAST  
\- 1TB ssd  
\- 2k/4K Display  
\- 15"" or 17""  
\- Around 4-5$K Max  


I've done some research and I think the best setup would be a AMD CPU with RTX Quadro GPU, but cant really find a laptop with those specs. So I should get an i9 with RTX Quadro or an AMD with Geforce RTX. Therefore I don't know what is better for my case, as I use Keyshot mainly on CPU.  
Geforce looks to be more for gaming and the RTX Quadros more for the tasks I'm looking for. But maybe the newer RTX 3080 can outperform the Quadro RTX 4000/5000  in Solidworks and PTC Creo? As I've said before, this is the only use I will be giving the laptop.  


Also, on the MSI website, the workstations they offer have intel chips. And basically, any other manufacturer who offers workstation laptops also do. But AMD are better? 

Laptops I have checked already:  
\- Asus ROG Strix G533 15""  
\- MSI WS66  
\- XMG NEO 15""  
\- Asus ZBook Studio G7  


I'm a bit lost here with all the options there are, but I don't know which combination would be better for my case. If AMD + Geforce or Intel + Quadro RTX. And also which models would be better for the use I am going to give the laptop.  


My current desktop setup works fine, except sometimes it freezes if I create a big pattern in PTC Creo, for the rest, a beast in Keyshot and no problem in Solidworks.  


Any help would be much appreciated!",maurogb96,2021-05-03 16:49:49,2,7,0.62
351,"Hello,

I've recently bought my new gaming PC which i assembled qucikly due because of a GPU drop in my local retail shop and i've only managed to find the MSI SUPRIM (non x) RTX 3080  and the gaming x trio so i've decided to go on the suprim.

I've barely seen anyone actually using that card, what's the difference between the X and non X?",Duke_of_Judea,2021-05-03 13:03:22,0,10,0.38
352,Can anyone tell me the warranty for a Palit 2060 in the UK please? I think my GPU died and I'm in the process of ruling out other components before I try and RMA it. I bought it in February 2019 so it's just over 2 years old.,billyb1987,2021-05-03 12:35:17,1,5,0.67
353,This is Gigabyte GTX 980 G1 Gaming in good condition that wasn't used for mining.,And_Poop,2021-05-03 09:41:27,1,18,0.57
354,"I currently have a PC running with a GTX 750 Ti (2gb), and while it has served me well the past 6 years, I think it's time for an upgrade.

I'm not super versed into GPUs and all, all I know is that they can be expensive and are in short stock due to Crypto Mining.

So my questions are:

1) What is a mid-range, reasonable upgrade? I don't really need anything super high-end.

2) What do I need to check for compatibility before I pull the trigger? I mean, I imagine it at least hast to be compatible (and fit lol) with my motherboard.

3) Will an upgrade like this require me to reinstall my OS? I'm currently running Win10

Thank you very much and have a nice day!",USS_Phlebas,2021-05-03 09:14:26,17,25,0.77
357,"Just wanted to share my results with repadding/repasting my RTX 3080 FE which I bought back in November. I admit I also use it to mine but originally bought it for gaming and 3D work (and still do) but wanted to earn some of the cost back.

I was really scared of doing it (voiding warranty, breaking something) but thank god all went well. Wasn't even that difficult (even though I did mess up some things) and took me like 3hrs total.

Results:

**Before**: Gaming: Certain games would reach/exceed 96C which is above my personal limit. And this is while undervolted. 

Mining: I had to limit power to 50%, fans 60% and core/mem clock underclocked to the max (-500 MHz) to not exceed my personal limit of 94C VRAM temp. I got like 50Mh/s but felt safe doing this. Anything above 55% power or so would reach/exceed 100C.

**After**: Gaming: Haven't had a game reach above 84C or so yet, have yet to test it more thoroughly. GPU temps roughly the same or slightly higher, never above 70C or so (still undervolted). I believe the reason it's slightly higher sometimes is either because the memory now better spreads the heat across the card or the thermal pads reduce the pressure on the die a bit. 

Mining: 70% Power, 65% Fans, Core +0, Mem + 650MHz for an incredible 90 Mh/s @ 90C closed case, 84C open case! Incredible results, literally doubled my hashrate while lowering my temps.


The official pads seem to really suck ass. I used Gelid Extreme 2mm for the front/die side and 3mm for the back. On the sides I also used 1.5mm of some other thermal pads I had lying around as I ran out of the 3mm. Thermal paste I used was (too much of) Arctic MX-4.

I can really recommend this to anyone that cares about his card and does not mind risking the warranty. Ironically, I believe the card will last much longer this way and there will hopefully be no need to deal with the potential RMA process. Especially now that cards are sold out everywhere, I can not see it not being a pain in the ass.",g3ck00,2021-05-03 08:28:50,2,3,0.57
359,"Hey guys! 

I got 2 144hz monitors and I’m wondering if I should connect both to my GPU or one in the GPU and one in the motherboard? The GPU is a 1070 TI.

My second question is, is it that much more demanding to run 144x2 compared to one 144 and one 60hz monitor setup?

My PC build is:

I7 8700k
1070 TI
16GB DDR4
Z370 SLI Plus Motherboard
Samsung 960evo 500 GB SSD

Thanks!",Kalleac,2021-05-03 06:32:45,5,6,0.77
361,"Hi all,  I have never modded a GPU before but my 3090 FE is thermal throttling when ray tracing scenes in Blender due to hot VRAM temps (fans ramp up to 100%...). Would there be a difference if I only replaced thermal pads on the back of the GPU and not full re-paste GPU and front VRAM?

Has anyone done this and if so do you have any temp comparisons you could share? I am a bit risk averse and don't want to do a full re-paste / re-pad mod...",chrisredditcommenter,2021-05-02 20:27:38,2,30,0.6
362,"I just wanted to make this post so you don't make the same stupid mistake I did.  I followed all the guides I could find online and had all the settings correct.  But when I would play the recording on my PC, it was all washed out and dull.  I couldn't figure it out.  Wrong settings in Shadowplay? Maybe I should switch to HDMI instead of my Display Port? Is something wrong in the Windows or Nvidia Control Panel Settings?  I tried everything!

You know what it was?  I like to use GOM Player for my videos.  I just like the interface and such.  Today I thought, let's try another player.  Windows Media Player, no picture.  Then I played the recording in VLC Player.  PERFECTION.  I just figured this out.  IDK why VLC played it correctly.  I haven't researched it.  I am sure there are other players too.  But I am so happy.  This has bothered me for awhile, so I gave up playing and recording HDR awhile back.  Now it works.

\[insert meme pic here\] It always has been lol.  Hopefully this will help someone else out too :)",MJCbAdAsS,2021-05-02 15:59:37,6,4,0.87
363,"Hey so I scored a 3060 through the Newegg shuffle and it’s replacing my old faithful 1080 TI.  Sort of a side grade there but I’m looking forward to DLSS and Ray tracing, ReBAR support.

Question is are there any water blocks compatible with an EVGA 3060 XC?  The review on Tom‘s hardware claimed it was an identical PCB to some TI and 3070 models.  I have a 360 mm radiator custom loop set up and I’d hate to have it only cooling my CPU now.",ruggercb,2021-05-02 14:20:20,0,12,0.44
366,"Hello all,

I have the Asus MG279Q monitor which supports FreeSync, but if you do a quick websearch you'll notice a lot of users online have frequently had issues when you try to enable it as a GSync Compatible monitor (E.G. graphical distortion, black screens, etc...)

I believe I have resolved these issues and I just wanted to post my findings for anyone else who finds themselves trying to get this working properly in the future too :)

I have placed a copy of the custom Driver file I based my instructions off (as well as another copy of these instructions) in the following link:

https://drive.google.com/file/d/1osjXAM00v_rHXyewBCNm86vBAsmD8RMO/edit

Hopefully this helps someone else down the road!

***

*Note: These instructions are meant to setup the MG279Q monitor* ***when using an Nvidia Geforce video card***. *These instructions leverage the ""GSync (Compatible)"" functionality which in turn leverages the Freesync functionality of the monitor.*

*My Testing System Details:*
*OS Detail: Windows 10 Pro, Version 20H2, Build 19042.964, Windows Feature Experience Pack 120.2212.2020.0*
*GPU: EVGA XC3 3080 Ultra, Geforce driver 466.27 (released 04/29/2021).*
*Monitor: MG279Q with Mini-DisplayPort to regular DisplayPort*

*(Additional FYI - I originally had minor horizontal flickering issues with GPU & monitor @144hz BEFORE trying to enable the ""Freesync"" / ""GSync Compatible"" feature. Switching to a Mini-DisplayPort>DisplayPort cable seemed to resolve this issue for me)*

***

# Setup Instructions for Nvidia Cards / GSync:

- First, enable FreeSync in your monitor's menu (if it isn't already enabled).
	- Note the monitor will always show a black ""FreeSync Disabled / can only be activated between 35-90Hz"" warning when Freesync is enabled. 
	- This is normal, and the message can be disregarded. When this is all setup, you will be running near a ~144hz refresh rate dispite this warning.
- Included in this zip is a file named ""**MG279Q-57-144-ACI27A7.inf**"". 
	- This is a custom Freesync driver that was originally created for AMD cards. We'll need to install this driver as a starting point.
		- *Note: If this driver is installed as-is with a GeForce card setup and GSync / FreeSync is turned on, it can lead to (black) screen flickering issues for Nvidia cards. It will need some further customization which is detailed below.*
	- To install the driver, you'll need to reboot into Windows with Driver Signature Enforcement turned off. To do this:
		- Click Start > Power. Then hold ""Shift"" on your keyboard while clicking ""Restart"".
		- Click Troubleshoot > Advanced Options > Startup Settings > Restart (button).
		- When the PC reboots / when prompted, select the ""Disable Driver Signature Enforcement"" (#7).
		- When Windows has loaded, from the start menu search for ""This PC"". Right-click on the icon and select ""Manage"".
		- Click ""Device Manager"" on the lefthand side, expand ""Monitors"", right-click on your monitor (likely called ""Generic PnP Monitor"") and choose ""Update driver"".
		- Click ""Browse my computer for drivers"" > ""Let me pick from a list of available drivers on my computer"" > ""Have Disk..."" (button)
		- Browse to location of the ""MG279Q-57-144-ACI27A7.inf"" driver file and click OK, then click Next. 
		- When prompted, click ""Install this driver software anyway"".
		- The driver should now be installed - reboot your PC as you would normally. 
- Change your monitor's refresh rate in windows:
	- Right-click the desktop, click ""Display Settings""
	- Click ""Advanced Display Settings"" (towards the bottom)
	- Change the Refresh Rate to ""143.856"" in the dropdown menu, then you can close this window.
- Next, download the CRU app from here: 
	https://www.monitortests.com/forum/Thread-Custom-Resolution-Utility-CRU
- Launch the CRU application (run as administrator). In upper-righthand corner, click the ""Edit..."" button.
	- In the ""Range Limits"" field, make sure the info looks like the following and click OK afterwards:
		- Vrate: 57-142Hz
		- Hrate: 135-135kHz
		- Max pixel clock: 590Mhz
	- Click the ""OK"" button at the bottom-right of the CRU application when finished to apply changes.
	- Next run the ""restart64.exe"" file that comes with CRU to restart your video card driver and apply the above new changes.
- Next, launch Nvidia Control Panel.
	- Navigate to ""Set up G-SYNC"" on the lefthand side.
		- Click ""Enable G-SYNC, G-SYNC Compatible""
		- Select ""Enable for full screen mode""
			- *Note: The MG279Q doesn't work well/properly with windowed applications - always run your applications fullscreen when using Freesync/GSync*.
		- Select ""Enable settings for the selected display model"".
	- Navigate to ""Manage 3D settings"".
		- Set ""Max Frame Rate"" to ""141"".
			- *Note: For those curious, this seems to be needed (I.E. forcing the max allowed FPS in the driver to be limited below the monitor's native 144Hz) because of some rounding-up of the framerate/refresh rate that ends up pushing past the monitor's refresh rate - that is what leads to the weird artifacts you can see. Setting this value to 1 FPS below the CRU's custom max range (142) seems to keep things in check.*
		- Set ""Monitor Technology"" to ""G-SYNC Compatible"".
		- Set ""Power management mode"" to ""Prefer maximum performance"".
		- Set ""Preferred refresh rate (Ancor Communications Inc ASUS MG279)"" to ""Highest available"".
		- Set ""Vertical sync"" to ""Use the 3D application setting"".
- Reboot your PC.
- Next, download and install Nvidia's Pendulum Demo - this can be used to verify FreeSync/GSync is working properly with no visual artifacts.
	https://us.download.nvidia.com/downloads/cool_stuff/demos/Setup_G-SYNC_1.13.exe
	- Wait 1 or 2 minutes after windows starts up before continuing to testing with the Pendulum demo (I.E. I noticed the FreeSync/GSync settings didn't take effect right away after a reboot).
	- Launch the Pendulum Demo, selecting the monitor's native resolution (2560x1440) and selecting ""Fullscreen"".
		- When running the demo, make sure that ""GSync"" is selected in the upper-lefthand corner (otherwise GSync is not active).
		- Also while monitoring the demo, turn on the monitor's onscreen display (pressing in the joystick button). 
			- In the upper-righthand side of the monitor's menu, you should see the monitor's active refresh rate changing with the demo's framerate.
		- The monitor should display framerates between 57-142 natively, but anytime the framerate falls to 56 FPS and below, then FreeSync's LFC (Low Framerate Compensation) feature should kick in.
			- For example - a framerate of 65 FPS would cause the monitor to match it @ 65 Hz.
			- Alternatively, if the framerate is 35 (below the monitor's lower FreeSync/GSync range of 57-142Hz) it will double the refresh rate (E.G. 35FPS*2=70Hz, which falls within the monitor's 57-142 Hz range). In other words, if you notice a mismatch between the monitor's setting and your current framerate, that is normal.

Other Notes:

- Credit to ""Alex"" and his following YouTube video whose comments tipped me off on how to modify the refresh ranges in CRU app (the 57-142 range that'd work with Nvidia / GSync):
	https://www.youtube.com/watch?v=tZ7lInuvG1E
- Credit to Nils Schimmelmann""s blog below which is where I originally found the Custom MG279Q drivers used in the instructions above.
	- https://nils.schimmelmann.us/post/133778060542/extending-the-asus-mg279q-freesync-range
	- https://app.box.com/s/gj0k5j8wkdk4e8lfq0coazrfr4n31sr4
- More info about LFC (low framerate compensation) here: https://www.reddit.com/r/Amd/comments/5cv2kj/does_lfc_freesync_support_still_require_that_the/",larathydo,2021-05-02 07:34:29,21,9,0.88
367,"Greetings to all!

Forum users often discuss certain products from manufacturers and criticize them for saving on various elements.

As you know, the MSI RTX3080 Gaming X Trio uses a graphene (plastic) backplate.

How many times have I read here and heard that MSI is no longer the same and why they went down the path of saving on matches.

&#x200B;

https://preview.redd.it/96uwtj1yonw61.jpg?width=1785&format=pjpg&auto=webp&s=a167d4922a9bb3840d52c2c1f095485643cd36ec

I really liked the idea of replacing the backplate from plastic to metal, is it really possible to reset the temperature on the card without removing the main radiator and definitely not losing the warranty when opening it. This is so convenient for those who have not yet opened their cards!

I bought an aluminum backplate from EKWB, suffered, installed, performed tests and I want to share with you.

&#x200B;

https://preview.redd.it/mb5z0rmzonw61.jpg?width=2278&format=pjpg&auto=webp&s=efa11d293abc94a4309ecdbbcfa1573c8cf3d65c

The cost of the plate is 36 euros plus delivery to my country of 12 euros, i.e. $61. Not to say that the price is huge, but not small, if it does not give any effect.

&#x200B;

The backplate is made of CNC-machined black anodized aluminum, which is suitable for all EK-Quantum Vector Trio RTX 3080/3090 water blocks. The question of compatibility with the standard cooler remains open, but I had hopes that the mounting holes are in the same places as the original ones and there should be no problems with the installation.

The kit includes the backplate itself + mounting screws M2.5x8 8pcs black and 8pcs nickel-plated, as well as an excessive number of new thermal pads of 2x and 1 mm thickness.

&#x200B;

https://preview.redd.it/wwlsov5fpnw61.jpg?width=1693&format=pjpg&auto=webp&s=fe017ea8517c913df017f7000ac6fa5ecc067dd3

When installing, I encountered several problems, but the main one is that the backplate rested on one part of the PCB card and bent it, I had to modify it with my hands.

&#x200B;

&#x200B;

https://preview.redd.it/xxbvyjuppnw61.jpg?width=4032&format=pjpg&auto=webp&s=e0fe8daf828d57a07ff3ee81c6c5d2a778881c27

&#x200B;

https://preview.redd.it/0y78j1aupnw61.jpg?width=4032&format=pjpg&auto=webp&s=6b07ad9f233a1018c087dd99d5b7e5526176f522

I perform my usual tests and record the result in the final table

&#x200B;

https://preview.redd.it/d35pkn95qnw61.jpg?width=2407&format=pjpg&auto=webp&s=e602b1a13b4c0f8652df9120b86f11bc5a49411e

To all my previous experiments, a column with the results of Copper shim 0.8 + EKWB backplate was added. In this case, we can only compare the last 2 tests Copper shim 0.8 and Copper shim 0.8 + EKWB backplate. And what do we see, after all this headache, hours of disassembly, checks, waiting, money spent and effort: the difference was a negligible 2C when mining, and in the fourth test there is no difference at all. It was possible to count on a decrease in temperature on the GPU, because unlike the standard plastic backplate, where the GPU is simply open, there is contact with the metal backplate. But no, there is no visible temperature drop on the GPU in any of the tests.

I am disappointed not only with the product itself, but also with the results obtained. When thinking about this test, I had the idea to give you information that there is a way, remaining under warranty, without removing the main radiator, to throw off a dozen degrees, replacing the standard backplate, which is so popular to speculate on forums, as a huge minus of MSI. But the facts are here and it is useless to argue with this, there is no point in changing the backplate, this will only be relevant for the 3090 series, but I do not know any 3090 cards with a plastic backplate, they already all go with an iron backplate.

&#x200B;

Here is full test with all details:

[https://youtu.be/JSc3ALbufVE](https://youtu.be/JSc3ALbufVE)

&#x200B;

Thx for reading and watching!",amfgray,2021-05-02 07:14:05,11,10,0.7
369,"Just received my 5900x/Strix RTX3090 prebuilt and planned to replace the Thermal pads and possibly add Heatsinks to the backplate as I intend to mine with it as long as its profitable and the card is paid off, whichever comes first.

I already have an assortment of Thermalright Odyssey  12.8w/mk pads in the required thicknesses. 

Something occurred to me though. I'll be mounting the GPU with a Vertical GPU bracket and thus mods to the back of the card can be pretty ugly while not ruining the aesthetic of the build as they'll pretty much be hidden.#

With that in mind, I wonder can I just get rid of the Backplate altogether. 

Instead of the default back of card thermal setup of Memory Module/VRM->Thermal Pad->Shared Backplate with shared heatsoak->thermal tape/more pads/TIM->small add-on finned Heatsinks....

Can I just take the backplate out of the equation completely and simply thermal tape some discrete small finned Heatsinks to the Memory modules and VRM's cooled by a fan. The discrete heatsinks meaning the VRM's aren't heating up the Memory modules nor visa versa for example.",ca1ibos,2021-05-02 02:56:18,1,8,0.57
371,"So I understand that DSR upscales basically past you native resolution of monitor to give a 4k image or equivalent on a 1080p monitor. What I don't understand is, can I set game resolution to 1080p and use DSR on a 4k monitor to upscale the 1080p image to 4k?",VaultCheese,2021-05-01 22:00:56,3,8,0.62
372,"Thinking about putting some thermal pads and heatsink on the backplate of my 3090 FE to aid in VRAM cooling. I’ve seen a bunch of photos of people doing this, so I know many people have tried. Any concerns with discoloration of the backplate surface after prolonged contact with thermal pads?",devious_burger,2021-05-01 21:02:44,6,4,0.76
374,"I am currently running an NVIDIA RTX 3060 with i7 97000kf 3.7ghz and Gigabyte Z390 Gaming X motherboard board! Will this be strong enough to get the most out of this monitor.

I know I won’t be able to game at 240 FPS but will I able to get the most out of this monitor or should I shoot for a slightly less powerful monitor? 

Any information would be super helpful for an amateur such as myself!

Thank you!",whosey_whatsit,2021-05-01 17:47:41,9,35,0.81
376,"I am really confused about this topic. I have my PC connected to a Samsung 65Q70R using HDMI. The only option my TV shows in the sound settings for my PC is PCM Audio. I have a Sonos Arc connected through Arc to my TV, so my set is capable of doing both Dolby Digital Plus and Dolby Atmos.

Can anybody be so kind to explain me how I can enable this sound options in my PC?",SpacePirate2k18,2021-05-01 15:27:19,10,16,0.75
377,"After watching Battle(non)sense on YouTube where he suggests a competitive setup of having G-Sync on, V-Sync off and fps uncapped, I was wondering if there's any downside in terms of stutter or latency if I was hypothetically floating around 240fps on a 240Hz G-Sync display where G-Sync is constantly turning off and on depending on the frame rate? 

I'm after the lowest input lag possible but if there's no downside to having G-Sync on for the few moments I'll be dropping below my refresh rate I'll keep it on. Thanks",Smart-Fuel-573,2021-05-01 15:19:22,18,34,0.83
378,Title says it all tbh.,eugenis13,2021-05-01 13:48:37,0,4,0.43
382,"Just recently scored a 3070. System I am running has x570, R5 3600, with an aio I got from my buddy, 7 fans and an rx5700 Fe with an 650w Gold psu. Would an upgrade to 750 be required? The evga website says 650 is minimum requirement.",Mogie93,2021-05-01 11:55:33,3,14,0.58
383,_,spiderboy6,2021-05-01 07:03:17,3,19,0.59
385,"We're consolidating **all** tech support posts and questions into this **monthly** tech support and questions megathread.

It should be noted, r/NVIDIA does not represent NVIDIA in any capacity unless specified. There's also no guarantee NVIDIA even read this subreddit, if you have an issue, criticism or complaint; it's recommended to post it on the official GeForce forum.

**All Tech Support posts that do not include sufficient information will be removed without warning**

Before creating a Tech Support post, please see our additional resources section, it solves a lot of common issues.

TL;DR: **DO: Use the template. DO NOT: ""i have driver issue please help not 60fps!!""**

# For Tech Support Posts

Please use this template below - posts without adequate information will be removed, we can't help you unless you provide adequate information.

**Status:** UNRESOLVED/SOLVED - please update if your issue is resolved

**Computer Type:** State if your computer is a Desktop or Laptop and the brand/model if possible, e.g Desktop, custom built

**GPU:** Provide the model, amount of VRAM and if it has a custom overclock, e.g. GTX 1070, 8GB of VRAM, no overclock

**CPU:** Provide the model and overclock information if possible, e.g. Intel Core i5 6600k, no overclock

**Motherboard:** Provide the model and current BIOS version if possible, e.g. MSI Z170A GAMING M9 ACK, latest BIOS (1.8)

**RAM:** Provide the model and overclock information if possible, e.g. Corsair 8GB (2x4GB) DDR4 2400MHz, XMP enabled, no overclock

**PSU:** Provide the model and its rated wattage and current output if possible, e.g. EVGA 850 BQ, 850W, 70amps on the 12v rail - for laptops you can leave this blank

**Operating System & Version:** State your OS and version, also please state if this is an upgrade or clean install, e.g. Windows 10 build 1607 64bit, upgrade from Windows 8.1

**GPU Drivers:** Provide the current GPU driver installed and if it’s clean install or upgrade, e.g. 376.33, clean install

**Description of Problem:** Provide as much info about the issue as you possibly can, images and videos can be provided as well.

**Troubleshooting:** Please detail all the troubleshooting techniques you’ve tried previously, and if they were successful or not, e.g. tried clean install of GPU drivers, issue still occurs. Please update this as more suggestions come in

# For Question & Answer Post

Additionally, this thread will be used to answer general questions that may not warrant having their own thread -- this could be questions about drivers, prices, builds, what card is the best, is this overclock good etc…

Please don't downvote questions for the sake of helping others. We will also sort the post randomly so every question can be seen and answered.

If you don't have any tech support issues or questions, please contribute to the community by answering questions.

# Here are some additional resources:

* [Display Driver Uninstaller (DDU) tutorial](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)
* [Repairing/Maintaining/Cleaning a Windows 8, 8.1 or 10 Image](https://docs.google.com/document/d/1Y7HOS6UiOBXAWtNFBJ0w70f14izRQcBYD9puuSw6Ghs/edit)
* [How to repair/verify game files](https://docs.google.com/document/d/1Ba3RjEBnFcnUec0axX1ETgb1ndKvxSAX2YGQGu_leL0/edit)
* [Malware/Virus Removal Guide](https://docs.google.com/document/d/16er6ZmSj4nUHBP-80EQLZjNgLNIDHyE93u0Vu8e6wV0/edit)
* MemTest86 tutorial by [DigitalStorm](https://www.youtube.com/watch?v=e91hb60iPew) \- faulty memory can cause a lot of problems, running MemTest86 will verify if your memory is faulty or not
* You can also check the sidebar for helpful links, we update it regularly
* You can visit our [Discord](http://discord.gg/nvidia) to chat with other NVIDIA users

Again, it should also be noted, r/NVIDIA is not a dedicated Tech Support forum and your question/issue may not be resolved. We also recommend checking out the following

* r/TechSupport \- A Subreddit dedicated entirely to answering Tech Support related questions/queries
* [GeForce Support](http://www.geforce.com/support) \- answers to the most common questions with a knowledgebase available 24x7x365
* [Official GeForce Forum](https://forums.geforce.com/) \- Posting your complaints, criticism and issues here will increase the chances an NVIDIA employee sees it.
* [NVIDIA Support](http://nvidia.custhelp.com/app/home/) Includes live chat and email

If you think you’ve discovered an issue, it’s crucial you report it to NVIDIA, they can't fix an issue unless they know it exists.

Here’s a guide on how to submit [valuable feedback](http://nvidia.custhelp.com/app/answers/detail/a_id/3141)

And here’s where you [submit feedback](https://forms.gle/kJ9Bqcaicvjb82SdA)

If you have any questions, or think this template post could be improved for future use, please message the [/r/NVIDIA moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fnvidia)

Want to see previous version of this thread? Click [here](https://www.reddit.com/r/nvidia/search?q=Tech+Support+Megathread&sort=new&restrict_sr=on)",Nestledrink,2021-05-01 05:00:13,25,138,0.93
387,"Hi guys! 

Do you know how long it takes for the Nvidia rma team to respond in Europe? I have been waiting for a return label or any other response from them for days. My brand new 3090 FE top fan stopped working and I am unable to do any of my work since it’s GPU dependent. 

The customer service keep promising that the rma team will get back to me but they haven’t. Any one have any experience dealing with FE card rma process in Europe?

Thanks!",Starman0011,2021-05-01 03:33:58,2,4,0.67
388,"Evening,I am not seeing any gains on repadding and pasting my 3090 FE.Guide: CryptoAtHome on youtube,. The cut on the pads were eyeballed then trimmed into shape.Pads: 1.5mm Thermalwright Odyssey Extreme pads.

Paste: Thermal Grizzly Kryonaut.

Is it possible to see no improvement on VRAM Temperatures with new pads? I'm willing to try again and put more effort into making more accurate cuts, but I want to check if its worth the time and money.

Edit: Photo added

https://preview.redd.it/fktizcugffw61.jpg?width=4032&format=pjpg&auto=webp&s=f53af28aa2d418a7f8fcd37bf4cb5dcd6968dafd",RegalR4,2021-04-30 23:56:53,0,11,0.33
390,Like almost everyone it seems that my card is having issue with the original thermal pads. Does anyone know if changing them voids the warranty? I know that it doesn't for EVGA cards but I don't know about Asus cards,bebeJuan,2021-04-30 21:51:23,4,17,0.67
391,"Currently I locked at 30 fps with adaptive vsync from nvidia control panel + 30 fps in rtss, it looks smooth now then raw 30 fps, but when I compare it with consoles gameplay on YT, it looks even more smoother on same 30 fps, don't tell me if it's frame interpolation feature because it looks smooth even without it on consoles. Am I doing something wrong? Also max pre rendered setting doesn't seems to smoothen the image for me.

My specs is i7 3770 and gtx 960. Planning to upgrade when GPU price settles.
any help would be really appreciated.",cubanpirate03202,2021-04-30 21:28:41,1,25,0.55
398,"For anyone who was following my last post. The gelid pads got delivered last night and I've gone from mining at 93mh at 108-110c vram with an open case and a desk fan blasting at it. To now where it's been mining all night at 101mh at 82-84c vram temp with the glass panels closed.

Thank you everyone who helped out. You saved my GPU",Benalbo1,2021-04-30 06:36:28,10,14,0.68
399,Vulcan is the best version from colorful heard its as good as rog strix is that true,Aggressive-Volume-16,2021-04-30 05:41:00,2,2,0.6
400,"I had used Gamestream before on my old 1080ti under the same network conditions and although it was really good, it was pretty easy to notice that I was streaming because the image wasn't that crisp and there was a slight input delay. 

I built a new PC with a 3070 a few months back but hadn't bothered to use Gamestream at all. Today I decided to hook up my Shield to my 4K TV in the living room and oh my god... it ran like I had my PC plugged right into the TV. It was absolutely incredible, like almost too good to be true. I played some Cyberpunk, Fall Guys and Cuphead and it ran amazingly well. No artifacts, no noticeable compression, no input delay, no nothing. Just beautiful 4K gaming.

Why was my experience so different to what it was before? Was it the card? Did something get updated?",whathefuckisreddit,2021-04-30 03:43:01,6,7,0.8
401,Does NVIDIA even have any of the old 20 series FE Cards to RMA if I send in my old 2080 FE? I don't want to get downgraded with cash or any of that stuff so I wanted to make sure.,Weenmman,2021-04-30 03:41:20,4,6,0.75
403,"Hello,

In earlier threads, I made a comment, and also a post, about reducing the VRAM temps by replacing the original mesh/putty stock pads on the backplate of a 3090 FE, and also, on the front (GPU Core) side as well.  The original pads were measured as: backplate VRAM: 1.0mm, backplate V hotspots: 1.0mm, backplate long pad/small chip pads (unknown size, but are either 1.5mm or 2mm).  GPU Core side:  VRAM: 1.5mm.  VRM strips: 1.8mm-2.0mm.

Those are the stock measurements of the non compressed Nvidia pads.

It was suggested to replace the front side (GPU Core) pads with Thermalright Odyssey 1.5mm pads, and the backplate side pads with either 1.5mm or 2.0mm pads.  There is no problem with the backplate with the Odyssey pads, except you should \*REMOVE\* the SLI cover first, and put that on only when the card is fully assembled, because that cover \*WILL\* interfere with contact pressure, and because the pads do not compress very much, without a lot of effort, you should try to put the backplate on evenly and screw each side in partially to get an even mount and that will avoid flexing.

However, I discovered a problem with the GPU Core side with the TM Odyssey pads.  The VRAM and VRM fit and temps are perfectly fine.  But there is an issue with GPU Core contact.

It becomes obvious when you compare the compression of the Nvidia pads and the TM Pads:

Stock NV pads:

[https://i.imgur.com/LsJL2Z5.jpg](https://i.imgur.com/LsJL2Z5.jpg)

[https://i.imgur.com/fCx1J8C.jpg](https://i.imgur.com/fCx1J8C.jpg)

(Yes the VRM pads show a great deal of compression, which is why 1.5mm replacements work here).

Thermaright Odyssey (VRAM) pads: (discarded): They look torn up because I had them in the bin before I realized I needed them for a picture:

[https://i.imgur.com/1YfXsHk.jpg](https://i.imgur.com/1YfXsHk.jpg)

It immediately becomes clear that the TM pads simply did not compress as much as the NV pads.  Even if it's just a 0.1mm difference (possibly 0.2mm), this difference \*MATTERS\*.  Immensely, because you're dealing with GPU Core to heatsink contact PSI pressure here, and too low pressure + Convex core = degrading thermal paste, regardless of what paste you use.  This is due to heat and cold compression and expansion of the surfaces, if the mounting pressure is not firm enough, this will cause the paste to very slowly migrate and get displaced, instead of settling properly.

So, the issue here is the core to heatsink contact pressure.

Long before, I had noticed what I thought (before HWInfo's hotspot was available) to be GPU core temps rising slightly, which I simply attributed to ambient changes.  And since I was dealing with conductive paint and later soldered stacked shunt mods, I was repasting constantly anyway.  But recently, during the previous three disassemblies and repads with TM Pads and Thermalright TFX, I noticed the same very slow temp rise, preceded first by the Core to Core hotspot delta slowly increasing.  For me, this was most noticeable since with a shunt mod, I can pull 550W from the card, but even with a 400W cap (stock) it slowly happened.  What I had noticed on the previous two repastes with Odyssey pads, the core to hotspot delta would start off at about 10.5-11.5C.

Then over about a week, it would go up to about 12-12.5C, then after another week, it would be 13.5-14C.  And at that point that was enough to also notice the average core temp rising a bit.

This also explains why with a thinner paste (Kryonaut Extreme, that pink paste), I had temps 5C hotter in less than 2 weeks, and the Kryonaut in a 'strange' pattern on the die.

Anyway, after reading the 3080 FE thermal pad threads , and seeing how people were trying 2mm Gelid Extreme pads on the core side and it working, but 2mm Thermalright pads on the core side caused instant core shutdown on windows load (almost no core-heatsink contact), and other posts mentioning that the gelid extreme pads are a lot more compressible and soft than the Thermalright pads, I decided to order some 1.5mm (120mm \* 120mm) Gelid Extreme pads from the Slow Boat from China.

So I replaced the core side pads with 1.5mm Gelid Extreme pads, and applied my typical pattern of Thermalright TFX  X+ 4 dots method I suggest to people.

[https://i.imgur.com/61sbQk3.jpg](https://i.imgur.com/61sbQk3.jpg)

The very first thing I noticed when remounting the PCB on the heatsink, was that it seemed like the PCB ""went on"" with a lot less rocking or ""resistance"", if that makes sense (almost as if the Odyssey pads were pushing back on the mount somehow).  It literally fit right on evenly.

Then I had to test it a week.  And now it's been 7 days, and the results are:

That my Core hotspot delta has not changed one bit since day 1.

It's still identical: 10.3C to 11.6C, using Overwatch testing (1080p + 200% render scale=4k, at 400W TDP) and brief Heaven benchmark (5 minute) testing, at 550W TDP.  That's the first time the temps have not changed in the first week of usage, so I call that mission accomplished.

So, for repadding, I highly suggest considering Gelid Extreme 1.5mm pads on the core side of the card.  I wouldn't suggest Gelid Ultimate pads as they are harder than Extremes, but according to another person on [overclock.net](https://overclock.net), even the Ultimate pads are more compressible than the Odyssey pads but less soft than the Extreme pads.

The backplate side can accept pretty much any pad (Geild Ultimate pads may work there).

For those with existing Thermalright Odyssey pads, on the core side, if the pads are not dried out (it's obvious if they are), then they can probably be compressed down manually about 0.1mm-0.2mm max, by using a clean, flat surface, with a piece of glass on top pressing downwards, but all of the pads should be compressed at once to ensure accurate results.  Or just use new pads if you already have them.  Otherwise, try switching to Gelid Ultimate pads.

Big thanks go to the other people who were first to find out about the Gelid pads being softer, the 3080 FE repadders.",falkentyne,2021-04-29 21:48:03,127,95,0.93
405,"Does anyone know if the SRIX suffers from bad temps on the memory as much as other cards do? I mostly see FE cards suffer from this and some AiBs, but can't find if the STRIX 3090 does. Any info would be much appreciated!",2roK,2021-04-29 14:52:24,2,38,0.56
406,"Hey all, question from an amateur builder. I was wondering if it is possible to have 2 FE 3080's in one system, assuming the motherboard has 2 slots? The plan would be to have one card do regular gaming and work, while the second one mines, and when a friend comes over use the second one to game. However, I don't want 2 desktops. Is it possible to put it in one? (Also I know it doesn't support SLI, nobody wants to play those supported games anyways)",yojojo4,2021-04-29 13:25:53,0,18,0.36
407,"# Game Ready Driver 466.27 has been released.

# New feature and fixes in driver 466.27:

**Game Ready** \- Game Ready for the **Metro Exodus PC Enhanced Edition.** This new Game Ready Driver provides support for the **Metro Exodus PC Enhanced Edition**, which adds **additional ray-traced effects** and **NVIDIA DLSS 2.0** for greater performance and improved image quality. Additionally, this release also provides optimal support for **Mass Effect Legendary Edition** and **Resident Evil Village**, along with **support for 5 new G-SYNC Compatible displays**.

**New Features and Other Changes**

* Added support for DirectX 12 Agility SDK.
* This driver updates the hash limiter for the GeForce RTX 3060 12GB and is required for product shipped starting mid-May

**Game Ready Driver Fixes** (For full list of fixes please check out release notes)

* \[NVIDIA Reflex\]\[Rainbow Six Siege\]: Fixed a number of performance related issues related to NVIDIA Reflex and Rainbow Six Siege.
* \[HDMI 2.1:\] In-game FPS may be capped to the display refresh rate when ""Vertical sync"" is set to Off \[3285334\].
* \[Rigid Gems\]\[Prepar3D\]: The applications may crash or fail to launch.\[3285067/3286874\]

**Game Ready Driver Important Open Issues** (For full list of open issues please check out release notes)

* Yellow bang with Error Code 10 appears by the NVIDIA Platform Controllers and Framework Properties in Device Manager after Express or Custom driver installation without reboot.\[200716134\]
   * Reboot the system to clear the error, otherwise Dynamic Boost cannot be enabled.
* \[Mortal Shell\]: Unusual increase in the brightness occurs when Shadow Quality is set to Low or Medium. \[200724762\]
   * To work around, set the Shadow Quality to High or Ultra.
* \[Call of Duty: Black Ops Cold War\]: The game may crash on GeForce GTX 10 series GPUs. \[200719668\]
* \[World of Warcraft: Shadowlands\]: Random flicker may occur in certain locations in the game \[3206341\]
* \[Batman Arkham Knight\]: The game crashes when turbulence smoke is enabled. \[3202250\]
* \[Steam VR game\]: Stuttering and lagging occur upon launching a game while any GPU hardware monitoring tool is running in the background. \[3152190\]
* \[YouTube\]: Video playback stutters while scrolling down the YouTube page. \[3129705\]

# Driver Downloads and Tools

Driver Download Page: [Nvidia Download Page](https://www.nvidia.com/Download/Find.aspx?lang=en-us)

Latest Game Ready Driver:  466.27 WHQL

Latest Studio Driver:  462.31 WHQL

DDU Download: [Source 1](http://www.wagnardmobile.com/DDU/) or [Source 2](http://www.guru3d.com/files-details/display-driver-uninstaller-download.html)

DDU Guide: [Guide Here](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)

**DDU/WagnardSoft Patreon:** [**Link Here**](https://www.patreon.com/wagnardsoft)

Documentation: [Game Ready Driver 466.27 Release Notes](https://us.download.nvidia.com/Windows/466.27/466.27-win10-win8-win7-release-notes.pdf)

Control Panel User Guide: [Download here](http://us.download.nvidia.com/Windows/466.27/466.27-nvidia-control-panel-quick-start-guide.pdf)

NVIDIA GeForce Driver Forum for 466.27: TBD

**RodroG's Driver Benchmark:** [Link Here](https://babeltechreviews.com/geforce-466-27-driver-performance/)

[r/NVIDIA](https://new.reddit.com/r/NVIDIA/) Discord Driver Feedback for 466.27: [Invite Link Here](https://discord.gg/y3TERmG)

# Having Issues with your driver? Read here!

**Before you start - Make sure you Submit Feedback for your Nvidia Driver Issue**

There is only one real way for any of these problems to get solved, and that’s if the Driver Team at Nvidia knows what those problems are. So in order for them to know what’s going on it would be good for any users who are having problems with the drivers to [Submit Feedback](https://forms.gle/kJ9Bqcaicvjb82SdA) to Nvidia. A guide to the information that is needed to submit feedback can be found [here](http://nvidia.custhelp.com/app/answers/detail/a_id/3141).

**Additionally, if you see someone having the same issue you are having in this thread, reply and mention you are having the same issue. The more people that are affected by a particular bug, the higher the priority that bug will receive from NVIDIA!!**

**Common Troubleshooting Steps**

* If you are having issue installing the driver for GTX 1080/1070/1060 on Windows 10, make sure you are on the latest build for May 2019 Update (Version 1903). If you are on the older version/build (e.g. Version 1507/Build 10240), you need to update your windows. Press Windows Key + R and type winver to check your build version.
* Please visit the following link for [DDU guide](https://goo.gl/JChbVf) which contains full detailed information on how to do Fresh Driver Install.
* If your driver still crashes after DDU reinstall, try going to Go to Nvidia Control Panel -> Managed 3D Settings -> Power Management Mode: Prefer Maximum Performance

If it still crashes, we have a few other troubleshooting steps but this is fairly involved and you should not do it if you do not feel comfortable. Proceed below at your own risk:

* A lot of driver crashing is caused by Windows TDR issue. There is a huge post on GeForce forum about this [here](https://forums.geforce.com/default/topic/413110/the-nvlddmkm-error-what-is-it-an-fyi-for-those-seeing-this-issue/). This post dated back to 2009 (Thanks Microsoft) and it can affect both Nvidia and AMD cards.
* Unfortunately this issue can be caused by many different things so it’s difficult to pin down. However, editing the [windows registry](https://www.reddit.com/r/battlefield_4/comments/1xzzn4/tdrdelay_10_fixed_my_crashes_since_last_patch/) might solve the problem.
* Additionally, there is also a tool made by Wagnard (maker of DDU) that can be used to change this TDR value. [Download here](http://www.wagnardmobile.com/Tdr%20Manipulator/Tdr%20Manipulator%20v1.1.zip). Note that I have not personally tested this tool.

If you are still having issue at this point, visit [GeForce Forum for support](https://forums.geforce.com/default/board/33/geforce-drivers/) or contact your manufacturer for RMA.

**Common Questions**

* **Is it safe to upgrade to <insert driver version here>?** *Fact of the matter is that the result will differ person by person due to different configurations. The only way to know is to try it yourself. My rule of thumb is to wait a few days. If there’s no confirmed widespread issue, I would try the new driver.*

**Bear in mind that people who have no issues tend to not post on Reddit or forums. Unless there is significant coverage about specific driver issue, chances are they are fine. Try it yourself and you can always DDU and reinstall old driver if needed.**

* **My color is washed out after upgrading/installing driver. Help!** *Try going to the Nvidia Control Panel -> Change Resolution -> Scroll all the way down -> Output Dynamic Range = FULL.*
* **My game is stuttering when processing physics calculation** *Try going to the Nvidia Control Panel and to the Surround and PhysX settings and ensure the PhysX processor is set to your GPU*
* **What does the new Power Management option “Optimal Power” means? How does this differ from Adaptive?** *The new power management mode is related to what was said in the Geforce GTX 1080 keynote video. To further reduce power consumption while the computer is idle and nothing is changing on the screen, the driver will not make the GPU render a new frame; the driver will get the one (already rendered) frame from the framebuffer and output directly to monitor.*

# Remember, driver codes are extremely complex and there are billions of different possible configurations. The software will not be perfect and there will be issues for some people. For a more comprehensive list of open issues, please take a look at the Release Notes. Again, I encourage folks who installed the driver to post their experience here... good or bad.",Nestledrink,2021-04-29 12:38:17,238,558,0.96
410,"I love PC gaming but i am not tech savvy at all. A friend of mine told me about Nvidia Geforce Experience when i asked him if there was any program that just scans your PC and automatically applied the best settings for your PC. I've been using Nvidia Geforce Experience for a few years now and when games show up in the list it does a brilliant job of doing exactly what i just said, but that's just it... when games do show up. Like for example i recently bought Resident Evil Revelations 1 and 2 on Steam and the first one shows up in the list, but not the second one.

I've googled it and also watched youtube tutorials on how to manually add games but no matter what i do i can't get it to show. Infact most of my Steam games don't show in the list. Can any game be added or only certain ones and if so does anyone maybe know another program that does a really good job of what i described at the start here and definitely can be used with any game?",Aussie_Wolfhound,2021-04-29 11:59:27,0,13,0.42
411,"I managed to get my hands on the Zotac Trinity OC 3080 for $800 a little over a month ago. Previously was using a gtx 760. Honestly, it's pretty nice. It has a clean look; nothing too crazy and ""gamer-ey,"" no unicorn vomit. I kinda dig the plain look. People also have said the rgb is buggy but I messed with it a couple times and now it matches my ram and peripheral rgb no problems. 

Every game I play I max everything out and turn everything on (I've never had this luxury before in my life). I also play on 2k apparently the ideal resolution for the 3080. I never had noticeable frame drops. And temps range from 70-80 when gaming. Been playing stuff like Metro Exodus, Skyrim SE, Apex, and the insanely graphic heavy game; Valheim. 

In terms of sounds, I have nzxt and noctua case fans, and noctua cpu cooler. The Zotac is actually quieter than the nzxt case fans but not the noctua. But if I were to throw the noctua's at 1700 rpm, the zotac is surprisingly quieter. No coil whine or anything abnormal. 

Conclusion, I really like the Zotac 3080. A lotta people have bagged on Zotac but all those problems I have not experienced. In fact, I've had absolutely zero issues. I didn't mess with any overclocking or undervolting etc. The only thing I changed was I put it into ""performance mode."" I'm not a crazy tech pc genius so I can't really give you the stats on everything. Just a normal dude who plays games and does 3d work. So if you see a Zotac 3080 on sale just take it. 3080s are hard to come by and you can't go wrong with one. 

My specs:
i7 9700k
16gb 3200 ddr4
Zotac 3080 Trinity OC
Asus prime z390-a",Brother_Bongo,2021-04-29 11:31:01,32,33,0.9
412,"I was wondering if anyone has a copy of the original BIOS that came with the 3080 iCHILL X3 prior the BIOS update that included ReBAR support—I want to do some troubleshooting because ever since that update, my system has been pretty unstable when gaming (yet is stable and does pretty well during benchmarks). I was stupid enough to not make a backup of my original BIOS before updating.

Tried looking for it in TechPowerUp's VGA BIOS collection, but it doesn't seem to be there. Would it be safe to use a BIOS from another manufacturer?

My 3080 could also be a faulty card, but I want to try reverting to factory settings + stock BIOS before considering an RMA.",curiousowlman,2021-04-29 06:51:48,0,12,0.5
413,"Cross post from the EVGA subreddit.

I've spent countless hours researching what type of thermal pads to use and what thermal pad thickness is required to have full contact for the 3080 hybrid ftw3.

A little backstory, I use my computer for school and gaming. When I'm not home I mine Etherium. Nothing fancy but I'm fine with mining on my gpu as long as temps are safe and its profitable. 
Is it profitable? Yes. Are my stock temps safe?? No!
The first time I tried mining on the hybrid card, temps climbed to **105C**. I quickly stopped mining and began my research. All temperature measurements are memory junction temps.

So after some time I found out that for the hybrid card you need a mix of **2.25mm thickness and 0.75mm thickness** pads. Those are odd measurements so as long as you are within 0.25mm then you will get good contact.

I've taken this card apart 4 times. Here are my results.

* 1st attempt saw me using THERMALRIGHT pads of **1mm and 2.5 mm thickness**, the latter of which is stacked (not ideal). I also went ahead and stacked 2.5mm pads for the backplate. The pads on the back stayed on for each attempt. It's important to note that I'm using KRYONAUT for paste on the GPU die and in between the vrm copper plate. If you have the hybrid card, you would know what I mean. Temps while mining dropped from 105C to **98C**. A good improvement but still not satisfied. 

* 2nd attempt saw me still using the THERMALRIGHT pads from before but I put KRYONAUT on both sides of the pads that sit on top of the memory. Temps dropped to **94C**. I still was not satisfied.

* 3rd attempt saw me using GELID EXTREME pads of **3mm and 1mm thickness**. 3mm thickness is fine here as the gelid pads are extremely soft and will compress as long as you tighten your screws enough but not too much that you risk damage to your card. Temps dropped to **92C**.

* 4th and final attempt saw me using the GELID ULTIMATE pads of **2mm thickness and 1mm** thickness. I also used KRYONAUT EXTREME in this attempt which has higher thermal conductivity than regular kryonaut but much more expensive. I also put a tiny amount of thermal paste in between the parts where there are 3 memory modules next to each other. I did this in an attempt to facilitate heat transfer. The biggest difference between the gelid extreme and ultimate pads is that the ultimate pads have a higher thermal conductivity of 15W. 
With all that being said, temps now sit at a much nicer **88C.** 

Edit: For exact thermal pad sizes (the backplate ones are false as they didn't work for me) https://forums.evga.com/Anyone-please-tell-me-the-exact-thickness-of-the-thermalpads-for-3080-XC3-ultra-HYBRID-m3244960.aspx Courtesy of u/ZekeSulastin

Hopefully this helps anyone attempting to do the same, if you have any questions just let me know.",epicloler,2021-04-29 06:11:26,35,48,0.85
416,"Source:

[https://www.msi.com/blog/improve-performance-with-resizable-bar-now-available-for-msi-geforce-rtx-30-series-graphics-cards](https://www.msi.com/blog/improve-performance-with-resizable-bar-now-available-for-msi-geforce-rtx-30-series-graphics-cards)

https://preview.redd.it/atcfehrt11w61.png?width=655&format=png&auto=webp&s=006adfa4dbf02c5cd0bb2041848b45e064ef89d9",playthissong2541,2021-04-29 02:58:37,24,19,0.8
417,I couldn't find any way to check my Queue position so I thought I may ask here. So I entered the Queue in 28.01.2021at 14:54 and I still haven't gotten any E-Mail about the card being available. I wanted to ask you guys If/when you received your card and when you joined the queue. It has been 3 Months for me and I hope I won't have to wait too much longer.,CrazyLeonGR,2021-04-28 18:53:13,3,14,0.63
421,"How come high end cards put thermal pads on the round capacitors but lower end cards just rely on ambient cooling? Wouldn’t putting thermal pads on the caps just dump unnecessary heating into them? 


https://overclock3d.net/gfx/articles/2020/09/25155649451l.JPG



This is an image of a “low end” 3090 the gaming OC varient. It has no thermal pads on its round capacitors.

https://www.reddit.com/r/gigabytegaming/comments/le1aeo/good_to_see_top_quality_thermal_pads_being_used/?utm_source=share&utm_medium=ios_app&utm_name=iossmf

This is an image of a “high end” 3080 variant and it comes with thermal pads on its round capacitors. But wouldn’t this heat them up for no reason since their operating temperature is only around 40C. Either I’m missing something or the capacitors are all different 
Internally and have vastly different operating temperatures and I’m being an idiot?",CarbonBasedHombre,2021-04-28 14:24:36,2,8,0.67
424,"So I've wanted to replace the thermal pads of my 3090 SUPRIM X and have done quite a bit of research trying to find the exact thickness of the pads to avoid any kind of bending. Unfortunately I could not find any clear answer so I contacted MSI directly and got this as a response, hopefully it'll help someone else that's searching for it!

[RTX 3090 SUPRIM X Thermal Pads Measurements](https://i.imgur.com/SImF509.png)",BibochOfficial,2021-04-28 10:34:24,81,55,0.92
426,"Guys,  I'm trying to change the GPU argb leds but I'm kinda lost. Which program am I supposed to use? MSI Dragon Center? Mystic Lights? I can't use Dragon Center bc it says I have to uninstall MSI Center SDK but I can't even find that program",RodLema,2021-04-28 04:58:04,5,4,0.73
428,"Is the backplate metal?  Is it worth looking into a replacement in order to increase cooling via heat pads on the back of the card?  I was looking into the EK backplate, but it looks like it might only work with the waterblock.",AStorms13,2021-04-27 19:17:03,3,18,0.67
429,"I’m having trouble finding the right settings for both HDR and SDR gaming. I’ve been trying a lot of things found on many different threads,and I always end up having either a dark image, or washed out colors. I have to say I’m a bit lost with the mix of Nvidia control panel settings, TV settings, and windows settings. 

I’m in PC mode on my C9. From there, whether HDR or SDR, I’m never sure what the ideal settings should be in my LG. Same in Nvidia control panel. I tried different combinaisons of output color format/color depth/dynamic range, but im never sure what the matching settings should be on the C9.

Currently trying to play the Mafia remaster, which does not support HDR, thus forcing me to go through my SDR settings from the beginning. So far I’m struggling 

Any recommendations?",Nelchior,2021-04-27 19:06:47,8,30,0.83
430,"Although not the most sought after 30-series card, just received my EVGA Queue notification for an RTX 3060 XC Gaming  12G-P5-3657-KR 

I signed up on February 25th @ 9:25am PST. (I now realize this was launch day lol)

Just thought I'd share for those wondering where they are in line.",leeboyjenkins1,2021-04-27 18:57:07,30,34,0.85
431,"I recently purchased a Flir thermal image camera and decided to check my pc temps. I currently have a LL O11 Dynamic pc case maxed out with noctua fans. I have a 380 AIO on the CPU and a 140 AIO on my 1080ti mounted via a NZXT G12 mount. 

I originally installed high quality copper heatsinks on the memory and VRMs and upgraded the fan on the G12 to a noctua. However, the Flir was registering memory temps of 94 C on the GPU memory! 

I found another article somewhere else that referenced installing heatsinks and a fan (blowing away from the card) on the back of the GPU to help cool the memory. I performed this mod and lowered my GPU memory temps from 94C to 85C. I will add the link to this thread once I am able to find it again.

Keep in mind that my card is overclocked and also using an enlargementpill.

[Previous GPU mem temp](https://i.imgur.com/SGtUfmN.jpg)

[GPU mem temp after mod](https://i.imgur.com/o2T3UaY.jpg)

[GPU mem mod image](https://i.imgur.com/HNCJMSn.jpg)",jrm523,2021-04-27 15:35:00,9,19,0.71
433,"I have an msi 2070s and first of all the card is a beast. Core temps max at 75 after a thermal repaste. My VRM temps seem a little high imo 70s shooting to 80s. Thinking about replacing the thermal pads on my card but I can’t find the sizing of the pads anywhere. 

Anybody have any info on thermal pads sizes?",mortalcelestial,2021-04-27 12:26:39,0,8,0.45
435," I have been considering buying a new laptop (a small portable one) to work on in a linux environment. I would like the laptop to be able to run a few games, such as GTA, LoL, CS:GO, etc. I also want it to be able to work well in Unity so I can practice game development. Most heavy tasks will be made on a VM or My desktop (through Parsec). USB-C charging would also be nice so that I can charge my phone and laptop with one charger.  

&#x200B;

I have found 3 different configurations, but find it hard to choose between them. I love the Ryzen 7 CPU, but I believe that the MX350 would do wonders to improve stream quality over parsec and reduce CPU load.

&#x200B;

The laptops I have found is:  


1. Lenovo Yoga Slim 7, Intel I7-1065G7, 16Gb LPDDR4x, 512Gb M.2, Nvidia MX350, USB-C charger, \~1309$ [https://www.inet.se/produkt/1964697/lenovo-yoga-slim-7-14-i7-16gb-512gb-mx350#specifikationer](https://www.inet.se/produkt/1964697/lenovo-yoga-slim-7-14-i7-16gb-512gb-mx350#specifikationer)
2. Acer Swift 3, Intel I7-1065G7, 16Gb LPDDR4, 512Gb M.2, Nvidia MX350, No USB-C charger, \~1190$ [https://www.inet.se/produkt/1965016/acer-swift-3-13-5-i7-16gb-512gb-mx350-qhd#specifikationer](https://www.inet.se/produkt/1965016/acer-swift-3-13-5-i7-16gb-512gb-mx350-qhd#specifikationer)
3. Asus Zenbook 14 UM433 PURE, Ryzen 7 4700U, 16Gb LPDDR4x, 512Gb M.2, Nvidia MX350, No USB-C charger, \~1309$ [https://www.inet.se/produkt/1965025/asus-zenbook-14-um433-pure-14-ryzen-7-16gb-512gb-mx350#specifikationer](https://www.inet.se/produkt/1965025/asus-zenbook-14-um433-pure-14-ryzen-7-16gb-512gb-mx350#specifikationer)
4. Lenovo IdeaPad 5, Ryzen 7 4700U, 16Gb LPDDR4x, 512Gb M.2, AMD Radeon Graphics, USB-C charger, \~952$

While the Asus Zenbook seems like the perfect alternative, I kind of want the USB-C, and the ErgoLift feels like it might be fragile (Considering this laptop will be with me on the move). Any thoughts?

&#x200B;

/Ejo",Ejo2001,2021-04-27 11:00:37,0,9,0.33
436,I have non max q laptop with rtx 2070. It's a refresh version so performance is a bit higher than older 115w rtx 2070. How much longer will I be able to play latest games at 1080p 60fps on at least medium settings?,Leon_idas0,2021-04-27 10:55:13,2,11,0.6
437,"Long story short, I thought my laptop would be able to handle this monitor. It can't

So im trying to build a pc, i have most parts picked out, but I cant seem to find any info that shows if a 3060 could run 1440p gaming on an ultrawide

Would it? Or should I get a 3070? Obviously ignoring the shortage

Or is the 3060ti a safe middle ground? 

Any other recommended cards that might be easier to find that would be able to handle 1440p gaming? 

Thanks in advance!",brunokid,2021-04-27 04:30:52,39,120,0.88
440,Is there anywhere someone has reviewed all 3070 models (FE vs AIB) and done a rundown of the top performance / specs in this class?,Nytehawk2002,2021-04-26 12:05:05,0,21,0.4
441,I have to options to use GPU in my SuperMicro SYS-4029GP-TRT server. Which is the better choice. I am planning to use this server for my deep reinforcement learning research.,btahtaci,2021-04-26 11:48:55,8,12,0.73
444,"I'm trying to setup Nvidia tesla k80 on hyper-v for boost graphics on each VM machine connected trough RDP 
Using:
HP DL380 G8 
windows server 2016 or 2019
Is it need to have some kind of license? 
Where can I find the right driver 

 is it possible?",MDBlackStar,2021-04-26 08:56:54,0,0,0.5
445,"Hey, there!

&#x200B;

Is there any up to date UK RTX 3060 Ti Founder's Edition Restock Spreadsheet? Or does anyone know when they're going to restock next / what days / if its bi-weekly?

&#x200B;

Thanks in advanced.",HowToEverythingYT,2021-04-26 06:41:35,8,15,0.73
446,"Hello everyone,

I am trying to set max frames on a game in the Nvidia Control panel, but I can’t type in 60 FPS. When I go to set FPS with my mouse I only get 58 or 62 FPS but not 60. Has anyone came across this before?",Sgtkeebler,2021-04-26 05:24:01,7,15,0.77
447,"I’ve always had HAGS turned off ever since I discovered that it causes performance issues in some games. To date, I haven’t experienced a case with my games where it brought more performance. It’s either performance is equal to if it were off or it causes degradation to performance. This was confirmed today when I was playing a game and my FPS were 20-30 frames below normal, no updates or changes to my hardware. I checked every setting I could think of and I came across the HAGS toggle that I must‘ve accidentally switched on a few days ago. I disabled HAGS, rebooted and bingo my game is running as expected.

When HAGS was first introduced I determined then that it was a feature that I can live without because my testing yielded bad results. Is there a specific case scenario where it may be beneficial as it relates to gaming, e.g., cpu/gpu bound instances?",Siroht,2021-04-26 02:42:00,21,30,0.88
449,"As the title says. I am looking into fluid (wind) simulations and content from 2016 etc. keeps coming up regarding Flex.

Is this still the way to go?",farox,2021-04-26 01:01:42,8,1,0.75
452,I would like to replace the pads on my MSI 3060 TI Ventus 2X and was wondering if anyone knew the pad thickness so I can order in advance. Thanks,EarlOfFunk,2021-04-25 21:59:01,2,5,0.6
453,"Is anyone running SLI for Cyperpunk 2077? I changed one of the profiles after watching a YouTube how to do SLI for the game.

Is anyone else running SLI or just a 2080 RTX TI?

If so what are your settings for 1440 p ?",thedemoncowboy,2021-04-25 21:47:48,4,11,0.67
454,So I've seen that Nvidia has decided to open up GeForce cards to virtualization again finally. As a VMware workstation user is it now possible to passthrough my 1060 to one of my Linux virtual machines? Any information is greatly appreciated!,Solaire_praise_sun,2021-04-25 19:39:19,9,3,0.86
457,Keep seeing inconclusive results. Some say not needed. Some say it's severely power limited. I wouldn't mind shunting mine if there was a good gain. I am running waterblocks. Is there performance to be gained?,jetleepaints,2021-04-25 17:05:56,4,11,0.83
458," 

Hi guys,

I'm having a bit of an annoying odyssey going on with my 2080 Ti Strix. One of the fans started becoming noisy, probably because of a broken bearing. So I googled the part number of the fan and ordered a matching one from Ali Express. 4 weeks later I got the fan and put it on the card, only to find out, that it would constantly speed up and down. So I ordered the whole aray of all 3 fans and put them on the card - didn't work properly either. I disassembled one of the new fans and found out, that the wiring is mixed up compared to the original. Thought about starting a big resoldering action, but I don't have much trust in my rusty soldering abilities.

Then I had an idea - why not just slap 2 Noctua NF-A12x25 straight onto the heatsink with zip ties? Anyone here who already did this sort of thing? The card has two additional 4 pin connectors, so I should be able to hook up the fans with 2 adapters. As far as I know I can only control the fans with the corresponding Asus software then - or will it work with 3rd party fan control software too?

Normally I would just buy a new card, but you know how the situation is at the moment.

Any help is appreciated, thanks!",KobraKay87,2021-04-25 16:03:46,4,8,0.83
459,"I only use my 3080 for gaming, no mining at all and nothing else I do with my PC is GPU intensive.

I run into periodic crashes in Black Ops: Cold War, especially in Zombies Outbreak.  I am tempted to open my 3080 FE and replace the thermal pads.

I've found a decent number of posts where miners talk about the benefits, and a small number of useful diagrams like [these](https://i.imgur.com/9nShJxc.jpg) [two](https://i.imgur.com/2TsPW5d.jpg), but those are for non Gelid pads, and I've read about posts with people using thicker Gelid pads with all 2mm on one side, and all 3mm on the other. (which is different from the links that suggest 1.5mm and 2mm pads on the same side for less soft thermal pads)

Does anyone have any clear diagrams, failure/success stories or just first hand knowledge around upgrading the thermal pads on the 3080 FE that they can share here?  I'd be especially interested if anyone has any positive stories around improved stability in games after upgrading the thermal pads.

Thanks in advance!",jxnfpm,2021-04-25 15:56:15,13,14,0.84
462,"&#x200B;

[https://www.youtube.com/watch?v=jwsT-lE4X9Y](https://www.youtube.com/watch?v=jwsT-lE4X9Y)

It looks pretty good:

[https://perschistence.itch.io/art-mark](https://perschistence.itch.io/art-mark)

>The benchmark is especially designed to bring modern graphics cards with Ray-Tracing support to its knees, but it is also possible to be executed on hardware that does not support Ray-Tracing. In that case the benchmark is simply using Screen-Space and Planar Reflections, rendering for example 7 instead of one viewport to get as close to Ray-Tracing generated effects as possible.   
>  
>The tech used to render the reflections is highly configurable and scalable. This could be especially interesting if you are keen to see how classical rendering compares to the modern Ray-Tracing approach.   
>  
>Because of its scalability the benchmark is capable of showing the limits of even the newest RTX GPUs without even the need for dedicated DXR support if not available.

The D/L is free although the creator asks for an optional donation.  It's a 1.4GB zipped DL from Google Drive.  I haven't scanned it and am D/Ling it now :)",apoppin,2021-04-25 14:27:47,11,13,0.87
466,"Hi guys
I have a waterblock for this GPU and I wanted to know if there is a guide or video to dismantle this Gigabyte GPU please",NitrousX123,2021-04-25 08:27:10,5,2,0.85
473,"Thought I would share an interesting story of my setup. I had been using a z270 with 7700K with a GTX1080 for a long time. In November I was lucky to score a 3070 which I put in this machine. All worked ok. After some time, I started wondering is the 7700K was bottlenecking. So I decided to do a longer test. In my office I had a z490 with 10700KF,. So I switched the motherboards around also to get RBAR. First I just ran a few benchmarks and short game sessions to look at FPS, and I was happy it was of course a bit more. BUT after I started properly playing games (longer than 10 minutes) I started getting crashes in almost everything I played. From Horizon Zero Dawn, I got the ""Unfortunately the game has crashed"" error. On RDR2 I got the ""ERR_GFX STATE"". And on Wildlands and Far Cry 4, simply th game would exit to desktop suddenly.

I thought it was a driver issue, so I played around with many different versions, and I thought it was solved at one point, BUT then again, crash. I started playing with lowering the clocks and everything, undervolting. Also, it did not help. I was at a loss. I even thought the 3070 was faulty. BUT then I remembered how it did work on the z270. 

I switched the GPUs back, tried using the GTX1080 on the z490. To my surprise, it crashed the same way. SO, I then put back the z270 mobo and the 3070 there. And all problems are gone.

Seems there is something fishy with that mobo. Moral of the story, a problem that seems to come from the GPU can come from somewhere else. I would have expected a mobo etc problem to make the whole system crash, bluescreen, reboot etc, but no. Just games exited and crashed WITH error message screen (which I then googled and foudn all sorts of ""solutions"" which did nothing)

So there you have. I will stay with my 7700k and 3070. I am getting 100+ FPS on everything, so it is enough :) I don't actually see a real-world difference in say 105fps vs 120fps. Maybe later some day, I will get an AMD mobo with DDR5. But for now, I am ok.",Boogertwilliams,2021-04-24 22:33:25,0,9,0.5
477," Hello everybody,  
 

   I need your help with replacing stock thermal pads on my 3080 XC3 for  ''aftermarket'' that will help decrease memory junction temperature.  
As you already may know,GDDR6X memory is very,very hot and despite  Nvidia claiming that high temperatures are normal,I'd still like to  replace thermal pads.  
I started mining Ethereum last month and I wanted to see how it will  go,because I wanted to use GPU while I'm not gaming for extra profit.  
It turned out it mines pretty good,so I stopped playing games and I continued to mine constantly.  
I had good temperatures around 86c average,and highest were 92c.We're  talking about memory junction temperature of course,not the GPU  temperature itself.  
Today,I checked my PC and current temperature was 110c with 112c being max.  
I was pretty shocked and worried,so I turned off my PC to get a little break.  
Today ambient temperature was somewhat higher than previous days,so that definitely caused the temp increase.  
 

   I have one huge request if I may ask...  
I have one store in my country that has good selection of thermal  pads,so I wanted to ask you if you could please tell me what size and  thickness of pads should I order for my model?  
I would like best results of course and I heard that it's possible to  replace pads on both memory and backplate,but they require different  pad size.  
I would like to install pads on both places to get lowest temperature possible.  
Also,should I pay attention for thermal conductivity ratings or are they ''irrelevant''?  
Since I obviously don't know anything about pads,I would kindly like  to ask you if you could recommend fitting pads for my model on this  store (don't mind Croatian language,just concentrate on dimensions):  
 

[https://www.adm.hr/termalne-paste-i-padovi-0936/158/](https://www.adm.hr/termalne-paste-i-padovi-0936/158/)  
 

   And most important question,I heard that manufacturers don't approve  doing these kind of mods for GPUs,except for EVGA  and ASUS (only TUF  models tho),but I'm not 100% sure if EVGA approve it.  
Will I void warranty if I do this mod with my model?  
And if one day my GPU gets malfunctioned,will I have problems if I  send it to repair service in my local shop (I didn't ordered it directly  from EVGA)?  
 

   Thank you very much for taking time to read this.",ChrisRedfield-STARS,2021-04-24 20:22:51,0,17,0.42
480,"What does the scanning actually do, and do I need to close background programmes, like RGB software etc?",davidchrisr,2021-04-24 17:02:17,4,2,0.83
481,"So 

Got a email alerting me to stock at above website. 

https://www.box.co.uk/NED3080019IA-132AA-Palit-GeForce-RTX-3080-10GB-GDDR6X-Gamin_3183924.html

How unfair is that pricing from a company. Nvidia should take some action maybe start to blacklist companies who are pricing way over the asking price and try get some normality back",cunny1979,2021-04-24 16:56:32,4,29,0.61
486,"Can anyone give me a picture of the layout they used on their card that worked for them using thermal right pads. I changed mine yesterday with 1.5mm thermalright pads and the temps went from 98 to 104 C :(

EDIT: Founders Edition card

Edit 2: I added more thermal pads on the backplate side and saw no difference. Ill try 2mm thermalright pads tomorrow. Will keep this updated

Edit 3: Added the 2mm thermalright. The memory temps dropped from 104 to 80C which is amazing, however the core rose from 58 to 76 without applying a core overclock. This leaves the only option of getting Gelid 2mm which will offer the size but softer padding for better gpu core temperature.I'll order a pack and update when i apply them.

Edit 4: Changed the thermal pads on the core side to gelid extreme 2mm. This is the only option worth changing too.If not available where u are stick to stock. My memory temps hit a max of 86C with +800 Mhz on the memory clock. :D",kotsiosfire6,2021-04-24 10:00:12,1,12,0.55
489,Hello everyone I am fairly new to this so I would like to ask what thermal pads would be great for an AORUS 3080 Master 10GB? Which brand and size would be awesome to know. I’m also hearing the Memory line needs a size smaller of thermal pads going across. Thank you I appreciate it.,BocaBk809,2021-04-24 01:59:46,0,1,0.5
492,"I did one Fire Strike Extreme test before and after undervolting and here are the results :  
Before : [https://www.3dmark.com/fs/25353167](https://www.3dmark.com/fs/25353167)  
After : [https://www.3dmark.com/3dm/60981988](https://www.3dmark.com/3dm/60981988)  


I only did it to get better temps because my AMP Holo used to get around 68-72c while playing cs go, now I am at about 55-65c

Here are my settings that I used in MSI Afterburner :  


My Voltage Curve :

https://preview.redd.it/bvnfsz9si0v61.png?width=1364&format=png&auto=webp&s=660e6bb4c864e98005f58d3317915882eb386f3d

My Memory Clock and Fan Settings :  


https://preview.redd.it/5ocb1uwyi0v61.png?width=405&format=png&auto=webp&s=0721d7e5df279a95c88dd90f45394f6bd932b068

So is everything fine or is something messed up? Because I don't want to break my graphics card and I never did an undervolt or OC before and I did all this based on some tutorials on YouTube...",iMrGreene,2021-04-24 00:06:29,3,9,0.67
493,"Nearly 5 months ago, I made [a post](https://www.reddit.com/r/nvidia/comments/k4hqgk/performance_improvement_by_repasting_and_adding/) on here about how adding a few thermal pads to the back of the PCB improved performance and I noticed less stuttering while gaming in Red Dead Redemption 2.

Back when I did this, HWInfo64 and other utilities only reported GPU temperature, no GDDR6X junction or GPU hotspot temperatures. I eventually put a Corsair XG7 waterblock on my 3090 FE and left it at that.

Shortly after doing this, HWInfo64 was updated to show GDDR6X Junction and GPU Hotspot temperatures and since there have been many posts on Reddit and YouTube proclaiming 20-30c drops in temperatures depending load the card is being placed on.

I decided to order some 1.5mm Thermalright Odyssey thermal pads to see this for myself. I ordered the pads off Aliexpress and they took around a week to arrive, if you order the 120x120mm pads, a single one is enough to cover the front and back of the PCB. If you order the 85x45mm ones, you will need three of them to complete this mod.

I used the [cutting template for the RTX 3090 FE](https://www.reddit.com/r/nvidia/comments/mmzri2/3090_fe_thermal_pad_mod_cutting_template/), courtesy of /u/GoodToForecast and [here's what the front and back of my card looked like](https://twitter.com/ghost_motley/status/1384640547852361728/photo/1)

Now unfortunately I don't have any direct before and after comparisons, because the last time I had the air cooler on the RTX 3090 FE with the original pads was before HWInfo64 showed GDDR6X junction and GPU Hotspot temperatures, but based on the results of others, it's safe to say my GDDR6X junction temps were probably peaking at over 100c, if not hitting 110c and throttling.

[After doing the mod and running Furmark for over an hour, with power and temp limits maxed in MSI Afterburner, GDDR6X junction temps reached a max of 94c](https://twitter.com/ghost_motley/status/1384649088780673025/photo/1)

[After two hours of Assassin's Creed Valhalla, with the power and temp limit maxed in MSI Afterburner, GDDR6X junction temps reached a max of 88c](https://twitter.com/ghost_motley/status/1384929283093803010)

For both Furmark and AC Valhalla, I left the fan speed at auto.

My results seem to confirm what everyone else has had, replacing the stock NVIDIA thermal pads and adding thermal pads in other areas seems to reduce GDDR6X junction temps by around 20c~, give or take a few degrees in either direction depending on the exact thermal pads used and your application.

One thing I will note, is my GPU temps seem to be higher after doing this, back when I had the stock air cooler and stock thermal pads, I remember my GPU temp hovering around 60c, whereas after this mod, my GPU temp hovers around 70c; both default fan curve.

I think what happens here is the fan curve of the GPU is based on GPU core and GDDR6X temps. With the regular pads, my GDDR6X was likely above 100c, causing the fans to ramp heavily, if I remember correctly, the fans would hover around 1800-2000rpm while gaming.

After this mod, the GDDR6X modules run much cooler, so the fans don't ramp as much and this results in a hotter GPU core, while gaming the fans tend to hover around 1200-1400rpm, which is honestly not that noticeable.

So for anyone else out there with an RTX 3090 FE, if you don't want to throw a waterblock on your card, replace the stock thermal pads.

Your card will run cooler, quieter and perform better.

If I had known about this mod originally, I probably wouldn't have watercooled my 3090. I'll probably go back to watercooling the card eventually, because in the last few months I've spent way too much money on radiators, pumps, blocks, tubings, fittings to just go back to an air cooled card.",GhostMotley,2021-04-23 22:35:56,10,9,0.75
495,"I'm trying to get my IBM T221 set up, and nVidia's drivers are detecting the monitor with the wrong resolution. It should show up as 2 1920x1200 monitors (each side of the monitor is its own DVI-I cable which I'm adapting to Displayport), and then they get combined using Mosaic. I figured I could just set a custom resolution and fix it that way, but that option is grayed out. No, I don't have DSC on, since I know that will get asked (I dont even have an option for it actually). All other info is detected right (ie 48hz refresh, 32-bit colorspace, that the display is ""IBM Digital Display,"" all of which is as it should be). I'm stumped at this point. I know the monitor isn't the issue since if I plug it in to my Matrox card or my ATI card (The Matrox being built for the monitor specifically and the ATI supporting it), it works just fine. 

Suggestions? 

tl;dr: Custom resolution option grayed out, detecting as 1920x1200 when it should be 1920x2400.",TovarishchKGBAgent,2021-04-23 21:18:12,0,1,0.5
501,"The question above says it all. Additionally if you can provide some guidance on the side note I'd appreciate it.

With G-Sync Off, 1440p Ultra RTX On (All Max/Ultra) and using DLSS Ultra Performance (New Update) I am able to get up to 175fps on COD Warzone.

Side Note: If I enable G-Sync the game refresh rate gets limited to the monitors refresh rate which is 119.998Hz (effectively 120Hz). It stays locked 119-120fps then. - Power management is set to Ultra (Windows Control Panel + Nvidia Control Panel)
- V-Sync OFF in Game and in Nvidia Control Panel
- Min/Max Frame Rate set to OFF
- Preferred Refresh Rate set to Application Controlled
- Unlimited Frame Rate is ON

System: RTX 2080Ti FE Core 2040MHz, Mem 7700MHz @ 70C, i9-9900K 5.0GHz @ 65C. Driver: 466.11 and latest Windows. Can OC GPU more.",Shelby_Sheikh,2021-04-23 19:05:57,0,17,0.43
509,"I’ve been checking this subreddit every now and then for any potential details or improvements on the supply situation, as I am still waiting to upgrade. But I’ve come across numerous posts covering thermal pads and temperatures. What’s going on here?

Is it some fault in the card that need to be manually fixed or is it some modification people are just experimenting with? Since I hope to get one in a couple of months I’d like to know beforehand whether this is something I should think about.",Mariosam100,2021-04-23 07:28:51,11,61,0.73
511,"A lot of people are saying to go for a 1440p 144hz for this gpu. What are some good ones?? And should I get a ultra wide or just a curved. I really want a curved monitor after trying one at my microcenter. 

Budget is about $400 MAXIMUM. Maybe a little over if it’s worth it",CINCOxBINCO,2021-04-23 01:22:37,1,24,0.55
512,"&#x200B;

[Two days after installing new 1.5mm pads on RTX 3080 FE](https://preview.redd.it/c6tsprrjktu61.jpg?width=1199&format=pjpg&auto=webp&s=83ac160c88d95b01eeac5714dd6821e236d9305d)

Hi all, just wanted to post a quick update following my post two days ago.  The 1.5mm TR Odyssey pads have settled nicely and MHS temps now down to 66c with a low ambient room temp.  I wont bother adding more pads now.",Silent-OCN,2021-04-23 00:42:56,1,13,0.54
515,I heard that the 3090 had issues with the Odyssey G9 monitor. Does anyone know if this has been resolved?,HellenKellersSenses,2021-04-22 20:59:46,7,8,0.82
518,"Hi all,

I replaced the thermal pads on my 3090 FE but am still getting temps in the hundreds on the vram junction. I think the mod was an improvement since it’s no longer thermal throttling. However I want to try to reduce my temps to below a hundred.

For all I know, I did the mod correctly, but I am now wondering about that. Just wanted to see if anyone knew anything about the following:

I used thermalright 1.5mm pads. I put the sticky side directly on the vram (with the rough side/blue side facing out). Is that the right direction? Should the blue/rough side be touching the vram instead? Maybe the mod won’t work as well on some gpus.

I followed this [video](https://youtu.be/G3260LR2JzQ), it’s not clear to me which side of the thermal pad is facing the vram.

Any pointers on what could be the culprit? Based on looking at some posts here, I know not all mods have been successful.

I have some extra pads so will be able to redo the mod.",_elogovna,2021-04-22 14:31:02,0,14,0.5
519,Just the title.,rnzerk,2021-04-22 13:46:05,9,22,0.8
521,"is there any risk to damage the gtx1660 super oc gygabite series installed with gameready driver if i have installed dlib with python 3.6 without visual studio if i set  

    dlib.DLIB_USE_CUDA = True

. to use cuda cores from gpu for face recognition. or is there something before i had to do to decrease damage risks ? 

before i buy that gpu i just use a 6 core cpu default but it it work little bit to slow for me. 

i like to play games too is there any risk if i use the gpu for gaming and KI work on same system?",patty_not_gates,2021-04-22 11:57:57,2,3,1.0
523,"I'm sharing this for those who are dealing with terrible GPU coil whining aswell, maybe this helps someone too.

I have  GTX 970 and the could whine on load was terrible.

So, I just tried out changing the power cable from using one 6 pin daisy chained cable into two 6 pin cables. And see there, the coil whine got reduced significantly. I would say it 95% quieter now, barely noticeable and I can't hear it with headphones at all anymore.",noobatanything,2021-04-22 00:02:33,30,24,0.84
524,"I run what's probably an unimpressive battery of test and analysis with each driver version. I felt maybe I should share it.

&#x200B;

My goal here is just to make sure there aren't crazy regressions in performance from one version to the next. I try to test DX11, DX12, Vulkan, OpenGL, DLSS, and RT with a focus on getting results for 4k resolution, as my target in most games is to run at 4k with minimum FPS around 55-60.

&#x200B;

I don't do any frametime analysis or any of that. I don't intend to either. I most likely could never do as good a job as the other benchmark posters here anyway.

&#x200B;

I do repeat tests if I see results that might be outliers in order to confirm results.

&#x200B;

Stock means stock clocks but changes in nvidia control panel (set power for max performance, disable g-sync)

&#x200B;

oc means bumping up power limit to 107%, temp limit to 88, mem clock +200, and a core clock curve generated by MSI AB.

[Core clock v\/f curve generated by MSI AB](https://preview.redd.it/p1xhd2zkylu61.png?width=796&format=png&auto=webp&s=46876fe8eb7b9dfb667d21302bf7e083aa95c034)

&#x200B;

I do my best to keep everything the same for driver version to driver version comparison. Minimal background processes, etc.

&#x200B;

I don't re-do my benchmarks with upgrades other than GPU drivers for the most part, though, so its possible software upgrades, windows updates, or BIOS updates could have some effect here.

&#x200B;

Have uninstalled prior drivers etc with DDU for as clean as possible install.

&#x200B;

System Specs: 

* EVGA GeForce RTX 3080 XC3 Ultra
* AMD Ryzen 7 5800X
* 32GB RAM - Crucial - DDR4-3200 - dual channel
* Gigabyte B550 Vision D - Bios ver. F12
* Samsung 980 Pro NVMe - Pcie 4.0 speeds
* Windows 10 version 20H2 build 19042.928
* Resizable BAR is enabled/possible (although probably doesn't impact any of these benchmarks as far as I know)
* HAGS is disabled in windows display settings

&#x200B;

Tests I run:

* 3DMark DLSS - 4k - performance
* 3DMark DLSS - 4k - quality
* 3DMark - Port Royal
* 3DMark - Port Royal - 4k
* 3DMark TimeSpy
* 3DMark Time Spy Extreme
* GFXBench Aztec - High - 4k - DX11
* GFXBench Aztec - High - 4k - Vulkan
* Heaven - Extreme - DX11
* Heaven - Extreme - OpenGL
* Superposition - 4k Optimized - DX11
* Superposition - 4k Optimized - OpenGL

&#x200B;

Here are some results.

&#x200B;

466.11 - stock

* Average comparison to prior drivers: 99.97% (negligible decrease in performance)

[466.11 benchmarks - stock - with comparison to previous drivers](https://preview.redd.it/q4na5s50xlu61.png?width=620&format=png&auto=webp&s=5b3e5dedbaac7bdb3cb33ebd94c0f5c3cf0fe523)

&#x200B;

466.11 - oc

* Average comparison to stock: 103.29%

[466.11 benchmarks - oc - with comparison to previous drivers](https://preview.redd.it/2hjwowp1xlu61.png?width=620&format=png&auto=webp&s=f6af5cf5eed00d4584d85b366f60f1cf7198e13b)

&#x200B;

If you have any questions I'll try to answer them.",Whiteboyfntastic1,2021-04-21 23:10:42,29,18,0.79
527,"Just did thermal pad replacements on my 3090 FE. Haven't seen anyone use this thermal pad yet, thought I'd share the results:

**Thermal Pads:**

GELID Ultimate 15 W/mK Thermal Pads 1.5mm (2x 2-pack)

[https://www.amazon.com/gp/product/B08PKF9316/](https://www.amazon.com/gp/product/B08PKF9316/)

**Thermal Paste:**

Thermalright TF8

[https://www.amazon.com/One-enjoy-TF8-Performance-Interface/dp/B07K442WXV/](https://www.amazon.com/One-enjoy-TF8-Performance-Interface/dp/B07K442WXV/)

&#x200B;

**Results:**

*Peak Temperature after 10 minutes of Furmark Stress Test (1440p Default Settings):*

**Before:**

Core: 66C

Mem: 98C

**After:**

Core: 65C

Mem: 80C

&#x200B;

*Ethereum Mining (6 hours @ 55% fan):*

**Before:**

Core: 64C (I think)

Mem: 106C steady state, 108C peak (occasional)

**After:**

Core: 62C

Mem: 92C steady state, 94C peak (rare)

&#x200B;

*Gaming (Control at 4K Ultra RT Ultra DLSS 1440p for 2.5 hrs - Max Temperatures):*

**Before:**

Core: 70C

Mem: 96C

**After:**

Core: 70C

Mem: 86C",devious_burger,2021-04-21 20:38:29,31,60,0.78
530,"by defalt, my rtx 3070 runs at 0.9 volts at idle, is that normal?",Nyancathulu,2021-04-21 17:09:49,10,9,0.74
531,"I mainly play league of legends ,my settings were always low latency mode off ,gsync on , framerates cap at 200 in game  ( i have 144 hz ) monitor and v sync off in game and in control panel.

However i test currently ultra low latency mode + gsync + vsync on in Control Panel ( Vsync in game off ) and my fps are capped to 138 without me capping it manualy. Does it create any imput lag? I dont really know what settings are the best for the least input lag in the game . My GPU is 1060 6gb with 144hz gsync monitor.",fadedv1,2021-04-21 15:55:56,8,15,0.83
532,"If you have an MSI Z370 motherboard, MSI just released on 4/20/2021 a revision 2 beta BIOS to support Resizable BAR, and removed the previous beta BIOS.  I believe its available now for all Z370 boards, mine was one of the latest to get added for the previous version, I only pulled down yesterday and this morning I see the new version released.

Examples of MSI Z370 boards I checked showing the 4/20 BIOS v2 release...

[https://us.msi.com/Motherboard/support/Z370-SLI-PLUS](https://us.msi.com/Motherboard/support/Z370-SLI-PLUS)

[https://www.msi.com/Motherboard/support/Z370-KRAIT-GAMING](https://www.msi.com/Motherboard/support/Z370-KRAIT-GAMING)

[https://www.msi.com/Motherboard/support/Z370-GAMING-M5](https://www.msi.com/Motherboard/support/Z370-GAMING-M5)

[https://www.msi.com/Motherboard/support/Z370-GODLIKE-GAMING](https://www.msi.com/Motherboard/support/Z370-GODLIKE-GAMING)

Edit - got some time to do a bit of testing and my Z370 SLI Plus board on this BIOS nets 7% on AC Valhalla and 4% on RDR2 at 1440p with ultra-ish custom settings, 466.11 driver.  I tried some other games with built in benchmarks but the average fps inconsistency between runs on those games were all over so I gave up on them.  ACV and RDR2's built-in benchmarks are super consistent, its less than 1fps average difference between each run at the same settings.  Happy with the results - I can keep this system around for another 2-3 years till DDR5/next-gen stuff gets matured enough and still get the benefits of GPU developments.",NoctD,2021-04-21 15:52:13,247,29,0.98
533,"I wanna pair it with a ryzen 5 5600x

btw what is the best combo CPU/GPU combo for 1440p gaming? Is it this?",leonidas_164,2021-04-21 12:32:53,261,276,0.93
534,"Hi,
I might get an ASUS Strix RTX 3070 for 1000€ or an ASUS RTX 3080 for 1350€. Which one should i get? I am tending to the 3070.",LWJG929,2021-04-21 09:00:14,0,43,0.41
535,"Hey guys, I already searched the web for a guide how to change the pads, didn’t found anything so far. Does anybody know which thickness I need for it? Also I’m not kinda sure if it’s worth replacing them since it’s a pure gaming rig. While playing BFV for example memory temp is around 80-85 degrees, what do you think? Thanks for your advice!",Replica90_,2021-04-21 08:18:32,3,7,0.67
536,"Hey everyone, i am thinking about to buy the new legion 5 Pro, but i am not sure which cpu and gpu combination will be the best and enough to enjoy the 2k gaming and the full potential of this Machine, 5600h+3060 / 5800h+3060 / 5800h+3070 ?",Nezvanyhostt,2021-04-21 04:52:36,4,8,0.71
537,"I am looking for a device that can stream games at 4K 120Hz via ethernet from my RTX 3080 powered PC. 

The newly announced Apple TV 4K looks like it might be capable of this via Steam Link, as it comes with HDMI 2.1. 

However, Apple did not officially announce 120Hz support yet. Also, I don't think Steam Link supports 120Hz - that's only possible via Nvidia Gamestream. 

So a new Nvidia Shield might be the only way this will be possible.",fieryfrolic,2021-04-21 02:51:20,14,19,0.85
538,"I tested using a 55R635, RTX2070 (mobile) and Star Wars Battlefront II.

4K 60Hz + HDR - No issues of any kind

1440p 120Hz + HDR - Every once in a while (anywhere from 1-3 times per minute) there would be a single black frame flicker. IMO it was not a deal breaker and would not break you out of an immersive experience. It could be that it occurs at a very specific refresh/frame rate, say for example 107fps/hz, as sometimes it would not happen for a while, and then occasionally I'd get one or two back to back within a few seconds, and it did appear as if there was some sort of correlation.

Note: While the 2070 would support G-Sync after forcing it on, a GTX1080ti would not, as the HDMI ports are older spec. It appears that HDMI to Displayport conversion while preserving any kind of VRR is not possible, as there are different standards used for HDMI and DP that can't be converted easily, or at all. So you will need a 2000 series or above to work with the R635's VRR.

Didn't really see anyone post anything conclusive about this, so thought I'd make a post. Hopefully this helps someone shopping out there. It was so smooth and snappy when it was working, and the fact it worked with HDR so flawlessly as well was great.",StabYourFace,2021-04-21 00:00:48,13,11,0.89
539,I'm currently looking into getting a RTX 3090 and the GALAX HOF in my country is currently $400 cheaper than ths Strix and $150 cheaper than the TUF gaming. Is it a good deal or am I better off with Asus?,uwot_m9,2021-04-20 20:19:37,8,41,0.75
541,"Last night I was doing some temp tests on my GPU and saw it was capping around 77-80c and thought cool, this is okay. Well today I see a post about how theirs is throttling to stay around 80c. So this had me thinking, is my card running too hot and not getting full performance, and downclocking to stay at 80c?",Random-Posterer,2021-04-20 16:06:36,7,20,0.73
542,"Hi I was wondering why there is absolutely no problem for shadowplay to encode 60 fps 1440p when I record but when I use my graphics card to encode 60 fps 1080p all of a sudden I get hardware overload and framdrops in obs? are they using different things to encode or is there a problem with obs?, I got a gtx1080 btw and a i7-8700k",WrapWonderful610,2021-04-20 15:36:06,4,6,0.84
543,"First off thanks to u/[Vegetagoat](https://www.reddit.com/user/Vegetagoat/)  and u/[falkentyne](https://www.reddit.com/user/falkentyne/)  for helping me out.  I redid the pads front and back and put new paste down.  Initially the gpu didnt boot and fans ramped to 100% (the gpu core wasnt making contact with the heatsink.  This was with 2mm pads core side, so I switched to 1.5mm pads all around (thermalright odyssey).

[Stock temps](https://preview.redd.it/3t1flsurwbu61.jpg?width=573&format=pjpg&auto=webp&s=d5f00933a09f554600db81a2a81aca0ddced1a84)

&#x200B;

[New pads temps](https://preview.redd.it/hrsp7q2twbu61.jpg?width=566&format=pjpg&auto=webp&s=229066077f3fd86d6150b0487f319b7735c785c0)",Silent-OCN,2021-04-20 13:18:43,263,186,0.96
544,"https://ibb.co/HDCZHV6

Can someone help me understand which parts I'm supposed to repad please. I can't understand why only half of the chips on the 3080 have Nvidia thermal pads on? Is there a specific reason for this?

Thanks",Silent-OCN,2021-04-20 10:55:20,0,5,0.38
547,"I have been using a custom water cooling loop for a few years now.  When I got my Tuf3090 I immediately installed the Alphacool waterblock on the card. Results seemed good and I was happy.  A few weeks ago I decided to use my GPU to run Nicehash when it would otherwise be idle or off.  That's when I found out my memory junction temps were through the roof.  As soon as I started mining immediately went to the 90s and stabilized around 108c.  So I started looking for a solution to this problem.  I found the [MP5Works] (https://www.mp5works.com/store/) backplate cooler. [Installed](https://imgur.com/zSovL7E)  It's not CHEAP!  But damned if it didn't work great for me.  [Results!] (https://imgur.com/BvtFEu9).  Full disclosure I did replace some of the pads from Aphacool with those that came from ASUS.  I'm blown away by the results!  I hope this can help someone else to tame the high memory thermals of the 3090. 

Bottom line:  my memory temps went from 110c max to 70c max. 40c drop!",stewdawggy,2021-04-20 07:50:17,11,37,0.73
548,I have a geforce rtx 2060 and it has this super bright light on the side of it. Is there any way to turn this off? If there isn't that should be added asap. It can be annoying at night if the screen is dim or I need to leave it on overnight for an update/download.,Chellzie,2021-04-20 03:59:52,2,13,0.67
550,"Hello there! :-)  
I am here because I thought something but I don't know if it's possible.

I play games at 1440x900 because I can use 75Hz instead of 60Hz (+I get decent fps) but this makes things a lot blurry since my native resolution is 1920x1080p. I recently discoverd DSR (Dynamic super resolution) and I was wondering... is there any way I can use it on a non-native resolution like the one I use to play (900p) to scale the image better and get rid of the blurry image?  


I know this is not the DSR goal, what I know is: it works with my native resolution; so my real question might be... is there any way I can trick my computer to make it think my native resolution is 1440x900 and use the DSR on it?",campajolamariano,2021-04-19 23:52:35,5,24,0.86
552,"I run a triple monitor setup, and my 1080ti has 2 display ports and 2 HDMI ports. I have been using an HDMI port for one of the monitors and this is not an issue since I play most games on one screen. Although I use all 3 for sim racing, is there any way I can use a splitter to enable gsync on the last monitor?",AmbitiousNut420,2021-04-19 21:30:25,8,14,0.73
553,"Does anyone have any idea how to get the lights on the 3090 to stay lit while in windows 10?

When the system boots up, the GeForce light is illuminated, but turns off when windows hits the login screen.

I’m running GeForce Experience and have tried both Studio and Gaming Drivers, but same thing.

Anyone know what’s up?",TerrryBuckhart,2021-04-19 20:58:57,7,8,0.74
554,"So, I am looking to buy 3090 in Germany. Have a friend in Bremen who would pick it up. He's not into this topic but willing to help. I would like 3090 FE, kingpin hybrid or rog strix. Any tips for tracking drops?  Thanks and good luck to all hunting them.",blazing_MO,2021-04-19 16:58:45,18,29,0.75
555,"Does anyone have experience with buying on [caseking.de](https://caseking.de), with all the GPU stock problems lately?

I see they have a lot of GPUs with decent prices but most of them say ""On order"".

>We have ordered the item, but did not receive a confirmed delivery date for it from the manufacturer or supplier. A delivery time estimation cannot be given for this item. 

&#x200B;

Any idea how long do I wait for these? A week or two, sure, but few months...",None,2021-04-19 16:01:03,4,24,0.65
557,"Recently, I've heard that there was a lot of changes in prices of the msrp of these cards. I know that the founder's edition is going for msrp but I don't know about the others. Can anyone tell me any 3060 ti (like for an example evga,msi) that still sells their cards for msp and where. ( I am aware that it would be hard to get the gpus though)",thatonekid9191,2021-04-19 15:04:55,3,12,0.64
558,"Testing this card while running Heaven benchmark, hwinfo is showing 245 watts and power limit is reached. However, I checked gpu z and it's showing bios power limit at 350w. Does anyone know why it might be power limiting at 245 watts, occasionally 250 watts??

This card only has a single 12 pin plug that goes to a 2 x 8pin adapter (weird for a water-cooled gpu right)

[Link to card](https://www.techpowerup.com/gpu-specs/asus-rtx-3070-ekwb.b8362)

[Link to bios for card](https://www.techpowerup.com/vgabios/229259/229259)",Knightfully,2021-04-19 14:29:35,8,20,0.84
561,"I have seen quite a few threads on people looking for waterblocks for there 2060, none of them have a definitive answer on whether there is actually a specific block that works, if anyone knows of waterblock that is compatible with the 2060 please let me know!!",Pdieter96,2021-04-19 08:19:28,0,0,0.5
562,"Hi all,

I'm doing some ML and Pooling VRAM for higher batch size will be great improvement for my model.

At the moment I run on 1x3090FE on Ryzen 3700x and Gigabyte Aorus Elite x570 1.0 mobo. This board isn't good for NVlink for many reasons (spacing, lane types). I already have second 3090FE ready to go in.

 I'm looking for the board that:

&#x200B;

\- Is AM4 ( I can keep my 3700x)

\- Have two gen3/4  x16 pci slots

\- Both pci slots are using CPU lanes (rather than chipset/CPU)

\- Spacing is ok for 4 slot NVlink

&#x200B;

Thanks for advice.",zabique,2021-04-19 09:46:11,3,22,0.81
563,"G'day,

With full understanding of the global shortage of cards, I wanted to ask about what happened to retailer updates to the supply of preexisting orders, especially in Australia.

We have access to some rough details of orders that have been fulfilled by each big supplier, but It seems like no Australian retailers are updating their customers anymore on what's going on and the updated information coming into mid-2021 is becoming scarce.

I find it strange that one retailer has a 99% order fulfilled rate on certain 3080 cards and others have <20% and an oldest date without an ETA being launch date, 8 months ago, for the same card.

&#x200B;

I'm chasing some more information on the supply is, specifically in Australia.

&#x200B;

EDIT

&#x200B;

PLE have updated their website with new information regarding their supply.",SiiqGO,2021-04-19 09:38:58,9,12,0.86
564,"So I have been looking for this information but all the posts that came up where dead ends. Reached out to msi support and they supplied me with graphics for the thickness and size of each pad. Considering it can't be found I will share it here for other people that might need it, just like I did.

 https://imgur.com/a/a8jfq6U",GR3Y_B1RD,2021-04-19 09:20:40,17,1,0.83
565,"Years back I built a gaming computer for my brother in law from some random parts I had and a donor system from a friend when he built a new computer. Being the cool guy I am I took a GTX 980 out of my SLI build and put it in his system until he could buy his own video card. 

Well, that never happened and he kept the 980 forever until a few days ago when he spilled soda on his computer while it was running. It went right through the radiator and onto my GTX 980. Seemingly missing everything else. The monitor went black, and he shut the power off. Pulled the card and threw it into a bag of rice... He's a paramedic, not a tech...

[Here's the sticky 980.](https://i.imgur.com/PIyeKM5.jpg)

I took the 980 from him, gave him the other 980 so he can continue to game while I attempted to repair it. 

[Here's a few pictures from the procedure.](https://imgur.com/a/NFDcgMk)

I pulled it apart, used some electronic QD Contact cleaner, distilled water and alcohol and cleaned the back of the PCB with a toothbrush & some Q-tips.

Put it in my machine and... it wouldn't boot. I pulled the card out and put in my backup GTX 760,... still no boot. Error 38 then 45, memory error. FSCK, so I pulled the ram and reseated it one by one. Once reseating all the ram I was finally able to boot and get video. 

Threw the 980 back in and tried again, this time I got video! I had successfully repaired the 980. 

[Here she is running happily.](https://i.imgur.com/JqaLcXs.jpg)

But I couldn't boot to windows, took me longer than I'd like to admit to finally realize that resetting the BIOS threw my old machine out of AHCI mode and so it couldn't boot from my SSD but it appears to be back up and running.

So why am I posting this? Because in this day and age where videocards are a rare commodity, it's more important than ever to be proficient in repairing your own devices. Not that this was a difficult repair job, really it was just a cleaning but the 980 didn't end up in landfill or in a shadowbox on my wall. Instead it'll continue to game.",zushiba,2021-04-19 08:36:12,188,59,0.96
566,"Hello,

I'm going to buy a gaming PC (prebuilt one) next month, but I can't decide between two models. One has a 3060ti, the other one has a 3070 and costs 200€ more, I saw some benchmarks for both cards but the differences in performance seem minimal, I feel that the 3070 is just slightly more powerful than 3060ti and the 200€ seems not worth it.

Keep in mind that I will game with a 1440p 144hz monitor and also I have a 4k TV (60hz) which I want to play games on.

If needed I can link full specs of those two PCs.

&#x200B;

EDIT: Thanks everyone for your feedback, I'm leaning towards the 3060ti for now, but if for some reason I won't be able to buy the 3060ti build I'll go with 3070.",Unknown-Drifter,2021-04-19 07:37:17,14,32,0.75
568,"I'm an architecture student looking to buy a laptop for the next four years of my Bachelors Degree. I will be using Autodesk software (Mostly Revit) and rendering software (Lumion mostly). My teachers also put a lot of focus into design, so I will also be using Adobe software like Photoshop and Illustrator.

The Legion 5 with a 2060 is aroung 1099 USD, while the ASUS ROG Zephyrus G14 with a 3060 is around 1499USD. I could use those 400 dollars on something else, like an external monitor or something. But I really want a future proof laptop that won't feel obsolete in the next years. Is the price worth it? Considering a 3060 is a better card, the G14 is more portable with a better battery life.",concretebrut,2021-04-19 03:55:24,8,15,0.91
570,"There are scores of videos/articles about how to replace thermal pads out there, but I found it difficult to find information about my *specific* card (3090 MSI Ventus)... which in turn made me reluctant to do the swap.  I did it anyway, with great results, and learned a few things along the way - I hope my experience will help you make the decision.

First, a baseline for comparison.  I had already made some modifications to my card, so unfortunately I do not have a ""stock"" baseline to compare to, but substitute your temps for an estimate.  Before replacement setup: Ventus in an open case, 10 40mm aluminum heatsinks on backplate, 2 50 cfm case fans blowing directly on the heatsinks, and fans at 100%.  With this setup I was getting 96 degrees at 122m/h. 

New thermal pad setup: new pads on VRAM chips only, 1 50cfm over the die/ram chips *pulling* air, and fans at 100% (no heatsinks).  Dropped to 82 degrees at 122m/h.  With fans lowered to 85% I'm getting 86 degrees!  I also repasted the GPU die with good paste and dropped a few degrees on temp and hot-spot.

&#x200B;

Steps: The only thing you will need is an 00 size phillips head screwdriver, a ""normal size"" phillips head, some quality thermal paste, and *your choice of thermal pads\*\*\**.  I used 2mm and 3mm ThermalRight 12.6/k pads (front, back) because they had good conductivity and were the only thing in stock.  The 2mm are perfect, the 3mm is not (more on that later).  I first used curved tweezers for removing the fan connectors, but you could use your fingers (don't pull the wires).  Then remove all screws on the backplate, including the 4 that ""brace"" the GPU (whatever the term is).  Doing this will free *the front* of the card - the fan shroud and heatsink.  To remove the backplate there are a couple more screws on the inside, and you also have to take off the HDMI cover/support bracket off.

Once all 3 parts of the card have been separated (cooler, backplate, PCB), flip the PCB over so the GPU die is facing down (I positioned it atop of 4 rubber pads to ensure the GPU die did not touch anything).  Slowly peel off the existing thermal pads from the VRAM, trying not to tear them.  After, use paper towel, alcohol, and cotton swab to carefully clean up the oily substance -- only off the VRAM chips.  The oily stuff isn't harmful, so I didn't bother trying to clean it off of the PCB - just the tops of the VRAM chips so that the new pads would make proper contact.  This took a bit.

Looking at the old pads you can see where the pad makes contact with the chip, as well as the cooling pipes on the backplate.  They don't entirely cover the cooling pipes, and because the Ventus 3090 has a METAL backplate... I figured I'd cut the replacement pads a bit larger.  I was able to cut the new ThermalRight pad in such a way that 1 pad covered all 12 ram chips (for real, and with more coverage then previous).  However, to make it work with the size I wanted and only 1 pad, the 1idividual VRAM chip had to be covered with 2 pieces of pad instead of one.  At this point I reattached the backplate to the PCB.

I did the exact same thing on the other side - and applied the thermal pads directly to the VRAM chip instead of on the cooler.  Re-paste as you will; I tried to spread it out.  I then took the backplate/PCB, turned it upside-down, and put the GPU down onto the cooler.  I used the 4 screwholes around the GPU as guides to get the card down perfectly, then slowly screwed them all down until the screw stops (alternating screws as you go, slowly).  I used a razor to trim-back the thermal pad where necessary.  Put the backplate screws and support/cover screws, reconnect fans.  Done.

Process sounds easy, and the results are great - especially if you are throttling at 110\*.  It took me about 3 hours, and it was mostly planning once I had everything open (I had bought 5 thermal pads..).  I didn't repad any of the other components because they are not having cooling problems, their thermal pads looked good (if greasy), but most importantly I had *no idea* what the different thicknesses were and was more concerned that the GPU make good contact.  I did reuse a couple pieces of the OEM thermal pad on the back of the card, between the cooler and backplate.

ThermalRight 2mm pads are perfect for the FRONT of the card.  ThermalRight 3mm pads ARE NOT the perfect pad for the back of the card.  Others have noted this, and I echo their wish for a 2.5mm size as that would be perfect here.  The problem is that the ThermalRight pads are harder - they don't ""squish"" like the OEM or Gelid pads - even though they appear to be the same thickness if you put them side by side (pics if I post them).  Now because of this... the backplate is clearly bowed, and if you look extremely closely with a flashlight - there are tiny pieces of the thermal pad that aren't making contact with the back plate (specifically on the single VRAM chip).  The bow does not concern me, as it is just a piece of aluminum - it's not the PCB itself.  Also, it's not significant enough to impact any of the other cooling pads - it's pronounced directly above the 3mm pads.  After several days of gaming and mining - and the temps are as advertised - I'm not taking the whole thing apart again.

I wish I remembered to put thermal paste on the thermal pads.  People are doing it, I'm sure it cannot hurt.  I would also recommend going with the 3mm Gelid pads for the back.  No I don't have experience with them, but I've read they fit correctly.

I didn't reapply the heatsinks ... because why.  I also changed the setup of the fan: it made sense to have cool air moving over the VRAM chips themselves - not over the cooling pipes/backplate to the sides of the GPU, and I didn't want to be blasting air/dust onto the backside of the GPU.  There is a little bit of a gap (the backplate is bowed afterall...), and I didn't try any other combinations because the results were so good.  I could easily reapply several of the 40mm aluminum heatsinks.  I probably will for the hell of it.

If anyone's interested in some photos let me know and you can see exactly how I cut the pads.  My first Reddit post - I hope it is helpful.",farva0066,2021-04-19 00:17:49,3,2,0.62
574,"I'm looking to switch out the thermal pads on my 3080 FE as memory junction is hitting around 96c whilst mining with 90% fan which I'm not comfortable with 24/7.

Does anyone know the best pads to use to replace the stock Nvidia ones? I.e which thickness/brand should we use?

Also does anyone know if changing thermal pads is likely to invalidate the warranty?

Thanks",Silent-OCN,2021-04-18 20:20:38,1,20,0.54
576,"Hello reddit,

The title says it all.  I have the option to choose between keeping an EVGA XC3 3090 and an Asus Strix 3090, both at MSRP.  I plan on using the card for personal use (primarily gaming) and am curious if the Asus card is worth the extra $530 over the EVGA if both are going to be put under an EK water block.  Is there really that big of a difference in performance?  I've read the EVGA XC3 has some trouble cooling itself using the stock cooler, but this would be negated (at least mostly) with the water block.

One benefit of the Asus card is it has 3 PCI-E power slots as opposed to 2, but if I'm not overclocking again I'm not sure this is reason alone to keep the Asus.

Between the two brands I know the general consensus is EVGA has better customer service, but I'm just trying to look at this from purely a performance to value standpoint.

Thanks for reading!",pootie_tangg,2021-04-18 17:39:12,4,9,0.83
577,"Hey all 

Will be getting this case soon since I have seen and heard it's a great case and due to Lian li being out of stock it's a good time to get one and spend the extra on other parts 

Never put my gpu vertical before , which one do I need to do that? Is there a universal one or does it have to be from the same company ? 

Sorry I know a lot about computers , vertical gpu mounting is new to me lol",zombies--,2021-04-18 17:35:44,1,1,1.0
580,"Hello. I'm looking into buying a laptop for my brother. So far, I'm looking at the ASUS TUF laptop brand as it seems more available. Looking into the laptop variants of RTX 3060 (Mobile) vs. RTX 3070 Max-Q seems they have similar performance (fps) in the end when looking up on youtube and other sites (maybe a 10fps difference). 

&#x200B;

My brother is concern with just playing at 1080p at high settings. In the choice between the two laptop GPUs, which has the better performance to value? Does anyone have personal experience with these two GPUs they would be willing to share? 

&#x200B;

Any feedback is appreciated.",LastOffender,2021-04-18 15:31:24,4,8,1.0
581,"Hello Guys, I am looking to buy RGB Cables for my Rig as I am upgrading it anyway, I already have an RTX 3080 MSI Suprim X as it states in the title and I am currently using 3 seperate connectors (8+8+8), so I want to buy a 24 Connector for the motherboard anyways and wanted to ask if I could buy it twice and just use this one for the GPU aswell.   


Thanks in advance and have a great day :)",Kn0pfAuge,2021-04-18 11:18:48,0,6,0.3
582,"I mean do i have to go to the nvidia website to install the drivers everytime i want to update them or they get directly updated in Geforce experience?

Sorry for the question im kind of new in this",genuinecat88,2021-04-18 09:16:34,4,25,0.75
584,I have a 4GB 1050ti and been offered to swap for a 3GB 1060 mini + $25. I think that's it's a sweet deal but this guy is pushing hard to seal this deal. Should I go ahead with it?,thetopcow,2021-04-18 07:31:23,12,43,0.93
587,"I bought the MSI 3070 Ventus OC 3X fans, and I'm wondering if it's possible to take off the fans and replace them with better fans such as clamping some noctuas on it. Has anyone tried it with this GPU?

&#x200B;

Thanks",Mysterious-Ad-1541,2021-04-18 02:03:26,2,40,0.75
589,"I just got an Oculus Quest 2 to play Elite Dangerous and I overclocked my 1060 6gb to try and increase my performance through VR. It's a bit of a cracker since my card is barely able to run the game smoothly through VR so I need to fine tune every single settings I can.

When I play without VR, I get 60% GPU usage (at 144fps, 1080p) and my memory usage stays idle, which I find strange.

Going through VR (80hz, 4128x2096), my power usage goes up and stays at 100% (which I understand is normal) and I finally get an accurate value of the full 6gb of memory used.

Is it normal not to have any memory usage like that (without VR)? Is memory only used once the power usage is at maximum?

Also, is using the full 6gb optimal? I feel like keeping it barely under maximum usage would prevent stuttering and frame drops. So I should drop texture quality until I get a value of let's say 5.8gb.",Pelteux,2021-04-17 21:32:01,0,11,0.5
591,"I've tried multiple ways including re-pad the Vram on both sides, but when gaming the Vram temp still reaches 80-90 with a heater in the room. Not to even mentioning mining 

Then I realized that I could get something used to cool LED modules .here it goes ...on the top it is NF-A8 at 65% speed. there is gap that at the back of O11 case which allows the hot air escape from the heatsink. 

though it looks ugly but it works. dropped around 20C ish. 

Excavator Vram temp - default setting with power to 100% and undervolted core voltage . Fan 1 50%, Fan2 55% 

Before : 108-110 and throttle 

re=padded : 92-100 no throttlling 

added a heatsink : 80-86 

[Ugly solution](https://imgur.com/a/aCgiV58)",kemchen,2021-04-17 20:16:01,0,22,0.33
592,"Hi all, I have a Dell RTX 3070 that I bought off of someone who got it with a Dell prebuilt and didn't need the card (I believe the XPS 8940 desktop). It's in my Ryzen 3700x, MSI Tomahawk B450 MAX system and works great.

However, I've been trying to see if I can update the VBIOS on it to get resizable BAR working, but either I can't find the right VBIOS, or I can't find out who the 'true' manufacturer of the GPU is (if it is indeed just a Dell-rebranded, or rather, brand-stripped) video card. The only VBIOS update Dell shows online is [this one, which appears to be for Alienware laptops only, and doesn't install for me](https://www.dell.com/support/home/en-ca/drivers/driversdetails?driverid=4vv44).

The NVIDIA Control Panel and GPU-Z [only report Dell as the manufacturer](https://i.imgur.com/dFbzHsQ.png), so I'm assuming that I have to wait for Dell to release a VBIOS update for this card? Or will I have any luck looking for anything else?

N.B. I have the latest BIOS and chipset drivers installed on the MB, and the BIOS reports Resizable BAR is operation, NVIDIA Control Panel reports it is not active on the card.

N.B.B. Is it true that CSM won't support resizable bar, only pure UEFI boot?

Thanks for the help!",javadlux,2021-04-17 20:01:35,2,16,0.6
593,"I recently purchased a used ROG Strix 2080Ti OC and upon receiving it, I noticed it is pretty dusty. I've decided it could use a good cleaning and will repaste it in the process. While it is open I have also considered replacing the thermal pads. My question is whether anyone here knows the thickness of the pads on this particular card. I have only found one other post regarding this and it stated that the thickness was 1.5mm for all pads but wanted to see if anyone here can provide insight. Thank you!",yalocalyeeter,2021-04-17 19:16:18,4,7,0.75
594,"Hello, I’m unsure of which of these two 3090s to get, and I may have a size restriction for my case which is a Corsair 680 crystal. I just want to know which of these two is smaller",brunoflower,2021-04-17 18:43:31,0,10,0.29
597,"My display is merged.  I wanna watch Star Wars and I want it to span across both displays.  I'm guessing I can't tweak aspect ration to make this happen without losing picture quality, I'm just curious if there is a way to accomplish this.  Thanks!",picklenades,2021-04-17 16:34:33,3,2,1.0
598,"After 4 months of refreshing and disappointment I finally scored a EVGA 3060 (12G-P5-3657-KB) from BestBuy. I'm coming from a non ti 750 so I am absolutely thrilled to be upgrading, but I did notice some complaints about cooliing on this particular model. I wanted to look at aftermarket cooling options, triple fan or liquid, but I am having a really hard time finding anything compatible. Is anyone able to help get me pointed in the right direction?",Fair_Helicopter_661,2021-04-17 16:06:37,0,8,0.33
603,"So I saw an article earlier this week on the first day of GTC announcing the long awaited open beta of Omniverse Machinima, arriving near the end of GTC alongside Audio2Face. Well the last day of GTC came and went and the app still isn't there. Audio2Face is but it's unlaunchable. I was able to find out after some digging on the forums that Audio2Face got delayed a little bit due to some issues. But I wasn't able to find a damn thing on Machinima. Pardon my harshness but it shouldn't be THIS hard to find this info, it's actually unacceptable in 2021 in my opinion. The  reveal of a delay of one of their programs should not of been a pain in the ass to find. If it's simply delayed, fine, but I need to be made aware.

But I digress. Any information on this would be appricated. Again sorry for the harsh tone.

&#x200B;

EDIT:   I'm not talking about the Omniverse as a whole, I'm talking about the Machinima app.

Since I'm not convinced one hand knows what the other is doing, here is the article I'm referring to. [https://developer.nvidia.com/blog/nvidia-omniverse-machinima-now-available-in-open-beta/](https://developer.nvidia.com/blog/nvidia-omniverse-machinima-now-available-in-open-beta/)

It said it would be available at the end of GTC. However as of me typing, the app is not there. Pic proof: [https://imgbox.com/b1aIj0TB](https://imgbox.com/b1aIj0TB)",WarmanReborn,2021-04-17 13:53:10,0,13,0.4
607,"At stock/non-overclocked settings, what are your core clock speeds in games/benchmarks?

I’ve checked a lot of the 3060ti reviews after getting one, and most are from early December when the card dropped. One common theme is that during their benchmarks (like Timespy) the boost clock speeds hover around 1900mhz. 

Even though my timespy gpu score (~11500 at stock) seems to be around average, my clock speeds drop to around 1815/1800 MHz by the end of gpu test 2 at roughly 70 deg C. 

I came across this site https://www.computerbase.de/2020-12/nvidia-geforce-rtx-3060-ti-asus-msi-test/2/?amp=1 for more data points - in doom for example, my core clock hits anywhere from 1815-1845 MHz at 1440p, whereas that reviewer has clock speeds at 1845-1875 at 4K. 

Any explanation for the slight discrepancy? I’m aware of how GPU boost works, and I’m pretty sure it’s not the silicon lottery since I can OC core +160 and memory +800 (which seems in line with the norm). 

TLDR; 3060Ti FE boost clock speeds seems lower than a lot of the reviewers from when the card came out. Any ideas?

Edit: specs:
3060 ti FE
Ryzen 3600 
16gb ddr4 3600 MHz
Asrock b550 pro4
550w psu",Shultzy1992,2021-04-17 11:27:15,5,5,0.78
608,I own inno3d frostbite 3080 which has 2 8 pin connectors. Cards runs really cool max 50 on gpu en max 80 on mem. So i want to overclock it. stock bios is 340 watt with max 100% percentlimit and no voltage controll. What bios could I flash to unlock it OC potentials? Please advise?,rwijnhov,2021-04-17 07:02:58,2,4,1.0
609," building a pc for my cousin and i found good prices for this two gpu on a local seller and im curious is the extra money worth it for the 1660 ti, or should i go 1660 super, is the difference substantial?, thanks in advance

Ryzen 3 3100, T-Force Dark za 3200mhz, Samsung Evo 860 500gb, DeepCool 600w 80+ Bronze NZXT H400i, Gigabyte B450M DS3H,",aquaaax,2021-04-17 05:53:24,2,4,1.0
612,"Where can you buy an rtx 3060ti founders edition in Australia. I hate the ugly partner cards and would really like a founders card. I saw you could buy the 3080 on mwave for a while but I couldn’t see anything else.

Can someone help?",henwydadog,2021-04-17 02:58:20,2,2,0.75
615,"I have been using digital vibrance for years now (70%) and it's what I am used to, but then I ask my friends if they use it they almost say no every time.

Wanted to get your opinion on this!",DaarkGT,2021-04-16 22:17:09,7,27,0.82
616,"I recently learned about issues with junction memory temperature being quite high in 3080 Founders Edition cards. It turned out to indeed be the case for my card so I decided to do something about it.

Here's what I've done. I replaced all of the pads in the front with 2mm Gelid GP-Extreme and all of the pads in the back with 3mm Gelid GP-Extreme. Pretty standard. Lots of people recommend them. I bought two packs of each (80x40mm) and it was barely enough. I've had a little bit of 2mm pad left, but 3mm was practically all gone. I didn't waste much of them either. I also bought some 2mm Thermalright pads, but decided against using them as apparently they're too hard for the die to make good contact. Thermal paste used was Thermal Grizzly Kryonaut Extreme. Here are some pics of how I applied them:

Front: [https://imgur.com/a/QUOhHsR](https://imgur.com/a/QUOhHsR)

Back: [https://imgur.com/a/txYbFjK](https://imgur.com/a/txYbFjK)

Memory junction temps improved by \~20C, and I'm not even kidding. It topped out at 104C before the mod and the highest I've seen after \~20 minutes of playing games while GPU bottlenecked now was 84C. I could test it again for a longer time if anybody wants me to.  Die temp improved as well, albeit less substantially, as it now tops out at 73C as opposed to 77C before. I don't remember what the hot spot temperature was before the mod. My card was purchased in December and it already had more thermal pads on the back than the early versions.

Temps: [https://imgur.com/a/zfy4YZ0](https://imgur.com/a/zfy4YZ0)

Above readings for minimum temps are what they're like when idle now. Temps before the mod were pretty typical for a stock 3080FE and can be easily found online. I unfortunately do not have a picture.

I'm actully really happy with those results. I was skeptical going into this as lots of people were having issues after modding the cards, but it worked out in the end for me.

Make of that what you will. Overall I would not recommend this mod to people who are not willing to accept losing their warranty, risk damaging their card or are not handy with electronics in general. It might be worth it to others.

&#x200B;

Edit: 

After an additional hour of Watch Dogs 2 memory temp rose to 88C

Pic: [https://imgur.com/a/BIByG3A](https://imgur.com/a/BIByG3A)

&#x200B;

Edit 2:

15 minutes in furmark (temps stabilised around 7-10 minutes in) with GPU  fans at 70%, case fans at 30%, side panel off and cpu cooled via an aio  exhausting through the top. GPU had all setttings stock (except for the  fan speed). Case was Corsair 4000D Airflow.

Pic: [https://imgur.com/a/Jc8dG6A](https://imgur.com/a/Jc8dG6A)",peachoidpro,2021-04-16 20:51:09,22,32,0.83
617,Currently I have an extra computer with no gpu. These cards seem like a really good deal for but im not sure about them being an accelerator card means. I'd be using for 24/7 ai video interpolation and upscaling. Would this be a good card for the use case?,Isaac8849,2021-04-16 19:15:43,1,1,1.0
618,"I just installed the game F1 2020 on my gaming PC with an Nvidia 2070 Super and 1080 monitor, and the Geforce Experience suggested to enable both Nvidia DLSS and DXR at 3840x2160.

From what I understand DSR alone will render bigger image (which means lower FPS), then shrinks the image to have better image quality, while DLSS renders at lower resolution and upscales with AI to native resolution to increase FPS.

What does technically happens when both are active?

DLSS and AI is used to downscale the DXR image?",tech_engineer,2021-04-16 18:01:43,20,10,0.93
621,[https://www.tomshardware.com/news/msi-russia-reduces-some-gpu-warranties-from-3-years-to-6-months](https://www.tomshardware.com/news/msi-russia-reduces-some-gpu-warranties-from-3-years-to-6-months),Leo1_ac,2021-04-16 16:50:36,27,20,0.91
622,"Hi guys,

I saw that recently it became almost common practice to modify the cooling solution on the GPU to lower VRAM temps. I know it's mostly done on GDDR6X 30 series cards, but on my 2080Ti FTW3 VRAM temps also get past 80c on heavy load, on hot days even approaching 90c, so I'm searching for a way to get those temps down. The GPU core is relatively cool, having typical load temps of 68-73c. 

Considering what people in this sub have learned from recently, what is the right course of action to get those VRAM temps lowered?

Thanks!",yoadknux,2021-04-16 16:34:00,1,16,0.54
623,"Hi guys,  
in few days i'll receive this gpu, at the moment i have a 5800x @ 4.8ghz, 4x8gb 3600mhz ram, 1tb nvme + 1tb ssd. As psu an rm750x.  I would like to ask you if this power supply is enough for my rig. Any direct experience with this specs?  


Thanks in advance",beppenike,2021-04-16 16:30:28,0,9,0.5
624,"Based on the [specs](https://store.steampowered.com/app/1134570/F1_2021/) on the Steam page, it looks like F1 2021 will support ray tracing. 

F1 2020 supported DLSS, so we can expect it in F1 2021 as well.",None,2021-04-16 15:43:22,12,16,0.88
626,"Hi, due to the current crazy times GPU market is all over the place and retailers are selling above MSRP, now I’m after an Aorus RTX 3080 (Rev 2.0) but I don’t want to pay crazy amounts over MSRP for it however tracking down what the actual MSRP for the card is proving difficult, so does anyone know or have any idea? I’m from the U.K. so £ would be ideal but $ is fine as well.",Waqster94,2021-04-16 15:02:36,0,9,0.2
628,"hi guys, i want to buy new monitor and have a question

as i noticed, regular freesync ""g-sync compatible"" monitors works with nvidia in 48-144 for example or something 48+ fps, and if fps below 48, it wont work.

And in amd freesync premium there is a LFC options, that compensate low fps. I wander, will LFC work on nvidia card, if monitor have freesync premium and ""g-sync compatible"" ? cuz right now i play AC Valhalla, and my framerate usually 60 with drops to 50 in citys and some times even to 45-47 in hard situations, and i want achieve smooth gameplay (cuz my current monitor pretty old 24' benq, that have a huuuuge stutters when fps drops from 60 (using v-sync right now). Yeah, i know, that buying a new GPU better way, but i live in Russia, and via bitcoin situations GPU's here costing very expensive, like 3 years ago i bought 1070 and now it costs x4 higher, that 3 years ago, in blows my mind.  


So any help? my goal is to find cheap 1080p 24 or 27 freesync monitor, that will give me smooth gameplay with fps drops and free me from stutters",Adventurous-Travel76,2021-04-16 14:41:56,1,10,1.0
629,"Hey, to all the people that have this setup could you give some insight as to what issue i might possible by having here

i got a 2060 mobile, in a razer 15 probably from 2019, paired up with an LG GN800-B monitor, 1440p, 144hz

when i hook up the monitor using hdmi the screen flickers periodically, it recognizes that there is a second monitor, and then doesnt, and just repeats this over and over, i am positive that i am on hdmi1, have tried 2 as well...i am aware that the hdmi port on the laptop comes directly from the dgpu, i know that the usb c or thunderbolt or whatever is a port on the igpu for whatever reason

both hdmi ports are at least hdmi2, i know the port on the monitor is hdmi2.0a

im thinking maybe my hdmi cable is just too old?  was thinking of getting an hdmi2 cable, but instead picked up a mini dp to dp cable, should arrive saturday so ill see how it goes

anyone have any experience with this?  also updated my drivers",ilyasdaniel,2021-04-16 14:10:04,3,13,1.0
630,"&#x200B;

https://preview.redd.it/wupiyv3ajjt61.jpg?width=4032&format=pjpg&auto=webp&s=fbe37825e2672d38e5b54acdb6c46dd7b5622b5b",OptimumPC,2021-04-16 13:53:31,0,2,0.5
632," 

[https://blogs.nvidia.com/blog/2021/04/16/gan-research-knight-rider-ai-omniverse/](https://blogs.nvidia.com/blog/2021/04/16/gan-research-knight-rider-ai-omniverse/)

[https://www.youtube.com/watch?v=0PQnrnUIBlU](https://www.youtube.com/watch?v=0PQnrnUIBlU)

Using GANVerse3D as part of Nvidia's Omniverse, game developers (& others) can create animated 3D objects (such as the Trans AM in 'Knight Rider') from 2D images using AI without having to model them.

From Nvidia's presentation to the press yesterday, Omniverse has strong applications for creating unified game worlds in one metaverse like ""Oasis"" similar to what has been imagined in 'Ready Player One'.

Nvidia's Blog (first link above) and also the Youtube video (they used the original actor to voice Kitt from the 80s TV show) explain how. This is from a research paper \[presented at GTC 2021) - from Nvidia's blog:

>To generate a dataset for training, the researchers harnessed a generative adversarial network, or GAN, to synthesize images depicting the same object from multiple viewpoints — like a photographer who walks around a parked vehicle, taking shots from different angles. These multi-view images were plugged into a [rendering framework for inverse graphics](https://blogs.nvidia.com/blog/2019/12/09/neurips-research-3d/), the process of inferring 3D mesh models from 2D images.  
Once trained on multi-view images, GANverse3D needs only a single 2D image to predict a 3D mesh model. This model can be used with a 3D neural renderer that gives developers control to customize objects and swap out backgrounds.  
When imported as an extension in the [NVIDIA Omniverse](https://www.nvidia.com/en-us/omniverse/) platform and run on [NVIDIA RTX GPUs](https://www.nvidia.com/en-us/design-visualization/), GANverse3D can be used to recreate any 2D image into 3D — like the beloved crime-fighting car KITT, from the popular 1980s *Knight Rider* TV show.  
Previous models for inverse graphics have relied on 3D shapes as training data.  
Instead, with no aid from 3D assets, “We turned a GAN model into a very efficient data generator so we can create 3D objects from any 2D image on the web,” said Wenzheng Chen, research scientist at NVIDIA and lead author on the project.",apoppin,2021-04-16 13:31:49,21,6,0.88
635,Can a RTX 2060 6GB from Gigabyte handle 3 4K TVs for gaming racing?,ANK_Ricky,2021-04-16 13:26:02,0,6,0.5
637,"Care to help me redeem a gamecode?

Would be very awesome! I got a key for a game in GeForce Experience from someone, but he had to RMA the laptop and now I can't redeem it :S",Kuyi,2021-04-16 12:34:44,0,0,0.44
638,"Just wanted to share with everyone:

[Link](https://www.alternate.nl/content.xhtml?c=64c4c8d6-9488-4273-8ae7-f24cb540256b)

Information about RTX 3000 series

Thank you for your interest in the new GeForce RTX 3000 series! Due to the huge demand for these graphics cards and the limited stock that was available at launch, there is a large amount of open orders, which we unfortunately can not deliver. Through this page we try to answer the most common questions and keep you informed of the latest developments.

Unfortunately we have been told by the various manufacturers that the deliverability of the RTX 3000 series cards will not improve much in the second quarter of 2021. The exact reasons are unclear, but the demand remains much higher than the supply. In addition, the first manufacturer has since stopped producing a particular model, namely the popular MSI RTX 3080 Gaming X Trio.

In general, manufacturers focus on the higher-end models within their series. As a result, cards from the entry-level series will be much less available. We hardly ever issue pre-orders for these. Therefore, we will no longer accept pre-orders for RTX 3000 series video cards and will only deliver models from stock.

Here is an overview of our delivery/availability expectations:

RTX 3090: small deliveries, normally from stock, only very specific types not.

RTX 3080: very little supply, only on the high-end models occasionally free stock becomes available.

RTX 3070: small deliveries, normally deliverable from stock, only very specific types not.

RTX 3060 Ti: very little supply, occasionally deliverable from stock, only on specific types there is a high queue.

RTX 3060: small deliveries, regularly deliverable from stock, only very specific types are not.

This unfortunately means that the chance of getting an RTX 3080 remains small, only higher-end models are occasionally released. The RTX 3060, RTX 3070 and the RTX 3090 will arrive in small quantities and are available on a regular basis. Also for the RTX 3060 Ti, the chances of availability, especially for the popular models, will be very low. For the earlier generations and the GTX series, unfortunately, supply is also poor.

Despite the fact that the purchase prices of the products and the costs for transportation have risen sharply, we will of course continue to deliver to our customers in order. Unfortunately, the prices for new orders may increase further in the near future due to market forces. Globally, it is announced that the scarcity may continue until mid-2021. 

Translated with www.DeepL.com/Translator (free version)",SubZer0G,2021-04-16 12:29:17,0,3,0.4
639,Just curious where I live there are plenty of rtx 3000 cards except the 3080 and 3060 ti but the prices are super high RTX 3070 €1200/$1435.68. so what is the situation where you live,Sir_flaps,2021-04-16 11:59:19,7,55,0.74
642,"Hello everyone,  


[https://www.nvidia.com/en-us/geforce/news/geforce-rtx-30-series-resizable-bar-support/](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-30-series-resizable-bar-support/)

After reading several articles I still have a questions:

Why this feature is bound only to latest series of GPUs and CPUs?  
What does prevents it to run with previous generation?

Thanks for your comments in advance!",AndriiTalksTech,2021-04-16 11:25:33,0,13,0.5
643,"So I added 2 noctua air cooler to my 3090 and an 84c junction temp was the result.

&#x200B;

I recently did the pad mod and it was safe to say that it was a failure. The junction temps were like 100c. Then it occurred to me maybe the top panel couldn't dissipate the heat fast enough so i added a fan and the temps went down to 94. Then I thought what if I get an air cooler instead. I found this tiny little noctua cooler so I was like what the heck lets just add 2. Added some thermal pads and thermal paste and I'm happy. mid 80's junction and and gpu at 69c with the fans going moderately slowly. O and also added more fans because why not. Once I put the tinted glass you cannot see them.

Just thought I'd share I thought it was pretty cool.

https://preview.redd.it/yzs8ix4w2it61.png?width=1790&format=png&auto=webp&s=c6c9ceb93f8b9a145828e8a3ecc0b75cbc99e5b9",forzablu46,2021-04-16 08:49:51,9,40,0.71
644,"Hey all! I have an Acer predator Triton 500. Here are the specs; i7-10750H, RTX 2080 SUPER Max-Q, 32GB Ram, 1TB nVME SSD. I'm looking for a monitor with great color accuracy and high refresh rate.

Should I pick up a 1080p 240Hz monitor or a 1440p 144Hz monitor? The laptop itself has a 300Hz screen but I can rarely ever hit 300FPS to begin with so I'm not super interested in super high refresh. That being said, is the 2080 SUPER Max-Q even capable of 1440p at a consistent 144Hz in games? Some games like Rainbow Six Siege, Overwatch, Resident Evil 2, I'm sure I'd have no problem hitting 144Hz. But what about less optimized games? Rust, Outriders, Black Ops Cold War, etc? I'm really going for consistency, I don't like a lot of frame dips, etc. jumping from 120-90 wildly over a few seconds, really messes with my eyes. Thoughts?",HILLxHXUSE,2021-04-16 02:54:59,1,9,0.67
646,"Just curious if there's anything recommended changes before putting this card to use?  I will be using it mainly for COD:  Warzone at 1440p.  

People seem to be rather opinionated in card itself so i figured id reach out to see what others who have the same card have done and their experience with it.

Thanks!",HellaSupBro,2021-04-15 23:17:31,4,13,0.75
647,"It’s a long story, but as of last week I have a 3090FE order for in-store pick this coming Saturday at a local Best Buy but I’m still leary/paranoid if it’ll actually get fulfilled with how crazy the video card situation has been.

The order currently says “Preparing for Pickup on Saturday” so it should be good right?

Edit: I was informed on how to contact the store via email.  They got back to me and said their manifest show it arriving at the store tomorrow and as of right now they do not see anything that would delay me being able to pick it up tomorrow! 😁

I’ll make an obligatory “got 30-series” box pic post tomorrow when I do confirming I was able to pick it up!  Now to just get thru sleeping tonight and work tomorrow! Ha ha!

Thanks everyone for their info and input and helping calm me down a bit!",Dizman7,2021-04-15 22:52:56,18,73,0.91
649,"Just saw the NVIDIA presentation on Jarvis and would love to try it out. Can it run on the consumer level RTX 30 series (specifically my 3070 laptop). Or what about older hardware (1080 ti?) Don't care about performance, just want to play around with it...

&#x200B;

Thanks for any info",reddit__un,2021-04-15 20:04:01,1,3,0.67
650,"MSI VGA nVidia GeForce GT-1030 LP OC 2 GB.

Chipset: GP 108-300 Pascal.

Engine Clock: (1266 MHz-1518 MHz).

RAM: 64 bit 2 GB DDR5 Samsung  (2100-6008 MHz).

Output: 1 x HDMI/1 x DP.

What is the Best Stable Secure Settings for OverClocking it.

Cause I dont have money to Buy GTX or RTX GPU.

[https://www.msi.com/Graphics-Card/GeForce-GT-1030-2GH-LP-OC](https://www.msi.com/Graphics-Card/GeForce-GT-1030-2GH-LP-OC)",Pavlaras88,2021-04-15 19:34:47,0,4,0.4
651,"Good afternoon everyone, I've been trying to do a bit of research on this, but haven't encountered much in the way of other people's experiences.  I've seen a lot of posts where people are talking about transplanting an Alienware into a custom case, but no real follow-up on if they actually did it and if it worked.  Long story short, I have a custom build that I made around Christmas for video editing and VR development.  At the time I was able to grab a 1050Ti for it as a stop-gap measure.   As we're all aware, there are card shortages... blah blah blah.  Through work, I now have the opportunity to get a prebuilt HP/Alienware desktop for personal use at near cost.    


My question is simply this: are the 3090 cards in either of these machines proprietary to where they will not be usable in a different motherboard/custom build configuration?  I'd literally be buying either of these machines just for the the graphics card.  The other parts I don't really care about.  


If you have done this, and it worked, I'd also be curious as to hearing about your experience doing it.  Are there any pitfalls I should be aware of (driver issues, etc.)?   I have an MSI B550 Gaming Carbon Wifi motherboard, and am using the AMD Ryzen 9 3900XT processor.  Any advice is welcome.

Thanks.",uncheckablefilms,2021-04-15 19:15:18,1,7,1.0
652,Just went and played it after installing 466.11 and downloading a patch for the game and it seems to run... really really well now.  No stuttering and weird low GPU utilization that was killing the game right after 465.89 with ReBAR enabled.  Can anyone else confirm?,w00t692,2021-04-15 18:11:08,10,15,0.78
653,"I know it’s alt f2 to use it, but idk how to enable it so I can go into it when I press alt f2",CletusMcgeetus,2021-04-15 17:43:22,1,1,1.0
654,"from the release notes:

> - Adding “Change Screen Size” feature

> - **Adding “Saving LED Control to Board” feature**

> - Fix some bugs

https://www.palit.com/palit/thundermaster.php?lang=en",zmeul,2021-04-15 16:47:00,12,7,1.0
655,Good luck everyone in getting a card!,ElderberryCareful879,2021-04-15 16:06:59,14,163,0.64
656,"So I’m definitely not a rookie at doing this, as this is my fourth card. But looking into some recent research, I’ve seen some people saying upping the core voltage is useless. Is this true? Could be a silly question, as the 2000 series cards have been out for a while. My temps barley touch 50 degrees under a full load. Any advice? Thanks",drklwo39,2021-04-15 16:04:35,0,3,0.33
657,"First time building a PC, have little knowledge and just wanted some of you’re opinions, as the PC industry seems massive and don’t have much time to look into everything. Will be using it for gaming and architecture. 

- EVGA 3080 FTW3 GPU
- AMD Ryzen 9 5900x CPU
- Sgate 2TB Barra
- 2 x 16G CorsVeng LPX DDR4
- Corsair H100x CPU Cooler
- 1TB Corsair MP600 M.2
- Asus Pro WS X570-ACE motherboard 
- Corsair Carbide 678C ATX case

Hopefully that made sense, probably going to pair it with a 1440p 144hz monitor, let me known what you think! Thanks",Grose144,2021-04-15 15:53:50,0,5,0.43
659,I was just wondering whether I can and should leave ULLM enabled when I use Reflex for a game or if they somehow conflict. Thanks in advance,DerUebamensch,2021-04-15 15:10:12,1,4,0.67
661," Hi everyone! Some of you may know our work from our collaboration with Microsoft on their newest release of the Flight Simulator. But our technology is capable of doing much more than ""just"" that. At the recent NVIDIA GTC, our Head of Machine *Learning*, had the chance to give a presentation about our platform.

You can watch now the video of Stefan Habenschuss (our Head of Machine *Learning*) where he is explaining how our platform works and the way we are constructing the planet in 3D with massively scalable aerial *image* segmentation for virtual sensor simulation environments.

\>> Link to the video:[h](https://lnkd.in/dafgdvm)[https://gtc21.event.nvidia.com/user/login?ref=%2Fmedia%2FMassively%2520Scalable%2520Aerial%2520*Image*%2520Segmentation%2520for%2520Virtual%2520Sensor%2520Simulation%2520Environments%2520%255BS32456%255D%2F1\_ww9xg28y%2F204677963](https://gtc21.event.nvidia.com/user/login?ref=%2Fmedia%2FMassively%2520Scalable%2520Aerial%2520Image%2520Segmentation%2520for%2520Virtual%2520Sensor%2520Simulation%2520Environments%2520%255BS32456%255D%2F1_ww9xg28y%2F204677963)\>>

To access the video you have to register >>for free<<\*

We hope that you enjoy the presentation and get a little bit more insight in what we do. Feel free to reach out to us anytime.",BlacksharkAI,2021-04-15 14:00:51,3,3,0.81
663,"Hi I’m building my first ever PC, I stream and play Warzone competitively, I’m waiting for a RTX 3090 but have a 3070 until stock is better available.

I already have the Samsung G7 240hz monitor, will it work with the RTX 3070 or will there be any issues I need to be aware of before I build? 

PC specs:
Ryzen 5900x
Asus TUF motherboard 
Corsair 16gb 3600hz 
Ssd WD black 1TB 
850W gold PSU",Turbulent-Slice4235,2021-04-15 11:11:03,0,23,0.5
665,"I received a ton of great responses from you guys on [this post](https://www.reddit.com/r/nvidia/comments/mouek9/rtx_2060_vs_3060_ti/) and was about to pull the trigger on a prebuilt HP with a 3060 Ti, but it got me thinking...

Everyone recommended spending $1500 to get the system with a 3060 Ti and better components over the $1000 system with a 2060. Would it be worth it to pay another $400 for a system with a 3070, bigger case, better CPU, RAM, power supply, and water cooling?

Some comments had me worried about the 500W power supply not being enough, but would HP really sell a system with a power supply that can't keep up with its own components?

Aside from the case, system differences are below. $1900 really stretches my budget and is honestly more than I want to pay, but it's not like you buy a computer every day so I can see the value in paying more for something that will last longer or give a lot more benefit. What do you think?

**HP Pavilion TG01 - $1500**  
i7-10700F  
16GB DDR4-2933 (8GB x 2)  
512GB M.2 NVMe SSD  
1TB 7200 rpm HDD  
500W 80 Plus Gold  
RTX 3060 Ti

**OMEN by HP 25L - $1900**  
i7-10700K + AIO with 120mm fan (Cooler Master branded)  
32GB DDR4-3200 (16GB x 2 - HyperX Fury branded)  
512 M.2 NVMe SSD (WD\_Black branded)  
2TB 7200 rpm HDD  
750W 80 Plus Platinum (Cooler Master branded)  
RTX 3070",friesfish,2021-04-15 07:25:08,36,53,0.86
667,"Hi friends, does anyone know when they bring in new delivery or best way to get one from that location?",NatsuDragneel--,2021-04-15 06:35:55,0,7,0.5
668,are the cards not being produced? Or is it just that they're bought out so fast? Other reason?,p0ndobear,2021-04-15 06:23:23,0,14,0.29
669,"When DLSS was initially announced Nvidia told us that there would be two modes: DLSS 1x and DLSS 2x. The first one would try to match native while being based on a lower render resolution, the later one would aim for best image quality based on native render resolution. The later mode wasn´t released so far.
Two links from back then:
https://developer.nvidia.com/blog/nvidia-turing-architecture-in-depth/
(search for the passage ""In addition to the DLSS capability described above, which is the standard DLSS mode, we provide a second mode, called DLSS 2X."")
https://www.reddit.com/r/nvidia/comments/ada0v0/will_dlss_2x_be_available_for_every_dlss_game/

Anyways, the name DLSS 2x isn´t that handy anymore with DLSS 2.0/2.1 around. It looks like Nvidia now thinks about naming it DLSS Ultra Quality. Anyways, it´s a must have. So many games don´t mostly lack in terms of performance, they lack in image quality. A well rounded AntiAliasing got huge potential in such an environment. 
So, Nvidia, where is it? Why don´t you announce it already? It´s important to get some coverage so devs will integrate DLSS with full selection options (from Ultra Performance up to Ultra Quality) when switching to the newer UnrealEngine or UnityEngineBuilds.

Edit: Judging by several comments it looks like DLSS Ultra Quality isn´t based on native renderres. Well, maybe nvidia would have to name it DLSS Xtreme High Quality. Or maybe they just stick to the name DLSS 2x. (this would make it possible to add DLSS 4x, DLSS 8x and so on as well, but all these names would be kind of misleading, as DLSS 2x already was)",RadonGOG,2021-04-15 06:00:39,223,70,0.97
671,"Is there a way to restrict my system to a max resolution? i.e. my screen is capable of 4k but I want to limit it to 1080p 120hz only. Normally it's not a problem but occasionally after game updates, driver updates, etc. I find my games bumping back to 4k resolution. I poked around in the Geforce control panel and couldn't find anything like that.",ericwhat,2021-04-15 00:47:11,6,10,0.88
672,"I am capable of getting a 3090 that was taken out of the [Dell Alienware Desktop prebuild](https://www.reddit.com/r/Alienware/comments/jo02b1/alienware_rtx_3090_aurora_r11_general_information/)

I currently have a 3080 Vision and my CPU is a I7 10700k, would getting this 3090 which I know little about be worth it for me? Any help would be appreciated. 

Assume I am getting it at msrp value.",NephilimGiant,2021-04-15 00:33:03,0,26,0.25
674,I'm thinking it's something in Armory Crate but I only figured out how to do basic RGB patterns on there,sleepy_the_fish,2021-04-14 23:58:16,0,4,0.5
675,"And if so, which one would you recommend to someone with a 3090 build?

Edit: Thank you to everyone who responded/is responding, much appreciated guys <3",chadthelad420,2021-04-14 23:56:33,0,39,0.5
676,I'm on one of the first game ready drivers still and it was working great until the premiere update. Now my premiere freaks out and uses 100% CPU power for no reason every hour. Anybody having better luck with more recent game drivers?,stickbob123,2021-04-14 23:26:38,3,12,0.8
677,"I really wanted to add a 27"" 2560x1440p monitor next to my 34"" 3440x1440p monitor. So I ordered one. It looked so good as a curved ""61"""" filled a 55"" desk perfectly. Having the offset screen gap was great, but it only worked at 1080p. Tried everything to get it working, CRU and all that. No dice. no 6000x1440p for me. WHY MUST YOU TEASE ME SO!!!

&#x200B;

So my kid got a new 27"" monitor today.....",synkndown,2021-04-14 22:49:17,0,3,0.5
679,[Uprising Bios Update](https://www.pny.com/company/support/nvidia-geforce#BARBIOSUpdate),skyebaron,2021-04-14 21:46:15,10,0,0.79
680,"I signed up for auto notify:  12/10/2020 - 9:09:21 AM PT 

https://preview.redd.it/fdgvevbwe7t61.png?width=891&format=png&auto=webp&s=86cbb5782b5250f143329ff3ca215659b38b4c98

Anyone have a hybrid gpu with air cooled cpu? I've never had a hybrid gpu before, curious to hear setups. 

I'm assuming the top is the best spot for the radiator since I need my intake fans in front for my cpu?",TerraMystika,2021-04-14 21:28:12,9,9,0.85
684,"Does anyone know which direction the coolant flows in the MSI 2080 Sea Hawk AIO GPU? Usually on GPUs, the coolant enters on the left fitting and exits on the right, but I need to make sure of this before I tear into the card... long story. Anyway, I'm putting one inline with another pump and I want to make sure that the two pumps aren't working against each other... Has anyone here converted one from AIO to custom loop before?",MrPeakAction,2021-04-14 19:27:22,1,0,0.67
685,"Hello everyone, i need to know if there is any vbios updates for GTX 1660, Model: (asus ph-gtx1660-o6g).

Thanks in advance.",ghaithomari,2021-04-14 18:17:41,0,3,0.43
686,"Do anyone have a list?  
 from [https://www.nvidia.com/en-us/geforce/technologies/reflex/](https://www.nvidia.com/en-us/geforce/technologies/reflex/)

## MEASURE RESPONSIVENESS

PC performance for competitive gaming is about responsiveness—how quickly your display updates after mouse click. NVIDIA Reflex Latency Analyzer, built into new [NVIDIA G-SYNC displays](https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/)\*, captures end-to-end system latency and delivers a precise measure of your PC’s performance. Step confidently into battle knowing your PC is performing at peak level with GeForce RTX GPUs and NVIDIA Reflex Latency Analyzer-compatible displays and mice.

\*Not available on all monitors or displays. Please consult the display manufacturer specifications for supported features.",Zewy,2021-04-14 18:47:57,0,2,0.4
687,"So I accidentally broke the annoying 2-pin connector when doing the thermal pad mod on my 3090 FE. Anyone happen to know if it's an orderable part? The female end looks sorta like the [Molex Pico Ezmate](https://www.molex.com/molex/products/family/picoezmate) series connections, but I can't find the PCB-side conncector with the metal lock. 

Ultimately not the end of the world either way I guess, but would be nice to fix. 

Connector seen [here in this teardown](https://youtu.be/9JWqRjqqNko?t=310) (I want the piece soldered to the board; my wire end is intact):",terraphantm,2021-04-14 17:54:59,7,12,0.77
689,"# Studio Driver 462.31 has been released.

# New feature and fixes in driver 462.31:

**Applications** \-  New AI features in top creative apps, running on NVIDIA RTX GPUs, are changing - and accelerating - the way we create. The April NVIDIA Studio Driver provides optimal support for the latest AI-powered features in creative applications including **NVIDIA Omniverse, Topaz Denoise AI, Topaz Sharpen AI, Notch, and OBS Studio**. 

In addition, GeForce Experience now optimizes creative applications like **Blackmagic Design's DaVinci Resolve and Adobe Lightroom by automatically enabling GPU acceleration in these apps**, ensuring artists are using the maximum GPU acceleration available, just by clicking a single button. **Initially starting with 34 supported apps, this list will continue to grow over time as more creative applications are added.** 

**New Features and Other Changes -** Added support for the following GPU products:

* NVIDIA RTX A5000
* NVIDIA RTX A4000
* NVIDIA T1000
* NVIDIA T600
* NVIDIA T400 

**Studio Driver Fixes** (For full list of fixes please check out release notes)

* N/A

**Studio Driver Important Open Issues** (For full list of open issues please check out release notes)

* \[Rainbow Six Siege\]\[Vulkan\]: Smoke appears pixelated. \[3266916\]
* \[Batman Arkham Knight\]: The game crashes when turbulence smoke is enabled. \[3202250\]
* \[World of Warcraft: Shadowlands\]: Random flicker may occur in certain locations in the game \[3206341\]
* \[Supreme Commander/Supreme Commander 2\]: The games experience low FPS. \[3231218\]
* \[Steam VR game\]: Stuttering and lagging occur upon launching a game while any GPU hardware monitoring tool is running in the background. \[3152190\]
* \[G-SYNC\]\[NVIDIA Ampere GPU architecture\]: GPU power consumption may increase in idle mode on systems using certain higher refresh-rate G-SYNC monitors. \[200667566\]
* \[YouTube\]: Video playback stutters while scrolling down the YouTube page. \[3129705\]
* \[Notebook\]: Some Pascal-based notebooks w/ high refresh rate displays may randomly drop to 60Hz during gameplay. \[3009452\] 

# Driver Downloads and Tools

Driver Download Page: [Nvidia Download Page](https://www.nvidia.com/Download/Find.aspx?lang=en-us)

Latest Game Ready Driver:  466.11 WHQL

Latest Studio Driver:  462.31 WHQL

DDU Download: [Source 1](http://www.wagnardmobile.com/DDU/) or [Source 2](http://www.guru3d.com/files-details/display-driver-uninstaller-download.html)

DDU Guide: [Guide Here](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)

**DDU/WagnardSoft Patreon:** [**Link Here**](https://www.patreon.com/wagnardsoft)

Documentation: [Game Ready Driver 462.31 Release Notes](https://us.download.nvidia.com/Windows/462.31/462.31-win10-nsd-release-notes.pdf)

[r/NVIDIA](https://new.reddit.com/r/NVIDIA/) Discord Driver Feedback for 462.31: [Invite Link Here](https://discord.gg/y3TERmG)

# Having Issues with your driver? Read here!

**Before you start - Make sure you Submit Feedback for your Nvidia Driver Issue**

There is only one real way for any of these problems to get solved, and that’s if the Driver Team at Nvidia knows what those problems are. So in order for them to know what’s going on it would be good for any users who are having problems with the drivers to [Submit Feedback](https://forms.gle/kJ9Bqcaicvjb82SdA) to Nvidia. A guide to the information that is needed to submit feedback can be found [here](http://nvidia.custhelp.com/app/answers/detail/a_id/3141).

**Additionally, if you see someone having the same issue you are having in this thread, reply and mention you are having the same issue. The more people that are affected by a particular bug, the higher the priority that bug will receive from NVIDIA!!**

**Common Troubleshooting Steps**

* If you are having issue installing the driver for GTX 1080/1070/1060 on Windows 10, make sure you are on the latest build for May 2019 Update (Version 1903). If you are on the older version/build (e.g. Version 1507/Build 10240), you need to update your windows. Press Windows Key + R and type winver to check your build version.
* Please visit the following link for [DDU guide](https://goo.gl/JChbVf) which contains full detailed information on how to do Fresh Driver Install.
* If your driver still crashes after DDU reinstall, try going to Go to Nvidia Control Panel -> Managed 3D Settings -> Power Management Mode: Prefer Maximum Performance

If it still crashes, we have a few other troubleshooting steps but this is fairly involved and you should not do it if you do not feel comfortable. Proceed below at your own risk:

* A lot of driver crashing is caused by Windows TDR issue. There is a huge post on GeForce forum about this [here](https://forums.geforce.com/default/topic/413110/the-nvlddmkm-error-what-is-it-an-fyi-for-those-seeing-this-issue/). This post dated back to 2009 (Thanks Microsoft) and it can affect both Nvidia and AMD cards.
* Unfortunately this issue can be caused by many different things so it’s difficult to pin down. However, editing the [windows registry](https://www.reddit.com/r/battlefield_4/comments/1xzzn4/tdrdelay_10_fixed_my_crashes_since_last_patch/) might solve the problem.
* Additionally, there is also a tool made by Wagnard (maker of DDU) that can be used to change this TDR value. [Download here](http://www.wagnardmobile.com/Tdr%20Manipulator/Tdr%20Manipulator%20v1.1.zip). Note that I have not personally tested this tool.

If you are still having issue at this point, visit [GeForce Forum for support](https://forums.geforce.com/default/board/33/geforce-drivers/) or contact your manufacturer for RMA.

**Common Questions**

* **Is it safe to upgrade to <insert driver version here>?** *Fact of the matter is that the result will differ person by person due to different configurations. The only way to know is to try it yourself. My rule of thumb is to wait a few days. If there’s no confirmed widespread issue, I would try the new driver.*

**Bear in mind that people who have no issues tend to not post on Reddit or forums. Unless there is significant coverage about specific driver issue, chances are they are fine. Try it yourself and you can always DDU and reinstall old driver if needed.**

* **My color is washed out after upgrading/installing driver. Help!** *Try going to the Nvidia Control Panel -> Change Resolution -> Scroll all the way down -> Output Dynamic Range = FULL.*
* **My game is stuttering when processing physics calculation** *Try going to the Nvidia Control Panel and to the Surround and PhysX settings and ensure the PhysX processor is set to your GPU*
* **What does the new Power Management option “Optimal Power” means? How does this differ from Adaptive?** *The new power management mode is related to what was said in the Geforce GTX 1080 keynote video. To further reduce power consumption while the computer is idle and nothing is changing on the screen, the driver will not make the GPU render a new frame; the driver will get the one (already rendered) frame from the framebuffer and output directly to monitor.*

# Remember, driver codes are extremely complex and there are billions of different possible configurations. The software will not be perfect and there will be issues for some people. For a more comprehensive list of open issues, please take a look at the Release Notes. Again, I encourage folks who installed the driver to post their experience here... good or bad.",Nestledrink,2021-04-14 15:54:27,11,3,0.84
690,"Any reviews or teardowns on the 3080 Waterforce WB?

Is there any difference between the PCB in the Master and the Waterforce WB series?",Jackerl,2021-04-14 15:06:18,2,2,0.75
691,"# Game Ready Driver 466.11 has been released.

# New feature and fixes in driver 466.11:

**Game Ready** \- Game Ready for **Mortal Shell**. This new Game Ready Driver provides support for Mortal Shell's RTX update, which introduces **NVIDIA DLSS, boosting performance by up to 130% at 4K**. Additionally, this release also provides optimal support for **Valorant's NVIDIA Reflex update, NVIDIA Broadcast Noise Reduction support in OBS, 6 new G-SYNC Compatible gaming monitors and TVs, and more.**

**Game Ready Driver Fixes** (For full list of fixes please check out release notes)

* \[Supreme Commander/Supreme Commander 2\]: The games experience low FPS. \[3231218/ 3230880\]
* \[Adobe Camera RAW 12.x\]: RAW files may show up black in Adobe Lightroom. \[3266883/ 200717265\]
* \[VR\]: Microsoft Flight Simulator 2020 VR may stutter if Hardware-accelerated GPU scheduling is disabled. \[3246674\]
* Some displays may show incorrect color levels after booting into Windows. \[3285148/3287063\]

**Game Ready Driver Important Open Issues** (For full list of open issues please check out release notes)

* \[World of Warcraft: Shadowlands\]: Random flicker may occur in certain locations in the game \[3206341\]
* \[Batman Arkham Knight\]: The game crashes when turbulence smoke is enabled. \[3202250\]
* \[Steam VR game\]: Stuttering and lagging occur upon launching a game while any GPUhardware monitoring tool is running in the background. \[3152190\]
* \[Prepar3D\]: The application crashes to desktop after launched. \[3285067\]
* \[YouTube\]: Video playback stutters while scrolling down the YouTube page. \[3129705\]
* \[Notebook\]: Some Pascal-based notebooks w/ high refresh rate displays may randomly drop to 60Hz during gameplay. \[3009452\]

# Driver Downloads and Tools

Driver Download Page: [Nvidia Download Page](https://www.nvidia.com/Download/Find.aspx?lang=en-us)

Latest Game Ready Driver:  466.11 WHQL

Latest Studio Driver:  462.31 WHQL

DDU Download: [Source 1](http://www.wagnardmobile.com/DDU/) or [Source 2](http://www.guru3d.com/files-details/display-driver-uninstaller-download.html)

DDU Guide: [Guide Here](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)

**DDU/WagnardSoft Patreon:** [**Link Here**](https://www.patreon.com/wagnardsoft)

Documentation: [Game Ready Driver 466.11 Release Notes](https://us.download.nvidia.com/Windows/466.11/466.11-win10-win8-win7-release-notes.pdf)

Control Panel User Guide: [Download here](http://us.download.nvidia.com/Windows/465.89/465.89-nvidia-control-panel-quick-start-guide.pdf)

NVIDIA GeForce Driver Forum for 466.11: [Link Here](https://www.nvidia.com/en-us/geforce/forums/game-ready-drivers/13/448105/geforce-46611-grd-feedback-thread-released-41421/)

**RodroG's Driver Benchmark:** [Link Here](https://babeltechreviews.com/geforce-466-11-driver-performance/)

[r/NVIDIA](https://new.reddit.com/r/NVIDIA/) Discord Driver Feedback for 466.11: [Invite Link Here](https://discord.gg/y3TERmG)

# Having Issues with your driver? Read here!

**Before you start - Make sure you Submit Feedback for your Nvidia Driver Issue**

There is only one real way for any of these problems to get solved, and that’s if the Driver Team at Nvidia knows what those problems are. So in order for them to know what’s going on it would be good for any users who are having problems with the drivers to [Submit Feedback](https://forms.gle/kJ9Bqcaicvjb82SdA) to Nvidia. A guide to the information that is needed to submit feedback can be found [here](http://nvidia.custhelp.com/app/answers/detail/a_id/3141).

**Additionally, if you see someone having the same issue you are having in this thread, reply and mention you are having the same issue. The more people that are affected by a particular bug, the higher the priority that bug will receive from NVIDIA!!**

**Common Troubleshooting Steps**

* If you are having issue installing the driver for GTX 1080/1070/1060 on Windows 10, make sure you are on the latest build for May 2019 Update (Version 1903). If you are on the older version/build (e.g. Version 1507/Build 10240), you need to update your windows. Press Windows Key + R and type winver to check your build version.
* Please visit the following link for [DDU guide](https://goo.gl/JChbVf) which contains full detailed information on how to do Fresh Driver Install.
* If your driver still crashes after DDU reinstall, try going to Go to Nvidia Control Panel -> Managed 3D Settings -> Power Management Mode: Prefer Maximum Performance

If it still crashes, we have a few other troubleshooting steps but this is fairly involved and you should not do it if you do not feel comfortable. Proceed below at your own risk:

* A lot of driver crashing is caused by Windows TDR issue. There is a huge post on GeForce forum about this [here](https://forums.geforce.com/default/topic/413110/the-nvlddmkm-error-what-is-it-an-fyi-for-those-seeing-this-issue/). This post dated back to 2009 (Thanks Microsoft) and it can affect both Nvidia and AMD cards.
* Unfortunately this issue can be caused by many different things so it’s difficult to pin down. However, editing the [windows registry](https://www.reddit.com/r/battlefield_4/comments/1xzzn4/tdrdelay_10_fixed_my_crashes_since_last_patch/) might solve the problem.
* Additionally, there is also a tool made by Wagnard (maker of DDU) that can be used to change this TDR value. [Download here](http://www.wagnardmobile.com/Tdr%20Manipulator/Tdr%20Manipulator%20v1.1.zip). Note that I have not personally tested this tool.

If you are still having issue at this point, visit [GeForce Forum for support](https://forums.geforce.com/default/board/33/geforce-drivers/) or contact your manufacturer for RMA.

**Common Questions**

* **Is it safe to upgrade to <insert driver version here>?** *Fact of the matter is that the result will differ person by person due to different configurations. The only way to know is to try it yourself. My rule of thumb is to wait a few days. If there’s no confirmed widespread issue, I would try the new driver.*

**Bear in mind that people who have no issues tend to not post on Reddit or forums. Unless there is significant coverage about specific driver issue, chances are they are fine. Try it yourself and you can always DDU and reinstall old driver if needed.**

* **My color is washed out after upgrading/installing driver. Help!** *Try going to the Nvidia Control Panel -> Change Resolution -> Scroll all the way down -> Output Dynamic Range = FULL.*
* **My game is stuttering when processing physics calculation** *Try going to the Nvidia Control Panel and to the Surround and PhysX settings and ensure the PhysX processor is set to your GPU*
* **What does the new Power Management option “Optimal Power” means? How does this differ from Adaptive?** *The new power management mode is related to what was said in the Geforce GTX 1080 keynote video. To further reduce power consumption while the computer is idle and nothing is changing on the screen, the driver will not make the GPU render a new frame; the driver will get the one (already rendered) frame from the framebuffer and output directly to monitor.*

# Remember, driver codes are extremely complex and there are billions of different possible configurations. The software will not be perfect and there will be issues for some people. For a more comprehensive list of open issues, please take a look at the Release Notes. Again, I encourage folks who installed the driver to post their experience here... good or bad.",Nestledrink,2021-04-14 15:05:10,202,718,0.96
693,"From GeForce PR - with implications also for VR:

Quote:

[GTC 2021](https://www.nvidia.com/en-us/gtc/?ncid=pa-srch-goog-35830#cid=gtcs21_pa-srch-goog_en-us) kicked off this week with a flurry of GPU news and announcements. Of interest to gamers, Unity will be natively supporting NVIDIA Deep Learning Super Sampling (DLSS) in their popular game engine. 

**Unity Developers Can Easily Add DLSS to Add to Their Games**

Developers’ ability to level up their games with the same cutting-edge technologies found in the biggest blockbusters got a lot simpler. Unity developers will soon be able to add NVIDIA DLSS to their creations in just a few clicks. Before the end of 2021, [NVIDIA DLSS ](https://www.nvidia.com/en-us/geforce/technologies/dlss/)will be natively supported for the High Definition Render Pipeline ( HDRP) in Unity 2021.2.

At GTC 2021, Light Brick Studio demonstrated how stunning Unity games can look when real-time ray tracing and DLSS are combined. Watch their full talk for free [here](https://gtc21.event.nvidia.com/media/LEGO%20Builder%E2%80%99s%20Journey%3A%20Rendering%252%5b%E2%80%A6%5dng%20Ray%20Tracing%20in%20Unity%20%5BE32773%5D/1_n3jxujtr). You can also check out our developer interview with Unity’s Mathieu Muller, senior product manager for high-end graphics [here](https://youtu.be/nY20fDmlW7M).

NVIDIA DLSS uses advanced AI rendering to produce image quality that’s comparable to native resolution--and sometimes even better--while only conventionally rendering a fraction of the pixels. With real-time ray tracing and NVIDIA DLSS, Unity developers will be able to create beautiful real-time ray traced worlds running at high frame rates and resolutions on NVIDIA RTX GPUs. DLSS also provides a substantial performance boost for traditional rasterized graphics.

This comes hot on the heels of the announcement that DLSS support has been added as a plug-in to Epic’s Unreal Engine.

**Related Links:**

NVIDIA DLSS coming to Unity Engine on the NVIDIA Developer blog:

[https://developer.nvidia.com/blog/nvidia-dlss-natively-supported-in-unity-2021-2/](https://developer.nvidia.com/blog/nvidia-dlss-natively-supported-in-unity-2021-2/)

GeForce.com article on NVIDIA DLSS coming to Unity Engine:

[https://www.nvidia.com/en-us/geforce/news/unity-engine-adding-dlss](https://www.nvidia.com/en-us/geforce/news/unity-engine-adding-dlss)

Developer interview with Unity’s Mathieu Muller, senior product manager for high-end graphics on YouTube:

[https://youtu.be/nY20fDmlW7M](https://youtu.be/nY20fDmlW7M) 

Light Brick Studio’s GTC  talk by Mikkel Fredborg (must register first):

[https://gtc21.event.nvidia.com/media/LEGO%20Builder%E2%80%99s%20Journey%3A%20Rendering%20Realistic%20LEGO%20Bricks%20Using%20Ray%20Tracing%20in%20Unity%20%5BE32773%5D/1\_n3jxujtr](https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgtc21.event.nvidia.com%2Fmedia%2FLEGO%2520Builder%25E2%2580%2599s%2520Journey%3A%2520Rendering%2520Realistic%2520LEGO%2520Bricks%2520Using%2520Ray%2520Tracing%2520in%2520Unity%2520%255BE32773%255D%2F1_n3jxujtr&data=04%7C01%7CBBurke%40nvidia.com%7Cc900be6a680041e5028a08d8fea4aca4%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C637539330512812368%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=sns1fiBUBGXnegOfXSGJ7Eb5ZAjA65G%2BRXHEEVvcWTw%3D&reserved=0)

GTC Game Development topics page:

[https://www.nvidia.com/en-us/gtc/topics/game-development/](https://www.nvidia.com/en-us/gtc/topics/game-development/)

GTC 2021 Graphics SDK round up on NVIDIA Developer blog: [https://developer.nvidia.com/blog/leveling-up-graphics-amp-performance-with-rtx-dlss-and-reflex-at-nvidia-gtc/](https://developer.nvidia.com/blog/?p=30558)

NVIDIA DLSS Plugin and Reflex Now Available for Unreal Engine on the NVIDIA Developer blog:

[https://news.developer.nvidia.com/nvidia-dlss-and-reflex-now-available-for-unreal-engine-4-26/](https://news.developer.nvidia.com/nvidia-dlss-and-reflex-now-available-for-unreal-engine-4-26/)",apoppin,2021-04-14 13:50:27,1632,206,0.98
694,"I want to buy a better computer for video editing. So far I was on an i5, 8GB RAM and it wasn't the best of course.

What do you think of this computer?

[https://store.hp.com/UKStore/Merch/Product.aspx?id=111B8EA&opt=ABU&sel=NTB](https://store.hp.com/UKStore/Merch/Product.aspx?id=111B8EA&opt=ABU&sel=NTB)

I can't consider Apple as a choice because I am a university student in sciences and I work also with specific softwares that don't run on Mac.",csira_allapot_5876,2021-04-14 12:20:41,3,6,0.81
695,">Version 1901 Beta Version
2021/04/14 

>	ROG MAXIMUS XI HERO (WI-FI) BIOS 1901 
Add Resizable BAR support for Nvidia RTX 30 series cards to potentially deliver more performance to gamers in select titles.

[Source and download link for Maximus XI Hero (WiFi)](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-hero-wi-fi-model/helpdesk_download)

Today I was pleasantly surprised to see a beta BIOS update available for my Maximus XI Hero (WiFi) motherboard! Excited to try out the feature ASAP!

~~Currently I can’t see any other Maximus XI boards having any update yet but I’m sure they will arrive imminently if Hero (WiFi) is getting the update today!~~

Edit:
More models getting the update now! I will update the post with links below to other Z390 models once they go live on ASUS’s website.

* [Maximus XI Apex beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-apex-model/helpdesk_download)
* [Maximus XI Code beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-code-model/helpdesk_download)
* [Maximus XI Extreme beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-extreme-model/helpdesk_download)
* [Maximus XI Formula beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-formula-model/helpdesk_download)
* [Maximus XI Gene beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-gene-model/helpdesk_download)
* [Maximus XI Hero beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-hero-model/helpdesk_download)
*  [Maximus XI Hero (WiFI) beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-maximus/rog-maximus-xi-hero-wi-fi-model/helpdesk_download)
* [Prime Z390-A beta v1901 link.](https://www.asus.com/uk/Motherboards-Components/Motherboards/All-series/PRIME-Z390-A/HelpDesk_Download/)
* [Strix Z390-E beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-strix/rog-strix-z390-e-gaming-model/helpdesk_download)
* [Strix Z390-F beta v1901 link.](https://rog.asus.com/uk/motherboards/rog-strix/rog-strix-z390-f-gaming-model/helpdesk_download)",supercakefish,2021-04-14 11:34:05,58,52,0.94
696,"Hi,

I want to get Dolby Atmos with my graphics card. I was also wondering about Nvidia, does it have an audio driver that supports Dolby Atmos?

Regarding my equipment, I connected my computer to my television via an HDMI cable which itself is connected to my Sonos Arc sound bar in HDMI.

I also saw that there was the software offered by Microsoft: Dolby Acces. The concern being that it only generates 7.1. Sonos being exclusively in 5.1, I am not sure that I am in the best possible conditions to take full advantage of my Sonos system.

I also saw that in Windows, when I right clicked on the little speaker at the bottom right of the taskbar, there were 5.1 and 7.1 offered but these are greyed out.

Do you have a solution to get 5.1 instead of 7.1?

&#x200B;

PS: I see on the Sonos app and elsewhere on the television the Dolby Atmos badge that appears when I play a video or a game in Dolby Atmos, so at this level it seems to work. The concern being that it is in 7.1 ...",Le_Cee,2021-04-14 11:17:21,10,17,0.86
697,"Currently it saves Screenshots in:  
`C:\Users\[USERNAME]\Videos\[GAME NAME]`

what if I want it to always save in

`K:\Photos\Screenshots`",CubeIR,2021-04-14 10:20:21,4,1,0.76
700,Hi all! I was wondering if a 90 degree display port adapter can create any problem to the proper functioning of gsync.,GrumpyCalabi314,2021-04-14 09:16:39,1,5,0.6
701,It's for my 3090. My PCIe cable 1 and PCIe cable 2 usually are pulling in at around 25 more Watts that my PCIe cable 3.,sleepy_the_fish,2021-04-14 05:36:41,9,17,0.8
702,So i recently bought a 3070 from the evga qeue today at around 2 pm and its currently 9:30. it still states that my order status is processing. how long does EVGA usually take to processed orders? or is that a sign that theres a chance that it will be denied?,AggravatingAd5851,2021-04-14 04:26:19,0,4,0.17
703,"I haven't tested that thoroughly.

Is there any statistics spreadsheet around about that?

Just trying while running Heaven Benchmark in a fixed camera position so framerate stays consistent, I don't see anything outside perhaps 2 FPS more when RAM is +1000",Sacco_Belmonte,2021-04-14 03:12:46,7,15,0.82
704,"I'm looking to purchase a used card online, and am curious if anyone has tried to use a manufacturer warranty after getting a lemon from such third parties. The specific card I'm eyeing is MSI.",jvalordv,2021-04-14 02:49:40,4,3,0.75
705,"I think this is the cheaper version of the 2060 so it only has 3 outputs, 1 of which is DVI-D:  
[https://cdn.mos.cms.futurecdn.net/rbNXw6ZJHZ72Z58NsLohhL-970-80.jpg.webp](https://cdn.mos.cms.futurecdn.net/rbNXw6ZJHZ72Z58NsLohhL-970-80.jpg.webp)

I found many articles saying that DVI only supports 2560x1600 max but some other articles say 4k @ 30hz is possible if it's dual link. I found this cable that says it supports 4k but it's a DVI-I would it really give me 4k resolution? If not then what cable do I need?  
[https://www.monoprice.com/product?p\_id=2218](https://www.monoprice.com/product?p_id=2218)

Does this card even support 3 4k monitors?",covered1028,2021-04-14 02:42:19,3,3,0.8
706,"im thinking of buying one as a second gpu to rtx 3060, see an msi one on fb marketplace for 100 bucks",Ok-Operation-8018,2021-04-14 02:21:30,0,7,0.36
707,"I replaced the thermal pads on my 3090 with 2mm Thermalright pads and it fixed my memory temp problem, but then my GPU core started to overheat. I tried reapplying thermal paste 3-4 times now, but it didn't fix the issue. I swapped out the pads with some 1.5mm pads of the same brand and bam, the GPU core temp went back to normal, but then the memory temp went back to overheating. I'm not sure what else to do.",sleem17,2021-04-14 02:15:06,15,6,0.83
708,"Recently did some mining and did a deep dive into performance and temps etc.
And the gpu was downclocking it self to 50%.

Temps were a nice 56c however the vrm was at 110c so I assumed mining was the issue and did a test with some Cyberpunk and Flight Sim and saw temps at 106c.

Removed the vertical mount and placed it as normal in the case and while gaming same scenarios went to 100c.

My question is this normal? And safe the gpu in question is the 3090 Aorus Extreme and so far only issue I found with it are those vrm temps.
I no longer mine and only tested it for curiosity not worth the stress in a 3500 aud card.",Nostradamuz88,2021-04-13 23:59:51,2,16,0.75
709,"Hey guys!

I was just able to get 3 gtx 1080 reference cards, slight problem though, the heat sinks are all gone. The cards seem to be working fine (i did test boots with all three) so i was wondering if it was possible to buy the heatsinks from somewhere. I got the cards for next to nothing so I wouldn't mind getting aftermarket coolers but i was wondering what the better option was.

Thanks!!",ikreeperz,2021-04-13 23:23:27,4,14,0.71
710,"Since I haven't seen any reports about how well the new [active backplate](https://www.ekwb.com/shop/ek-quantum-vector-re-rtx-3080-3090-active-backplate-d-rgb-plexi) works, here is a brief summary at 100% load:

**CPU:** Ryzen 5950x (4.5Ghz all cores, 5Ghz light threaded)

**GPU:** PNY 3090 RTX (Reference PCB) flashed with Galax bios 390W (Core +150mhz, Memory + 250mhz).

**Water Temp:** 32C. (at idle)

**Passive Backplate Temps:**

Memory Junction Max:  74C.  
Hotspot Temperature Max:  78C.

**Active Backplate Temps:**

Memory Junction Max:  52C.  
Hotspot Temperature Max:  60C.

This thing performs incredible and is definitely a worthy purchase for all RTX 3090  owners. This is what it looks like installed: [https://imgur.com/a/EZ6HL87](https://imgur.com/a/EZ6HL87)",carrot_gg,2021-04-13 22:49:25,20,25,0.85
711,"Hello, I want to maintain my GTX1070 Strix OC that I have had for 2-3 years but I have not found the thickness of the thermal pads that I need and there are many measures, does anyone know what thickness I need for the different components of the card?",chanchoextremo,2021-04-13 20:30:27,1,2,0.67
712,"\----------------------------------------Translation English

Dear Frederick,

I am sending you this e-mail in response to your open order with Alternate to inform you further about the availability of the ordered MSI graphics card.

I regret to inform you that we have recently received new information from MSI stating that the MSI 10GB D6X RTX 3080 Gaming X TRIO 10G graphics card is no longer available as it is no longer produced by the manufacturer.Unfortunately, this change at MSI means that we will no longer have the graphics card from your order in stock and we will not be able to further process your order in its current state.

For that reason I would like to inform you about the further options.  - If desired, you can cancel the order so that we can refund the amount paid.

\- We can also change the product in the order to an alternative product. If the product concerns an additional price, we will charge this price with a payment request. If the alternative product is cheaper, we can provide a refund for the remaining amount.  We would therefore like to hear your wishes within the period of 7 days. After this period has expired, your order will be automatically canceled and refunded.  If you have any further questions, please let us know. I wish you a good day.

\-------------------------------------

So, I'm just wondering, because I'm not following the NVIDIA MSI branding & production on the foot; what is the alternative that MSI sets forward as the successor for  MSI 10GB D6X RTX 3080 Gaming X TRIO 10G?

Offcourse I'm not satisfied with the terms of Alternate. It's just a cheap shot to get rid of the obligations they have to their customers. Sure MSI will have an alternative available for the card.

Kind regards

Frederick D.

&#x200B;

&#x200B;

&#x200B;

\--------------------------------------------------Original email in Dutch

Beste Frederick,  
Ik stuur je deze e-mail naar aanleiding van je openstaande bestelling bij Alternate om je verder op de hoogte te brengen over de beschikbaarheid van de bestelde grafische kaart van het merk MSI.

Ik moet je helaas informeren dat wij recent nieuwe informatie hebben mogen ontvangen van MSI met de melding dat de MSI 10GB D6X RTX 3080 Gaming X TRIO 10G grafische kaart niet langer wordt uitgeleverd gezien deze ook niet meer wordt geproduceerd door de fabrikant.

Deze wijziging bij MSI betekent spijtig genoeg dat wij de grafische kaart uit je bestelling niet langer op voorraad zullen verkrijgen en wij je bestelling ook niet verder kunnen verwerken in de huidige staat.

Om die reden wil ik je informeren over de verdere mogelijkheden.

\- Indien gewenst kan je de bestelling annuleren opdat wij het betaalde bedrag kunnen terugbetalen.- Ook kunnen wij het product in de bestelling wijzigen naar een alternatief product. Mocht het product een meerprijs betreffen, zullen wij deze prijs in rekening brengen met een betaalverzoek. Indien het alternatieve product goedkoper is, kunnen wij een terugbetaling voor het resterende bedrag voorzien.

Graag vernemen wij dan ook je wensen binnen de periode van 7 dagen. Na het verlopen van deze termijn zal je bestelling automatisch geannuleerd en terugbetaald worden.

Mocht je verdere vragen hebben, dan vernemen wij het graag.Ik wens je alvast nog een fijne dag.",Popjukebox,2021-04-13 19:59:28,12,29,0.93
714,"from poking around it seems EVGA is best but theyre also pretty expensive. Expecting a china version would fuck me over so im wondering what a good balance of cost and reliability is. Realize this is a pretty bad time to shop for these but my current card is on the way out.

\>does it have to be 1050 Ti?  
Yeah, unless there's another card with <85 wattage and as good/nearly as good performance, OR something that is so much cheaper that it could cope the price of an additional PSU upgrade. Altho it might be smart to get that plus a beefier fan",beef_muncher,2021-04-13 18:56:07,0,12,0.29
715,"A couple of weeks ago I got a queue for the FTW3 Ultra.. however just got an email today again from EVGA for the Hybrid!!!! Is there anything I should know about the differences of the cards? Are they the exact same except for one is a hybrid cooler? I am debating on which one to keep as I actually like the look of the FTW3 Ultra.. but I feel like it would be dumb not to stick with the Hybrid...

Thanks!!!

\*FYI.... My bestfriend/roommate will most likely be taking my second card, in case anyone tries to message me about buying a card.",Random-Posterer,2021-04-13 18:54:24,15,63,0.83
717,"I am waiting on my step up for a 3080, which I filed in the end of October. I have not seen any recent updates regarding the queue, does anyone know what day EVGA is up to? Last I heard, they got through the release date orders.",futurescientist1234,2021-04-13 17:00:38,1,12,0.56
718,"I mostly play warzone and just upgraded to the EVGA 3070 over the 2070 super and have a EVGA 750 g3 power supply. I have either the 9 or 10 series i7k processor 32b of ram but I’m still only seeing around 150fps in my MSI G27c2. I was getting that the the 2070 and reports say the 3070 should be a big step up in performance. Am I not seeing that just because the game is cpu bound?  

Also does the card need to be powered with two separate 6+2 cables or one cable with 2 6+2 is good?

UPDATE:::

I’ve read that the psu only needs the two separate power cords if your overclocking. 

I did just upgrade from a 6700k to a 9700k and seen a pretty big jump in performance

I only purchase the 2700 because it was in stock for $550 plus tax. Just sold it for $600. Ash amd found a 3070 for $599 plus tax so I’m sure it was still worth the upgrade.",BaChickaWaWa,2021-04-13 16:56:10,0,14,0.33
719,"Do Intel i5-8600ks work with the resizable BAR? The motherboard bios has the option, but I keep seeing old posts that this CPU line doesn’t get resizable BAR.",Pvarron,2021-04-13 16:31:31,0,9,0.5
720,"So I'm selling my arctic accelero xtreme iv (new) product to an 2080ti owner.

The 2080ti die size looks way bigger than 1080.

Will the pre applied paste do the job? Will it cover the whole die?
Thanks.",ahmetomerozgen,2021-04-13 16:13:54,0,1,0.4
721,"I got a kfa2 gtx 1060 3gb, but the fan speed is locked to 27% min, it cannot go below in msi afterburner. Even if I set it to 0% with the custom fan speed curve, it still spins at 27%. How can I disable that? I want it to be silent, it's making way too much noise for my sensitive ears",IAmYourFath,2021-04-13 15:59:33,1,11,1.0
722,Hello! I have a GTX 1660 and I want to change/turn off the LEDs but I can't find where I can do such things. I have tried nvidia LED visualizer but it didn't recognize my card.,internalbleeds,2021-04-13 14:16:59,1,2,1.0
723,Is this possible?,XTsam2,2021-04-13 14:08:53,0,19,0.27
725,"I luckily grabbed myself a 3090 FTW3 from Scan a few weeks ago but due to payment delays (fucking NatWest security) I missed the last batch.

When I spoke to scan, they said there were expecting another shipment of cards on the 14th April. 

Just a heads up if you're still looking and want to snag one.",J_Triple,2021-04-13 13:27:33,0,10,0.4
726,"Let's say I have a chance to get both cards at MSRP, is the overclocked ROG Strix 3060 faster than the 3060 Ti Founders Edition?

It's a 3060, yet even more expansive than the 3060 Ti FE.

And what's the disadvantages for Founders Edition against ROG Strix overclocked variant(if comparing the same product, ROG Strix 3060 Ti Overclock vs 3060 Ti Founders Edition)?",lwclwclwc,2021-04-13 13:13:27,0,12,0.33
727,"Hi! 

Sorry if this is placed in the wrong subreddit, but I currently have a 1080 @ 60hz (I have never tried any higher to be honest..)

&#x200B;

Even though I have 3900x and 1080 I still feel some games can be choppy and I am considering if it might be the GPU.

&#x200B;

Now that the 3xxx-series is out, what would be a suitable upgrade? Is it worth it for 1080/1440p in the future, or will my 1080 be good enough? Considering RTX/DLSS or what its called as well.

I play games, yes. 

&#x200B;

Thanks!",Kukkacola,2021-04-13 12:09:16,0,9,0.3
729,"Is it bad to hit the power limit on these cards? I have a 3080 FE which hits it's power limit frequently, but does this cause any stuttering or hurt performance?   


Obviously hitting the power limit will mean no more boost but I'm talking about whether the power limit algorithm reduces frames even more? - sort of like hitting the rev limiter in a car where you lose all power for a split second.",thatsprettyshady,2021-04-13 10:15:37,1,4,1.0
730,"Spoke with a rep to find out the pad thickness and the corresponding locations on the card, I have 3080 & 3090. The rep said that there was a change in warranty policy without letting the public know. Here is the dialog below:

23:53**Paulo T:** Hi, Thank you for opening a chat session. Let me help you.  
23:53**L:** oh my message got cut  
23:53**L:** So i have the zotac 3080 and 3090  
23:54**L:** I need to replace the thermal pads for obvious reasons  
23:54**Paulo T:** we dont have access to that and if you need to replace them since opening the heatsink aids the warranty already  
23:54**L:** I need a picture/diagram of the pcb and backplate indicating location and thermal pad thickness please  
23:54**L:** what do you mean aids the warranty?  
23:54**Paulo T:** If you need to replace it you need to open an rma  
23:55**Paulo T:** what ii meant was void  
23:56**L:** no it's not23:56**Paulo T:** im saying that it does  
23:56**Paulo T:** i just receive the news yesteday  
23:57**L:** straight from Zotac ""Thermal paste applied on graphic card might be dried off after years of gaming. It's good to service and re-apply from time to time to ensure maximum performance! YES, reapplying thermal paste on ZOTAC graphic card will not void the warranty but make sure be extra cautious when doing it.""  
23:57**L:** I've been doing this for over 10 years  
23:57**Paulo T:** we were surprised ourselves for this change in policy  
23:57**Paulo T:** Same here  
23:57**L:** you can't change the policy after I bought it  
23:57**Paulo T:** all im saying was there was a change in policy  
23:58**Paulo T:** you can no longer remove the heatsink  
23:58**Paulo T:** i dont call the shots here. if you have concerns you can email [rma.us@zotac.com](mailto:rma.us@zotac.com)  
23:59**L:** i'm not removing the heatsink or fan  
23:59**L:** we are getting off topic as this applies to only the thermal pads  
00:00**Paulo T:** you mentioned thermal pads  
00:00**L:** yes, i did not receive a manual indicating where the thermal pads should go and their corresponding thickness  
00:01**Paulo T:** you cannot remove the back plate without removing the heatsink since the screws are from the inside to remove the back plate  
00:01**L:** so this is what id like to know for the zotac 3090/3080  
00:01**Paulo T:** there was no manual for that  
00:01**L:** fair that there was no manual, i can't find any zotac materials online either  
00:02**Paulo T:** there wasnt any related to it you can ask users probably  
00:02**Paulo T:** just please bare in mind that will require you to remove the heatsink at it will void warranty. You can rma it to avoid voiding warranty  
00:03**Paulo T:** thats what i suggest  
00:03**L:** Can you give me the announcement to this change?00:03**L:** There were no void-warranty stickers on the gpu  
00:04**Paulo T:** I dont have access to it. this was communicated by my supervisor verbally.  
00:05**Paulo T:** If you have questions about iit feel free to send an email to [rma.us@zotac.com](mailto:rma.us@zotac.com)  
00:07**L:** Okay so Zotac secretly changed their warranty guidelines without letting the public, customers know, when in recent history the company has promoted users to replace their thermal pads.  
00:07**L:** I'll talk with rma then.  
00:07**Paulo T:** yes please.  
00:07**Paulo T:** same question for me  
00:08**Paulo T:** anything else?  
00:08**L:** You wont tell me the pad thickness right?  
00:09**Paulo T:** thats 1.5 - 2mm  
00:09**L:** do you have pictures/diagram?  
00:10**Paulo T:** none  
00:10**L:** alright thanks.00:10**Paulo T:** there wasnt any provided for that  
00:10**Paulo T:** thanks for contacting support.

I already made changes last week so they better still honor a replacement if there is anything else wrong with the card. He said this was changed yesterday so I wonder when they plan on actually plan on telling everyone themselves.

Seems like a great business plan though, give customers terrible pads, they do it themselves, Zotac won't tell anyone of the change, so they don't have to replace your semi-bricked GPU that should be breaking down shortly after the warranty as intended from extended use @ 104C+.

EDIT: Got an email and got confirmation that replacing thermal pads and paste void warranty, US rep:

Thank you for contacting ZOTAC Technical Support.

Please be advised that replacing the thermal paste and pad of the product will void the warranty .

Cheers,Max C------ZOTAC Technical Support",SuchHonour,2021-04-13 07:21:11,585,220,0.95
731,"I currently have a rtx 2080 and was looking to upgrade, I had heard they were extremely hard to get at release due to bots and how nvidia doesn't really care but i had no idea till i looked about the prices of these cards. Here in Australia rtx3080 go for $1400-$2000 aud and 3090 $3000-$3500 the cheapest 3060 i could find was still $1000aud, This just seems insane to me. My entire pc which i built in 2018 cost less than a 3090.

* case: Phanteks evolv x
* mobo: msi MAG Z390 Tomahawk
* RAM: 16gb g.skill trident z rgb 3200mhz
* cpu: intel core i7 8700k
* gpu: rtx 2080
* psu: evga 750 g+
* completely watercooled

I feel like with these insane prices that GPUs are reaching and the fact that bots keep buying all the cards the instant they go on sale which im sure increases the value of the cards even more, This will slowly kill PC gaming its become nearly unaffordable for most people.",kyro2000,2021-04-13 04:29:36,0,15,0.5
732," [What's new in GeForce Experience 3.22.0 (nvidia.com)](https://www.nvidia.com/en-gb/geforce/release-notes/GFE/3_22_0/Web/gfe-v3_22_0-web-release-highlights/?jso=eyUyMmNObSUyMjolMjJnZmUlMjIsJTIyY21JRCUyMjolMjIlMjIsJTIyZ2NWJTIyOiUyMjMuMjIuMC4zMiUyMiwlMjJsZyUyMjolMjIyMDU3JTIyLCUyMmdMZyUyMjolMjJlbi1HQiUyMiwlMjJnbyUyMjolMjJJRCUyMiwlMjJjSUQlMjI6JTIySW50ZWwoUiklMjBDb3JlKFRNKSUyMGk3LTM3NzAlMjBDUFUlMjBAJTIwMy40MEdIeiUyMiwlMjJkSURhJTIyOlslMjIxZjA2XzEwZGVfMTNhM18xMGRlXzElMjJdLCUyMnNNJTIyOiUyMjE2R0IlMjIsJTIyb3NDJTIyOiUyMjEwLjAlMjIsJTIyb3NCJTIyOiUyMjE5MDQyJTIyLCUyMmlzNiUyMjolMjIxJTIyLCUyMkdGUFYlMjI6JTIyNDY1Ljg5JTIyLCUyMmdJc0IlMjI6JTIyMCUyMiwlMjJpTHAlMjI6JTIyMCUyMiwlMjJpc08lMjI6JTIyMSUyMiwlMjJpc1NMSSUyMjolMjIwJTIyLCUyMmNTUiUyMjolMjIxOTIweDEwODBANzUlMjIsJTIydUNzdCUyMjpbJTIyMSUyMiwlMjIxJTIyLCUyMjElMjJdLCUyMmpUSyUyMjolMjJleUpoYkdjaU9pSklVekkxTmlKOS5leUowWkNJNklqazBNakV4TlRRM05USTROamt4TnpFeklpd2ljMk1pT2xzaWMyVnpjMmx2Ymw5MGIydGxiaUpkTENKalpDSTZJakV6TlRNek16RXdOelk0TkRNME5ERXdPU0lzSW5ObElqb2lRbUpVYm1wRlQxVTRMWEY1T0c5T1lUaFhNR3RYV21FeWN6UnFkelZUWlVJaUxDSnZkQ0k2SWpreU1qTXpOekl3TXpZNE5UUTNOelU0TURjaUxDSnBaQ0k2SWpFNE16SXpOalF3TVRJek1ESTFNRE15TnlJc0ltVjRjQ0k2TVRZeE9ESTRPREkzTnl3aWFuUnBJam9pTlRVd09HUTVaVE10TVRJNU5TMDBOREkxTFdJNU0yWXROamM1T1RCaVpUY3lNVFV6SWl3aWMzSWlPaUoxSWl3aWRYUWlPaUl5TnpBME5UazVORFExTWpNM09USTJNVFFpZlEuTGxEQWtmMFhsdnAwdXNGVnR4MEI1ZThYWVNfcmxmXzNVLTBmUm9FaHltdyUyMn0=) 

Has anybody tested the now out of beta one-click overclocking yet? Is it actually better than MSI Afterburner OC scanner?",Trytonism,2021-04-13 04:28:04,5,16,0.79
733,"EVGA is grandfathering the 2020 prices for those registered for the North American queues prior to January 11 for another month; **the 2020 prices will now expire on May 14th,** not on April 16th as originally announced.

As much as I am annoyed by this whole gpu launch, I continue to believe that EVGA is trying their best in the midst of a technology launch debacle not of their own making.

*Best of luck!*",enewt,2021-04-13 02:54:53,394,155,0.97
734,"Hello everyone, I recently installed the latest nvidia driver allowing me to use the new nvidia reflex in siege. I am just wondering what options I should choose between 'On' and 'On + Boost'. I would also like to know whether Nvidia Reflex decreases the amount of frames I get as I struggle to get a consistent 144fps during games

Specs:

i5 9600k

Gtx 1060 3gb

16gb 2133mhz Ram

Samsung SSD",DrDerpioguy,2021-04-13 01:10:20,0,4,0.4
737,"Tried flashing the bios to the low temp bios off of MSI's site and it doesn't work. Current version is 94.02.42.00.fc according to afterburn. When I try the screen goes black and comes up with a message that say s ""no display adapters were found that are compatible with this update""  not sure where to go from there. 

###",Noodninjadood,2021-04-13 00:01:50,2,1,0.75
738,"I have msi afterburner wanting to overclock my gpu, but the thing is im not good at this, how much should I overclock my own gpu, or should I even overclock it at all?",RealOofioRblox,2021-04-12 23:17:09,1,6,0.67
740,"So  recently resizeable BAR support was made available via a VBIOS update  through Precision X1. On my 3080 FTW3 Ultra I updated my VBIOS and  firmware too, since PX1 was pushing that onto me. I never use PX1  because I'm really not a fan; really the only reason why I opened it was  just to get the rebar supporting VBIOS.

How important are the firmware (*not* *VBIOS*)  updates that they push out from time to time? I tend to hear talk in  general that it's better to update hardware stuff as little as you can  (like BIOS, VBIOS, etc) vs drivers where you generally want to be a bit  more up to date with those.

Basically  my question is are the firmware updates EVGA pushes out worth opening  up PX1 for from time to time, or is it okay to pretty much skip them  all?",Gorbishganoid,2021-04-12 21:50:55,2,10,0.75
741,"Didn't saw it elsewhere, just saw it on the overclockers forums, so wanted to share.

The link is here from [Guru3D] (https://www.guru3d.com/news-story/download-msi-afterburner-4-6-4-beta-2.html)

Now you can increase it until +2000, it works for both my 3060Ti and 3080.",panchovix,2021-04-12 20:40:55,21,26,0.84
743,"I've been out of the graphics card game for a good while now, and ""heaven"" was a solid graphics card demo when I was around. Anywho - built my daughter a PC and put a RTX 3060 in it, what's the best demo to showcase the pretty images it can draw?",PixelThis,2021-04-12 19:25:49,14,12,1.0
744,"Hi all,

So I am looking at buying a laptop.  It's going to be a 9th gen i7.  All else being equal, it will be $400 extra for an RTX 2070 vs a GTX 1660ti. 

In 2021, is this worth it?  I know the 11th gen processors just came out, so maybe the 9th gen's are a getting closer to being obsolete.  But I'm also hoping the 9th gen's will be relevant for at least the lifespan of the laptop, and I'm going for the lower price.",Fletchman1313,2021-04-12 18:44:57,1,9,0.55
745,"I think I remember hearing somewhere that those 4 settings for DLSS are actually completely different and separate AIs doing the upscaling. Is this true?

I think maybe it was 3kliksphilip who said it? The new Ultra-Performance was a new trained AI that focuses even more on Performance?",AkiraChisaka,2021-04-12 18:40:10,21,12,0.97
746,"I have a Geforce RTX 3060 from MSI and it has a rgb light strip on it, I have tried different software but I can't seem to find the one to change it with. Does anyone know what software to use?",Memes_now_f,2021-04-12 18:38:32,2,2,1.0
747,"Since I do not wish to open and replace the pads on my brand new 3090 Founders Edition card, I did a little experiment by trying to reduce the VRAM temperature (GPU Memory Junction Temperature) with MSI Afterburner app. I am just sharing my experience with you and not advising you on what to do. Your results may vary. Yes, I know I can replace the pads without much difficulty, but I wanted to try this approach first. Basically, I just reduced the Power Limit in the app until the temp goes down to an acceptable number. Here are my maximum VRAM temp (monitored with HWINFO64) and the decrease in FPS with various Power Limit (PL) percentages and Memory Clock (MC) while running Heaven Benchmark (twice for each PL) at 1440p Extreme:

My ambient temp is 20C (68F) and my Corsair 4000D chassis has very good airflow. 

Base (100% PL, everything default): 98C  
100% PL, -500 MC: 96C and -1.2% FPS  
85% PL, -500 MC:  94C and  -5.4% FPS  
80% PL, -500 MC:  92C and  -7.8% FPS  
75% PL, -500 MC:  90C and  -10.5% FPS (My choice)  
70% PL, -500 MC:  88C and  -13% FPS

These numbers are fairly consistent (sometimes a little lower) while playing games (SOTTR, Destiny 2, etc.). However, these numbers do not reflect mining operations or any other memory intensive applications.  Thus, since I do not plan on mining or running other memory intensive applications, I believe that just reducing the Power Limit is a very good compromise. I believe that I must keep the VRAM temp below 100C (preferably, below 95C) and any higher ambient temperature (summer time) will definitely bring my base temp to above 100C or 105C. Thus, I am currently running at 75% Power Limit and -500 Memory Clock and maybe I will drop it down to 70% PL and -500 MC during summer time. In my opinion, 10% hit on FPS is acceptable in 1440p gaming especially since 3090 FE is already too powerful.",Competitive-Echo4075,2021-04-12 18:24:26,0,23,0.5
750," I've got a gtx 1080 in my pc build but i'm looking to sell my pc to make some money. Never heard about eGPU's until now but I'm wondering if, with windows on my mac, I could run games at good enough performance with a eGPU (thinking about the Razer X Core). Also with the eGPU could I do 144hz and GSYNC?

specs:

2.4GHz 8-Core Intel Core i9

16GB 2400MHz DDR4

UHD Graphics 630 1536mb

1tb SSD",HeyItzLucky,2021-04-12 17:40:05,4,6,1.0
759,"Every 3080 will be capable of  Resizable *BAR* with this driver update? Or the manufacturer, in my case Colorful, would need a Bios update for the GPU? Pretty sure Gigabyte is requires a Bios update for some models to enable  Resizable *BAR.*",ZaphreBR,2021-04-12 15:50:02,0,6,0.27
760,"So far I have had one crash, so I turned my voltage down a click now its at 1.2375MV my cpu is at 4.475GH my GPU its +400 memory +150 clock +0 power max of 2100 MHZ

Temperatures stay low, nothing over 44 Celsius on my gpu, nothing over 64 Celsius on my cpu.

With that being said, this is my first build and I did not know very much when I started this build, my RAM is GSKILL RIPJAW 3600MHZ and my motherboard is B450 Gaming plus max by MSI which is rated 2133MHZ(2400 OC MAX) my question is, how much of a difference would the 1200MHZ make in frame rate while gaming",Pdieter96,2021-04-12 15:20:20,3,7,1.0
761,"**TLDR:** 

* Save yourself an extra $30, you only need 1 single pack of Thermalright Odyssey 1.5mm pads
* Use the 1.5mm pads on the die side of the PCB. Gently lift up the existing VRAM pads with tweezers and reuse them on the back side of the PCB.
 
Just a helpful hint to people wanting to mod their 3080 FE with the Odyssey pads.

These diagrams floating around the sub: [1](https://imgur.com/2TsPW5d), [2](https://imgur.com/9nShJxc) list incorrect pad thicknesses.

Using 2mm pads on the die side causes insufficient GPU core contact (not enough to render the card unusable, but you end up losing performance). I also tried squishing the 2mm pads down on my second mount, this improved the GPU to GPU hot spot delta but it wasn't good enough.

Only by using a full array of 1.5mm pads on my third mount did my delta between GPU and GPU hot spot temps go down to 10C. Before the mod I was mining at 75% fan RPM, -500 mem @ 104C mem junction; now 50% fan RPM, +450 mem @ 96C mem junction.",Paskoff,2021-04-12 15:11:34,41,55,0.89
762,If I have ultra low latency enabled thru my monitor's menu settings do I still need to enable ultra low latency in nVidia control panel too?  I am using a Acer XF3 Nitro XF243Y pbmiiprx monitor and have a GTX 1650 Super.  Would having both on mess up the input lag/response or does one mode just override the other?,johnmorrisbloodlines,2021-04-12 14:15:16,7,5,0.71
764,"Any ETA anything? My 3070 is waiting ready to go everything is updated just waiting for the VBIOS

&#x200B;

Edit: UPRISING VBIOS is out  [https://www.pny.com/company/support/nvidia-geforce#BARBIOSUpdate](https://www.pny.com/company/support/nvidia-geforce#BARBIOSUpdate)

Edit 2 : Installed the 3070 VBios and can confirm it went smooth and BAR is now enabled in the Control Panel",MrScwheppess,2021-04-12 10:57:25,7,11,0.78
765,"Hi,

I recently got my hands on a Tesla K20X passive edition (same thing as this guy got [https://linustechtips.com/topic/1044759-friend-bought-me-a-present-no-idea-where-to-start-k20x/](https://linustechtips.com/topic/1044759-friend-bought-me-a-present-no-idea-where-to-start-k20x/)) and have been wondering what that 2-pin connector (the one a the top next to the ""caution hot"" sign) is used for. Thank you in advance!

TLDR: 2-pin connector identification on Tesla K20X",Cyberexeler,2021-04-12 10:03:49,6,2,1.0
767,"Heres my problem. I have a pretty fast computer so I can get close to 360 fps most of the time and above 240 99% of the time. I just tried G-sync with low latency mode on my alienware aw2518hf 240hz monitor and it actually feels better than ULMB and fixed refresh, low latency on either of them. My question is if I'm using ultra low motion blur on a 240hz monitor and my FPS stays well above 240, will the refresh rate of my monitor still drop to like 140 causing incresed input delay? If my frame rate stays above 240 most of the time, which mode will provide the least input delay? G-sync/ULMB/Fixed and then low latency or not? I was under the impression you only wanted it if your resources were near 90% and mine stay below 70% most of the time with temps under control. This is in Fortnite.

&#x200B;

&#x200B;

Specs:

AMD 3800x (8core with SMT disabled so a true 8 core cpu)

2x8gb 3800mhz cl 14

alienware aw2518hf 240hz

1080ti

Asus x570 tuf plus wifi

nvme 1 tb",Sumac86,2021-04-12 07:03:19,0,24,0.45
768,"In particular 3070 FE vs Gigabyte 3070 Eagle.

Power wise they are both identical but i have the option to swap one for the other in a few weeks time.

The eagle has an extra fan but i wanted some hard data to read on temps at idle and under load and fan speed/noise would be a great bonus.

I feel this should be easy to find but here i am.

Thanks!",Gords78,2021-04-12 04:07:54,10,12,1.0
770,"Hy guys!
I have modded an Accelero IV onto my Asus RTX 2060, and I feel like I have oc headroom, but power limit is an issue. Temps are 51c max, can I increase power limit somehow? Already maxed at 120.
Thank you in advance
Adam",BigCommunication3216,2021-04-12 02:55:08,2,3,1.0
771,"Hello, I have a desktop with Ryzen 9 3950X + Gigabyte B550 aorus pro (wifi 6) mother board + 32 GB 3200Hz ram + Gigabyte 3080 gaming OC 10G. In my machine all I do is deep learning and machine learning stuff. NO gaming. I only use linux. 

Today I came across some posts that nvidia has introduced resizable bar feature with bios update. My question is will it help to improve my machine’s performance for my work if I updated the VBIOS and Motherboard BIOS to enable the resizable bar. Will it help with my training? Is it worth the hassle? I asking because I might brick my GPU in this process if anything goes wrong. Is it worth the work? 

Thanks",sakib_farhad,2021-04-11 21:53:44,0,5,0.43
777," 

Can I decently run a second monitor for browsing, while my first monitor is playing games?

Current monitor: Iiyama ProLite XUB3493WQSU-B1 (DP)

Optional add. monitor: Philips 241E1SCA/00 (HDMI)

As combined, these monitors require 7 mil pixels to be shown, that's near 4k.

Other relevant specs:

Strix 1060 6gb, i5 6500.

Would this set up work?

Thanks in advance!",_Packy_,2021-04-11 19:25:00,5,8,0.78
778,"Hello!

I have always had my computer and 1 monitor on a UPS (this one). I was lucky enough to pick up a 3090 FE on launch day, and ever since then, whenever my power flickers my UPS instantly cuts out. It appears that since adding the 3090 to my rig, it pulls too much power for the UPS to handle.

I thought maybe my UPS was going bad, but I asked a friend who just bought a 3090 and an identical UPS to test it (by unplugging the UPS from the wall to simulate a power flicker), and he had the same results.

So it looks like I need to shop for a better UPS. What should I be looking for when I'm shopping for a UPS to find one that'll be able to drive my 3090 for 1-5s when my power flickers.

Thanks in advance!

EDIT: I returned the UPS to costco (they accepted it even though it was years old). I bought another identical one in the same trip and it appears to work. Apparently my UPS had just gone bad!",kikootwo,2021-04-11 18:40:01,2,12,0.58
779," 

Hi I recently ordered a Barrow ventus 3070 waterblock [https://www.aliexpress.com/item/1005001962305450.html?spm=a2g0s.9042311.0.0.222c4c4daRuTk0](https://www.aliexpress.com/item/1005001962305450.html?spm=a2g0s.9042311.0.0.222c4c4daRuTk0)

and was wondering how the heck I'm supposed to take off the AIO? I tried unscrewing the 4 screws on the PCB backplate and the bracket holder but was not able to get anything off. I surfed the internet and youtube but found no videos regarding this specific model, thanks in advance

Pic of the backplate ( [https://ibb.co/0B7KcWh](https://ibb.co/0B7KcWh) )",YoungNerdyOne,2021-04-11 18:00:35,2,2,1.0
780,"Hi, i updated everything needed to enable Resizable BAR on my Strix Rtx 3080  
vBios, mb bios and driver are all updated but Res BAR is still disabled, am i missing something?

https://preview.redd.it/yyeealp01ls61.png?width=559&format=png&auto=webp&s=8b99cc0ab0b8f66cfef3f92f4717c1a8da8061f7

https://i.redd.it/18xddkp01ls61.gif

https://preview.redd.it/un5gojp01ls61.png?width=945&format=png&auto=webp&s=8b24d1ff1814dd1f16eaad98c0f18ce2ea366c42",SparkyLollers,2021-04-11 17:51:59,2,8,0.6
781,"My 3090 was struggling. No way around it. During gaming, HWInfo64 memory junction temps were hitting 110C-120C, at 20C ambient. So, I waterblocked it, using the EKWB special edition FE block. Wow!

&#x200B;

Temps are nuts. 60C under load at 20C ambient for the memory.  [https://imgur.com/a/GbhbktM](https://imgur.com/a/GbhbktM). The Repaste W/ Hydronaut, new EK thermal pads and waterblock really did the job!

&#x200B;

&#x200B;

TLDR: Don't RMA, just spend 3k on a custom loop.",speedmachine666,2021-04-11 17:49:54,65,29,0.87
782,"My dad and I are trying to get a 3080 (specifically the XC3 or FTW3)

Are we still able to use the step up program? 

If so, what card do I have to get to ""step up"" to the 3080? 

Can I just go try to find a 2080 then ""step up"" for a 3080?  

Has anyone tried this?",anonymouspsy,2021-04-11 17:47:00,0,13,0.5
783,"Seeing as how it's impossible to get a card at a reasonable price these days, I'm considering between two prebuilt systems. Functionally they seem pretty similar aside from the GPU. I know that the HP has slightly better parts overall but I'm on the fence as to whether it is worth the difference in price. Specs are below. Any thoughts or advice would be greatly appreciated!

**Lenovo Legion T530 - $1000**  
Ryzen 7 3700X  
Windows 10 Home  
16GB DDR4 2666 (8GB x 2)  
256GB M.2 NVMe SSD  
2TB 7200 rpm HDD  
DVD super multi drive  
Bluetooth 4.2  
802.11ac/a/b/g/n WiFi 5  
500W 80 Plus Bronze  
RTX 2060

**HP Pavilion TG01 - $1500**  
i7-10700F  
Windows 10 Pro  
16GB DDR4-2933 (8GB x 2)  
512GB M.2 NVMe SSD  
1TB 7200 rpm HDD  
No optical drive  
Bluetooth 5.0  
802.11ax WiFi 6  
500W 80 Plus Gold  
RTX 3060 Ti",friesfish,2021-04-11 16:54:16,7,16,0.82
784,"Since the 3000 series launch in September 2020 I've been desperately craving for a RTX 3080 GPU. I really hoped the graphics card crisis would end in a few months, but that wasn't the case. I won't buy a prebuild because I already have very good specs except the GPU. In my country 3080's are listed for 2500 euros. I have been saving money for a new graphics card for 2 years now and I'm getting sick of waiting. What are my options?",D3V0URED,2021-04-11 16:12:49,2,22,0.6
786,"# [What Will NVIDIA CEO Jensen Huang Cook Up This Time at NVIDIA GTC?](https://blogs.nvidia.com/blog/2021/04/06/nvidia-keynote-gtc/)

**What**: GTC 21 Keynote

**When:**  Monday, April 12, starting at 8:30 a.m. PT. [Click here to see the time in your timezone](https://www.timeanddate.com/worldclock/fixedtime.html?msg=NVIDIA+GTC+2021+Keynote&iso=20210412T0830&p1=886&ah=1&am=30)

**Where:**

* [YouTube](https://youtu.be/eAn_oiZwUXA)
* [NVIDIA GTC Website](https://www.nvidia.com/en-us/gtc/keynote/)
* [IBM](https://video.ibm.com/gpu-technology-conference)
* [Twitter Event](https://twitter.com/i/events/1369725028795748353)
* Facebook Live on [NVIDIA page](http://facebook.com/NVIDIA)
* [VentureBeat](https://www.venturebeat.com/)
* [The Next Platform](https://www.nextplatform.com/)
* [SiliconANGLE](https://siliconangle.com/)
* [HPCWire](http://www.hpcwire.com/)
* [Enterprise AI](https://www.enterpriseai.news/)
* [Serve The Home](https://www.servethehome.com/)
* [PNY](https://www.pny.com/company/events/gtc)

**How**: **Discord** \- You can join [our Discord server](https://discord.gg/nvidia) and chat about the event live! We have recently revamped the server and we have a special GTC 21 section too!

**Special Meta Announcement**: Please make sure you look at ""New"" section to ensure you are not duplicating post. This will help immensely!

**Lastly, I would NOT expect any gaming announcement in GTC 21. This event is usually focused on enterprise and data center level products.**

# Contact Us

That's all for now. Any questions please feel free to [contact us directly](https://www.reddit.com/message/compose?to=%2Fr%2Fnvidia).

Thanks!",Nestledrink,2021-04-11 15:38:04,29,29,0.94
787,"The website lists the boost clock difference as 15mhz. The OC version is $300 more than the non OC. Is there any difference other than a 15mhz difference in clock? 

Also I read online that the power limit is locked on this card, but I was able to increase the power limit 10% in afterburner, same as reference. (OC Version)",amac109,2021-04-11 15:24:38,1,13,0.57
788,"Managed to score a 3070 Suprim X for 1000 euros (I know, I know) but I'm really looking to get a 3080 to use as my editing/rendering/streaming/gaming rig.

I'm sure the sensible thing to do is to sell it for a profit, but that 1080ti is giving me a headache with its fan failing and I'm not sure I can snag a 3080 at anything close to a reasonable price...",Bitt3rSteel,2021-04-11 14:56:20,0,5,0.5
789,"When using background removal, how to access the alpha/matte channel?",mithr4ndr,2021-04-11 14:19:12,4,1,0.83
790,"Hi,

Hopeful someone more knowledgeable than me can assist please.

I'm looking to upgrade my graphics card from a GTX970 to something a bit beefier and want to see if I need to consider anything apart from just a straight up replacement.

My PC is doing well and I have no issues with the 970 as such, but I just want to be able to use ray tracing when making games/projects in Unreal Engine 4. I don't really play games on my PC so I'm looking for something probably in the 30 series (when/if they become available) but don't want to go overkill for a high-cost GPU I don't need. I use 3 monitors, 2 with DisplayPort & 1 HDMI.

My current specs for the meaty stuff on my PC are:

 **Processor (CPU):** Intel® Core™i7 Quad Core Processor i7-4790 (3.6GHz) 8MB Cache

**Motherboard:** ASUS® SABERTOOTH Z97 MARK S: USB 3.0, SATA 6.0GB/s, THERMAL ARMOR

**Memory (RAM)**16GB KINGSTON DUAL-DDR3 1600MHz (2 x 8GB)

**Graphics Card** 4GB NVIDIA GEFORCE GTX 970 

**Power Supply** Corsair RM750x

My question is, which graphics card would you recommend, and with the specs listed above, will there be any issue in me just straight up switching out the graphics card old for new?

Thanks for any help",Shearer157,2021-04-11 14:06:09,2,12,0.62
794,"**Solution: I had DSR (Dynamic Super Resolution) activated, but still played native. No clue why it limits the fps since i don't see any reasoning for that, but it did. If anyone knows why please share. What does DSR have to do with an fps limit? I leave this post up if someone in the future has the same issue.**

I have a 165hz monitor and games are limited to 165 fps. This comes out of nowhere.

Example CSGO:

fps_max is set to 250 atm

Vsync ingame - off

nvidia control panel csgo settings- vsync off, fixed refresh rate (deactivates gsync), no fps limiter active

RTSS - CSGO is set to 0, means unlimited fps

Update: Other games have usually of course gsync enabled, vsync on via nvcp and a fps limit via RTSS of 162 fps. Now to test it i disabled the fps limit and turned vsync off. In BFV i had the same issue. FPS limited to 165hz.

I didn't install any new software that could limit the fps. I reinstalled Armoury crate yesterday and Logitech G Hub. I didn't find anything that could limit fps in these 2 apps.

Anyone has a suggestion what to look out for?",LewAshby309,2021-04-11 12:13:47,1,12,0.57
795,"Hey guys. I have a 3090 since a few months and it is in RMA currently because of stupid temperature for the memory (104°C even while playing evil genius 2..... ) 

Since i know that even if Nvidia did better use of thermal pads, i was wondering if swapping my old, noisy CPU AIO for an air cooled ventirad in vertical mount with cool air pulled from the GPU side and hot air sent top of the case (which is ventilated), i could drastically increase the airflow on my GPU backplate which would remove quite a bit of heat. 

My CPU is a 8700k so i think that most of CPU coolers can be mounted verticaly. I didn't see anything about that kind of sollution on the web, so i wanted to know if someont here tried something like that. 

Thanks!",La_mer_noire,2021-04-11 11:32:05,0,4,0.5
798,"Sorry if this isn't the place to ask, but does anyone know a fix for Geforce Experience recording my mouse movements of my first monitor, while recording the contents of my second monitor? It's very annoying, since I have a project overdue, that requires the use of my mouse. Thanks!",MansionOfNightmares,2021-04-11 10:17:58,3,7,1.0
799,"I got an Asus TUF  3080 O10G.

I got 17150 graphics score stock on 3DMark Time Spy, g-sync and v sync off (which seems low, most of people seems to have rather 17700 on stock)

I used MSI afterburner likes in the guides, lower the whole curve and increase the frequency up to 1850MHz at 850mV for instance.

However I'm confused, what is the real impact of the negative offset on the whole curve ?

What is the difference between -100MHz or -300MHz, people seems to lower this randomly in the guides, somes set it so the curve reach 1845MHz max, but why 1845 ? why not 1800 or 1750 ?

Also if I put 875mV at 1905MHz or 1935MHz, I basically got the same score on Time Spy, 17 650, even tho the frequency remains the same during the whole test.

Why do I get the same score with an higher and stable clock ?",AdrienQua,2021-04-11 09:50:41,5,15,0.73
800,Does anyone know the benchmarks of the 3080 with shaders and max render distance?,TheIronIndoor,2021-04-11 08:24:14,3,1,0.8
801,"I'm buying a Legion 5 Pro, which for some reason has a 16:10 display. Is there a way to force black bars and 16:9 on a driver level? Asking because not all games have an aspect ratio setting and some of those that do just stretch (if you select 4:3 on a 16:9 monitor).",dustojnikhummer,2021-04-11 08:18:28,1,13,0.67
802,Does anyone know roughly how much CFM of air the blower portion of the 3080 FE exhausts out the back of the case? Thanks,Willgames2003,2021-04-11 08:15:19,5,13,0.99
805,My card goes at 84 celcius when gaming. Is that a safe temp? My case is the Lian Li TU150.,shulzcharlie,2021-04-11 01:51:13,1,7,0.6
806,"Hey all.

So I have a total of THREE Nvidia GPU's in my machine, the newest of which is a 760 that I cannot keep from thermal throttling at heavy usage no matter how hard I try.

I got caught flatfooted by the GPU shortage of 2020 and I'm sitting here like a thirsty man in a desert wondering what the hell to do.

I see there's some rumors of a new  **GeForce GTX 1080 Ti**[\[](https://en.wikipedia.org/wiki/GeForce_10_series#cite_note-62) run but I'm not getting my hopes up too high since Nvidia is doing jack-all to stop all the cards going to scalpers and miners.

So in light of all that...what's my best option for a card that has a significant improvement over my current one *that I can actually get some time in the near future for a non-scalped price?*",HoldingOut4Miracle,2021-04-11 01:43:50,5,16,0.65
810,Will it be sufficient in supplying 450 watts ?,sleepy_the_fish,2021-04-10 19:30:42,2,7,0.75
815,"The fan broken past repair and I like playing games on my 1030 so I’m worried I won’t be able to do that or work on programming, where can I buy a replacement fan with fast shipping preferably on Amazon?!?!",IMakeWaifuGifsSoDmMe,2021-04-10 16:18:37,5,7,0.78
816,"hi i was just wondering if this was a good fan curve, because i dont really know that much about it.

https://preview.redd.it/0mw6ejsj8ds61.png?width=413&format=png&auto=webp&s=f2d3e53a998d044fb545ec7baa3f743337a83ff4",Jacob_Thorhauge,2021-04-10 15:38:33,1,5,0.6
817,"I'm thinking of buying a gaming laptop but im unsure if the 200 euros extra for 3070 is worth it over the 3060. 
The laptop is MSI GP76 17.3",Ryanpolaren,2021-04-10 15:24:57,0,11,0.5
818,"As there isn't much information about opening this specific card, I thought of taking pictures so I could walk all of you through this process. I'll be opening up the card and replacing the thermal paste and the thermal pads on BOTH sides.

I've also taken screenshots of the temperatures before and after.

The purpose of me doing this is I want to mine Ethereum with it and noticed the memory was getting pretty hot (95 degrees).

In case you're interested in my MSI Afterburner adjustments for mining:

**Core clock**: -200 mhz

**Memory clock**: +500 before / +950 after replacing thermal pads

**Power limit**: 65%

**Fan speed**: 60%

&#x200B;

The products I used for replacement:

**Thermal paste**: Thermal Grizzly Kryonaut

**Thermal pads**: Arctic APT2560 thermal pads

Some remarks:

\- I've read that Inno3D supposedly used 1mm thermal pads for everything on the front side (the side where you can see your GPU chip). However, I noticed that 2 strips wouldn't connect properly, so I've used 2mm there.

\- On the backplate side, there were both thermal pads with a thickness of 3mm and 2mm.

\- Be careful with the warranty sticker when you want to get to the backplate side. Sadly, I couldn't keep mine in one piece.

I hope this helps you. Good luck!

&#x200B;

https://preview.redd.it/p5b404h5wcs61.jpg?width=2093&format=pjpg&auto=webp&s=0473f0dc49d7d5cd2817cdafd59f41b888258ef1

https://preview.redd.it/1wzlxyg5wcs61.jpg?width=1988&format=pjpg&auto=webp&s=d1be452d91055c692ff54422b08457e2dce95805

https://preview.redd.it/4z4q6zg5wcs61.jpg?width=2024&format=pjpg&auto=webp&s=f02b05997770fa6d31f79b00068792dc199645f2

https://preview.redd.it/tm02zdh5wcs61.jpg?width=2146&format=pjpg&auto=webp&s=54e4095497ba9bca9b6719e71f4bf95b1c09ebdb

https://preview.redd.it/rpwbh2h5wcs61.jpg?width=2014&format=pjpg&auto=webp&s=f2fe91f94e2b368bccac16e0c95e00b56676f1b7

https://preview.redd.it/jpp5n2h5wcs61.jpg?width=2000&format=pjpg&auto=webp&s=ebed6528bfc27238a1acefe4e956026e946eed34

https://preview.redd.it/8qh0p5h5wcs61.jpg?width=2040&format=pjpg&auto=webp&s=69081885a34f792d0a5c3a6307bcfa74f4016600

https://preview.redd.it/s160k0h5wcs61.jpg?width=1947&format=pjpg&auto=webp&s=9edf048bad79545168f7305f672804100bfc9c57

https://preview.redd.it/ghh7lvg5wcs61.png?width=803&format=png&auto=webp&s=dbc0f65b37a04e027939d0503c4fc46ab148421a

https://preview.redd.it/hmuvrvg5wcs61.png?width=803&format=png&auto=webp&s=96bea3022a1f347a7f0131a0208920cdefb5e452",ixRobin,2021-04-10 14:28:45,9,26,0.74
819,Anybody running an LG 27GN950 with a 3090? Trying to decide if it’s worth spending the extra for the 4K monitor or should I just pick up a 1440p?,Mad_Moneyman,2021-04-10 13:37:22,3,10,1.0
821,"Inet in stock date for 2021 Legion 7 (R9, 16Gb 3080, 32Gb RAM) just got pushed from April to 8/31. If you are Europe/Sweden based can you offer any further knowledge of why this is? (assuming standard supply issues).. can you also share places to buy?

Understand why they released at CES but could at least give worst-case stock estimates instead of having to push back dates

(note, all Legion related subs seem to not allow me to post this for some reason.. wonder why)",inspired_randomly,2021-04-10 12:35:10,4,2,1.0
822,"My 3080 FE's memory junction temp hit a max of 102 C after 20 minutes of playing Control.

Would undervolting do anything to lower this temperature?",Derpface123,2021-04-10 12:15:04,5,13,0.74
826,Does Best Buy still restock the GTX 1650?,JayKappa2x,2021-04-10 05:12:12,1,4,0.6
827,"I have a i3 2100 and integrated 2000, im planning to upgrade as i do hardcore video editing on Adobe After Effects, my current gpu cant preview on 1/8th without effects less than 6 fps, i researched, and a i3 2100 will run well with a 1050 ti, will i be able to preview/render faster?",PxndaFN_,2021-04-10 06:29:28,3,9,0.67
828,Does anyone know when the next restock for the 3070s in Australia is or just in general,dank_29,2021-04-10 04:16:35,0,7,0.42
830,"Hi im plaing on upgrading my gpu from a 1050 ti to a 3060. Is there anything i need to know? New Cords i need, some sort of converter? I have a 650w gold power supply.
Thanks",redditorunknown44,2021-04-10 01:32:39,0,8,0.38
831,"Hey all!  


Long story short, i have a 970 that i bought off a friend a while back, and its served me well, but im wanting an upgrade. And im looking for something that hopefully won't break the bank. I live in australia currently.",WubWubPwny,2021-04-09 23:58:03,2,18,0.58
832,"Hey guys,

Just wondering if anybody has happened on a copy of the engineering reference guide nvlink / nvswitch / hxm2 or has any experience in the design / implementation of the fpga switching fabric used; would love to pick your (hopefully) collective brains :)

Cheers in advance!",amal55,2021-04-09 21:58:44,7,2,0.9
833,"I have connected an RTX3080 to a Samsung Q60R via a DisplayPort <-> HDMI cable. The highest resolution offered both by Windows 10’s Display Options and by Nvidia’s Control Panel is 1080p@60Hz, but the TV supports HDMI 2.0 and 4K@60Hz on its HDMI inputs. Any idea on what could be the cause?",introiboad,2021-04-09 20:53:45,1,8,1.0
834,"**EDIT :** [**Note that this is apparently only applicable for DirectX 9 and 11 games as the NVIDIA driver has no control over the context queue of OpenGL, Vulkan and DirectX 12 games.**](https://www.reddit.com/r/nvidia/comments/mnq2sl/psa_you_dont_need_to_manually_limit_your/gtzfytt/?utm_source=reddit&utm_medium=web2x&context=3)

Heya,

I still see a lot of people mentioning that you should limit your framerate manually via NVCP or RTSS so that G-Sync is always active, but you should know that this is not necessary anymore if you have **Low Latency Mode set to Ultra** as well as **V-sync set to ""On""**. This will automatically limit your framerate to \~4 fps below your max refresh rate. Automatically limited to 116FPS on a 120Hz TV in my case.

You can also see some info to that effect if you hover over the ""Low Latency Mode"" setting in the NVCP : [https://i.imgur.com/KO4FEg0.png](https://i.imgur.com/KO4FEg0.png)

That's about it! Enjoy :)",Bacongineer,2021-04-09 20:35:12,1037,234,0.96
835,"&#x200B;

https://preview.redd.it/t5ukat53i6s61.jpg?width=1400&format=pjpg&auto=webp&s=91d727d45018087abc33e04ab31d1abbaace416f

I'm still between new cases and trying to keep my FE cool anyway possible meanwhile :)",mltxf,2021-04-09 17:00:27,0,3,0.21
839," 

here's the deal. I upgraded to a gtx 1080 a few years ago with plans to sli when I noticed performance issues. I'm noticing those performance issues and I guess sli is dead. Would it still be worth the upgrade or would it be better to try to sell my 1080 for a newer card. I'm looking to upgrade my PC fully which is why i was hoping to sli, as I was gonna by a used pc with a 1080 and combine the two into a new case. With current GPU prices not sure what other option I have that's in my price range, but if sli is dead dead I guess I have no other choice.

Other specs:

i7-6700k

32gb ram

Maximus VIII Hero motherboard

CS850M Power Supply",HeyItzLucky,2021-04-09 16:08:44,0,13,0.42
842,"&#x200B;

[Gaming setup](https://preview.redd.it/etm5aqku06s61.jpg?width=3264&format=pjpg&auto=webp&s=54384ff74e62bdac038222a7b9f2f4cca04a8322)

&#x200B;

[Inside build](https://preview.redd.it/pj9obxs016s61.jpg?width=3264&format=pjpg&auto=webp&s=c36265767eaddf42074a9e103378924c732ed60c)

Gaming PC Specs:

Nvidia Gigabyte RTX 3080 Vision OC

AMD Ryzen 7 5800x

MSI B550 Gaming edge WiFi 

16GB patriot viper RGB C17

Corsair H100i elite capellix

Adata spectric rgb m.2 512GB

WD SATA 500GB SSD

Corsair 4000D Airflow

4X LL120 fans 

Monitor: ASUS ROG STRIX XG27UQ 4K 144hz 27” NVIDIA G SYNC COMPATIBLE

Gaming mouse: Glorious Model D-

Gaming keyboard- Havit RGB wired mechanical keyboard 

mouse mat- Aukey large mouse mat

speakers- Logitech z200 wired speakers",MirageVoyage18,2021-04-09 15:30:06,0,11,0.4
844,"No reviews at all and can't find it anywhere
Does anyone actually have it?",ForeignWelcome8,2021-04-09 10:14:22,10,12,0.78
846,"Hi everyone, just noticed that ASUS have released a new version of their ReBAR vBIOS for the 3080 lineup.

Unable to find a changelog ~~but presumably it's to correct the issues with the V3 update bricking some cards.~~

https://www.asus.com/au/Motherboards-Components/Graphics-Cards/TUF-Gaming/TUF-RTX3080-O10G-GAMING/HelpDesk_BIOS/

https://dlcdnets.asus.com/pub/ASUS/Graphic%20Card/NVIDIA/Utilities/RTX3080_V4.exe

--

V3 and V4 comparison: https://imgur.com/a/HS5JlgE

vBIOS ROMs are unchanged so you shouldn't need to update if you've already flashed V3.",twinviper,2021-04-09 04:52:18,22,35,0.78
847,"I was planning to wait for the rtx 3070 to become more available so that I could use it in my first pc build, but in the mean time I've been doing more research and read somewhere that workstation gpus are more appropriate for 3d rendering and ""content creation"" than the gaming cards. I'm not a gamer and don't intend to really get into it so my reason for wanting a graphics card at all (coming from having only a 2013 macbook pro) is to improve my workflow with 3d modeling/animation/rendering. Since I still want to go with Nvidia, I was looking at the Quado series vs the Geforce cards but 1.) I'm confused about the Quadro series numbers (like which one is the most recent?)  2.) do they not sell the quadro cards individually in the same way that they do the geforce cards? and 3.) can anyone attest that the workstation cards really are better for 3d rendering than the geforce cards? Its really hard for me to find information online regarding benchmarks to really see how the quadro cards measure up to the geforce once. Even on Nvidia's own website they seem to focus more on their cards for gaming uses. I don't even know how much one of these newer series quadro cards would cost to know if it is even reasonable to buy this versus the geforce cards.",pomegranatelover1990,2021-04-09 04:30:12,17,10,0.95
848,"Hi All!

I am in need of help from the the community here.  I have a EVGA 1080i SC2 Hybrid that the water cooler went out on outside of warranty an EVGA wouldn't honor it. I tried to install the NZXT Kraken and respective cooler and everything worked fine for about 5 minutes then screen went black and has never com back on. I tried everything to ensure it was wasn't my PC. I took off the cooler and searched until I found a surface mount capacitor that was blown on chip U10 on the PCBA. I think its a  TPSM53603.

I tried working with an E.E. friend I have to determine the cap value and size, we tried replacing it and could not get it to work and in the process we knocked off the tiny resistor next to it.  

An interesting thing is if I boot windows with it in the PCI slot and HDMI connected to the MB IGP I can actually get the device manager to shot the device but eventually I will blue screen within a few minutes of starting. If I feel the card after a few minutes of use all the components seem to be warm indicating some positive prognosis? 

I am trying to figure out what the components are sorry. I don't know what value of capacitor and resistor value to order or what footprint that's what I'm hoping to find. A couple of friends said to reach out to Reddit and see if somebody had an idea or schematic.

I am wondering if there is anyone out there that can help me figure out if I can salvage this card and replace these two parts. I do have access to PCBA magnification equipment at work to see what I'm doing. With the price of cards I really want to fix this and not pay exorbitant GPU prices. Any help would be appreciated! Thanks



Card: [https://imgur.com/piTn9jj](https://imgur.com/piTn9jj)

Close up: [https://imgur.com/R1c9lT8](https://imgur.com/R1c9lT8)

For Scale: [https://imgur.com/JtEgq1c](https://imgur.com/JtEgq1c)",syco0601,2021-04-09 03:13:26,9,10,0.8
849,"Hi everyone, got this beautiful card today, wondering about some recommendations for a custom fan curve to set up in afterburner to make sure the GPU gets some proper cooling during those intense gaming sessions. I switched from an AMD card and honestly nVidia not having something like radeon control center where I can adjust the fan curve,clocks,power limit etc in a few clicks was quite shocking to me.",LAFERRARI963,2021-04-09 01:20:07,0,6,0.5
850,"Hey guys,

Not sure if this is the right place to post this but I was just wondering how successful people are using the step up program or are people in limbo waiting in line for their gpus because of the current shortage? Is it still a good idea to get a evga card and depend on stepping up or should I just get any card I can and not worry about the reliability of the program.",Snoo_11263,2021-04-09 01:09:29,1,4,0.6
851,"I am planning to upgrade on a i7-4790 CPU.  I am trying to avoid drastical bottlenecking so i made a tight circle for these two cards. Which one should i choose, preferably for 4K gaming. I also plan on playing GTA V and RDR2 so i hope that could give a good view on the situation.  If someone has a better matching card i would appreciate the suggestion.

\*edit - Bonus question, what do you think of cyri/bottleneck calculators? How accurate are they?",TheToeSuckler69,2021-04-08 22:03:02,4,33,0.75
852,"Hi everyone!

Here is my experiment on changing thermal pads to copper plate on my RTX3080 MSI Gaming X Trio. 

As we know there is 1mm thermal pads on memory chips in MSI Trio. On stock version i have around 100C during mining on memory. Than I changed thermal pads (made post here) and got around 82-86C. But I alwayse wanted to try copper plates instead of thermal pads. Here is my experiment:

1) You have to be carefull and make dielectric around the perimeter of all memory chips not to make short circuit

2) In MSI Trio best thinkness of plate is 0,9mm. 1mm is too thick. But there is only 1mm and 0.8mm on the market, so we have to make it mannually.

Here are my results with 1mm and 0.8mm plates: around 70C while mining and silent 1350 cooler rpm!

&#x200B;

https://preview.redd.it/y9iltxqyk0s61.jpg?width=2294&format=pjpg&auto=webp&s=098bed6c4ca7fa89898d3502b9c42567ff168fdf

for more details You can watch full video

[https://youtu.be/oO5KNGXiRzk](https://youtu.be/oO5KNGXiRzk)

(dont forget to turn on english subs)",amfgray,2021-04-08 21:06:59,53,19,0.89
853,anybody flashed their 3090 Ventus 3x to a new gaming OC vbios?,MuscleStranger,2021-04-08 20:49:09,0,11,0.44
854,"I made a template for cutting the thermal pad pieces for the 3090 FE: [https://drive.google.com/file/d/18rPk56D8gdOPSzdKH4sC0SCKelHtBGnV/view?usp=sharing](https://drive.google.com/file/d/18rPk56D8gdOPSzdKH4sC0SCKelHtBGnV/view?usp=sharing)

Instructions, courtesy of CryptoAtHome: [https://www.youtube.com/watch?v=G3260LR2JzQ](https://www.youtube.com/watch?v=G3260LR2JzQ)

I achieved -20C memory junction temps (as measured by HWiNFO) by doing this. My card went from sounding like a jet engine with fans at 100% when gaming or mining, to being almost completely silent.

Some tips:

\- After you detach the cables, it helps a lot to use a few pieces of tape to hold them back and keep them out of the way.

\- Don't try to cut the thermal pad with scissors - it squashes the edges. Just use a knife and ruler, it's easier.

\- The thermal pad has a smooth side with clear plastic, and a rough side with blue plastic. The smooth side is stickier, and you want to put this side down on whatever surface you're placing the pads on. Remove the clear plastic before applying the pads. You can leave the blue plastic on until you reassemble, to avoid getting dust and fingerprints on that side.

\- I used 3 pads and had a little left over. Note that the 74x8 strip wouldn't fit in the template, so I split it into two pieces (41x8 and 33x8). You could save a cut by doing these as one 45x8 (i.e. make the 41x8 full width) and one 29x8.

\- All the pieces are symmetric, except for the two with diagonals. Make sure you cut the diagonal pieces the right way round - I did them backwards so I had the rough side facing down, and they fell off during reassembly.

\- Do re-paste the GPU. I used NT-H1. Your GPU core temps may go up a bit after the mod. This is because your card is able to run faster since it is no longer throttling on memory, and the fans are running slower so the GPU core isn't being cooled as much.

\- I have two 3090 FE cards. The second one I received more recently, and it runs \~10C cooler out of the box than the first one. It's possible Nvidia has changed pads over the last few months. I decided to replace the pads anyway on the newer card since it still runs hotter than the older card does with the Thermalright pads.",GoodToForecast,2021-04-08 19:42:43,978,274,0.98
855,"I don't understand anything I read on the subject anymore so I need your advices.

What is the best solution for FPS games?

1. **Do not limit FPS + Reflex ON Boost**
2. **G-Sync ON + V-Sync (Nvidia) ON + Limit FPS** (138 for me).
3. **G-Sync ON + V-Sync (Nvidia) ON + Reflex ON Boost (No FPS limit)**
4. **G-Sync ON + V-Sync (Nvidia) ON + Reflex ON Boost + Limit FPS (How much to limit FPS?)**

In the 4th case, I ask how much I have to limit my FPS because I base myself on the test of a person of the forum ""Blurbusters"". Here is the excerpt in question:

""If an in-game or external FPS limiter is to be used with Reflex enabled, the in-game or external limiter must set slightly below Reflex's automatic limit for it to override Reflex's. This will not override Reflex's auto FPS limiting function (and thus, render queue elimination benefits) when the game is GPU-bound and frames are fluctuating, and will instead only override the initial static Reflex FPS limit where the game is not GPU-bound and the system can maintain a framerate that could otherwise exceed the limiters if they were disabled."" 

[https://forums.blurbusters.com/viewtopic.php?f=10&t=7522&sid=3024a1748bd659fe4ee2c69a6f45a6f8](https://forums.blurbusters.com/viewtopic.php?f=10&t=7522&sid=3024a1748bd659fe4ee2c69a6f45a6f8)

&#x200B;

If the best is the 4th case, **what should I limit my FPS to? 138 or less** (135)?

&#x200B;

Sorry if my question sounds silly but I'm not a great expert and I'm starting to get lost reading different opinions.",Altair4Eagle,2021-04-08 19:25:12,14,33,0.86
857,Was just notified from tech support after failed attempts at installing the upgraded VBios on the PNY 3090 that a new version was just released. They had pulled it a few weeks back.,1800lampshade,2021-04-08 18:37:38,5,7,0.73
858,"Hey guys,

trying to setup rebar for my evga 3080 ftw3 with my ryzen 5600x on my b550 f gaming wifi board but cant seem to find the option to enable rebar in the bios. Gpu Drivers are up to date, precision x1 was used to update the gpu firmware and I have tried the 2003, 2006 and the 2201 bios versions for my mainboard but theres no option for me to enable rebar. 

Precision x1 says ""please check with your motherboard vendor"" under resizable bar. Anyone got an idea what might be the issue here? Thanks!",sinfuljunes,2021-04-08 18:30:23,2,4,0.6
859,"Big thanks go out to the tech support team at Gigabyte for supporting their 3090 Turbo 24G model, which got discontinued in February, and isn't even listed on their site. I figured I was hosed when Resizable Bar was added to their motherboards, but the 3090 Turbo (their only 3090 blower model) disappeared into the ether.  


To my surprise they were able to provide a VBIOS for this card that brings it up to current spec, and enables Resizable Bar. As an ex-mac guy (not entirely true as I still have a MacBook pro) my expectations for customer support weren't high. However having jumped back into the PC world this has been pretty great.  


TL;DR: Gigabyte provided an updated VBIOS for a 3090 that likely wasn't very popular in sales, and still added Resizable Bar support months after the card was discontinued.",lawndartdesign,2021-04-08 18:25:15,14,59,0.71
862,"Hi,

&#x200B;

I'm doing a one a decade purchase of a new monitor for my new system (i7-11600F RTX 3080) from what seems an eternity on 1080p gaming mostly on a 1080pTV or an old 1080p monitor.

&#x200B;

After many hours online (reddit, ninja display,tomshardware, linustechtips etc) reading on the subject, I stumbled upon the Nvidia GSYNC list with the premium the g-sync and the compatible monitors to my surprise, saw refresh rate ranges for the first time. I think that beside going 1440p GSYNC would be the most noticeable experience upgrade for hungry games like MSFS2020 where hitting 60fps is a dream and time is mostly spent under 50fps. I thought that any monitor with freesync premium of just LFC would be enough but all of those are listed with 48-144hz refresh ranges.

&#x200B;

I was wondering how much g-sync is an upgrade for my lowfps case. Also if freesync LFC works on NVIDIA gpus for low fps cases.

&#x200B;

To my understanding, an NVIDIA gpu on a full g-sync will work A1 from 1fps to 144+ fps (since the range is 1-144hz). Also an NVIDIA gpu on freesync premium or just freesync LFC woud not benefit from lfc but be perfect for 48-144fps (with a 48-144hz).

&#x200B;

&#x200B;

I never took that much time to choose a monitor but I feel completely out of the market with adaptative sync, free sync, freesync premium, g-sync, g-sync ultimate,g-sync compatible, g-sync compatible but not liste nowhere.

&#x200B;

Any advice on how NVIDIA GPUs behave on all there sync protocols would really be appreciated. Also your view on getting a new 1080p real g-sync monitor instead of looking for 1440p or a 4k 40-60hz with adaptative sync...

&#x200B;

Thanks.",Dukefromearth,2021-04-08 16:52:25,22,54,0.88
864," Wanting to save my 3080 FE from hell so I can actually start mining without worrying about it killing my GPU. But I want to buy the GELID pads after hearing about how it compresses way better than the Thermalright pads, giving you even better temps and higher success rates. The problem is that they are out of stock. The 3mm pads are available to buy from the actual GELID website but they don't for whatever reason, ship to the UK, which is where I am located. Anyone know when they could restock at UK stores or any other retailer where they ship internationally? Thanks for reading.",stop-the-cap-,2021-04-08 15:03:43,6,24,0.63
865,"From my person experience on 3080fe, most thermal pad talks about thickness, heat conductivity are likely bullshit.

I swapped pads and the vram temp went up first. And I know many have same problem. 

Vram junction temp is the highest temp reported by vrams. Identifying the hottest vram and just do something about that one is the key. 

Now @214W, memclock +850, fan@65%, my vram temp is 86-88C.

I posted my experience in 3080 subreddit which is not a popular place 😂
https://www.reddit.com/r/RTX3080/comments/mid9ql/rtx3080_fe_thermal_pad_mod_experience_sharing/?utm_source=share&utm_medium=ios_app&utm_name=iossmf",Gold_Solution569,2021-04-08 14:54:46,3,8,0.59
867,"Has anyone tried replacing the thermal pads for the memory on the Asus tuf 3090? I haven't been able to find any exact measurements for the pads online.

And from what I can tell, you basically have to deshroud the card to get to the pads. Anyone got pics of a teardown to see how to do it?
Thanks!",spin1490,2021-04-08 12:38:01,22,46,0.89
868,"As the title says, I have no idea and honestly I am in need for a new station for my work ....

&#x200B;

// thank you for your time and comments, I will go for a prebuild option.",Calamity_Armor,2021-04-08 07:52:07,5,17,0.73
869,So ye please help me,GateCodeMark,2021-04-08 06:04:41,0,6,0.5
870,"Not sure if it's been discussed on here, but I wanted to ask if there any thermal pads I could purchase online to mitigate the hot VRAM temps that have shown up.

Also, sorry if this violates guidelines, I'm not sure if this is appropriate for this subreddit.",mendozarene16,2021-04-08 05:45:24,0,45,0.44
871,"Hello! I am running the 1080 Duke in my build. I have been wanting to get my hands on the new 30 series for awhile now and have some questions. Like most people I’d love to get my hands on a 3070 or 3080 (possibly even the 3060.) But is it really worth it at the point in time? For anyone that has one or is more knowledgeable, is it worth it for me to buy any of these newer cards (if I can get my hands on one.) Thank you, hope everyone is well.",sneakz011,2021-04-08 02:05:38,0,12,0.5
872,"Want to save my poor gpu from hell. Seeing different answers for the thermal pads used, which one do I actually go with? 1.5mm, 2mm or 3mm?",stop-the-cap-,2021-04-08 00:31:02,0,19,0.5
874,Its about 73 when I play games room is kinda hot. Planning to move to basement where its colder. Was wondering what everyone else has.,Wowstar19,2021-04-08 00:23:41,2,20,0.67
875,I assume the 3080 will go out of production by then? Idk i just feel like theres a chance my 3080 will go defective on the third year of its warranty because of the high temperature vram chips. What will happen? Will they attempt to repair it? Replace it with a better card? Give me a refurbished unit?,stop-the-cap-,2021-04-07 23:57:24,5,28,0.67
877,They don’t notify when they restock so what time do they typically restock? Or day?,Technoob839,2021-04-07 20:58:09,3,10,0.64
878,"I'm currently working on turning a Dell Poweredge R720 into a cloud gaming server (I know you're not supposed to game on a server, but I loved the idea!). I bought 2x Nvidia Grid K2, however, they are very slow and aren't optimized for it. Is there any other options I could go for that won't empty my wallet? 

&#x200B;

I have had 1 slot GPUs in mind as well (I would love to have 4 people to be able to play), but I haven't managed to find any good 1 slot GPUs except the Quadro (Which costs more than my entire homelab ;-;)

&#x200B;

Also, suggestions for what I can use the Grid K2's would also be welcome, I have no clue what to use them for now :,)",Ejo2001,2021-04-07 18:23:07,1,27,0.53
880,Wondering if anyone has repasted or replaced thermal pads in their 3090 and how that worked out?,ObsidianWalker,2021-04-07 16:49:06,0,11,0.4
881,"The old thread was archived, so I am starting up this thread for all who want to discuss the status of the EVGA queue, give updates on their queue position, or let us know when the spreadsheets go haywire.

\*If you signed up for the queue prior to January 11th, 2021, you will be eligible to receive a card for the original price ($70 less than the price currently on the website) if your notify comes up before May 14th, 2021\*

Link to original thread: [https://www.reddit.com/r/nvidia/comments/j6vb1d/spreadsheet\_to\_track\_queue\_position\_for\_evga\_rtx/](https://www.reddit.com/r/nvidia/comments/j6vb1d/spreadsheet_to_track_queue_position_for_evga_rtx/)

&#x200B;

[FORM FOR 3070, 3080 AND 3090 MODELS](https://docs.google.com/forms/d/e/1FAIpQLSepMk2w5TVhlqtZDMP3rzZyY0X4Uklu_Sshpf55L-UtWYwvXQ/viewform?usp=sf_link)

[SPREADSHEET FOR 3070, 3080 AND 3090 MODELS](https://docs.google.com/spreadsheets/d/e/2PACX-1vRintBllSIYz0TBOTLSbxYW8trXO_V3GUsgOdBEksclTQyBMnXGbrW1j1z_44waeTjLa3t0KEHSjknP/pubhtml)

&#x200B;

[FORM FOR 3060 AND 3060 Ti](https://docs.google.com/forms/d/e/1FAIpQLSfZl2pNRDtfuPFoEsZ4AQ8Wc98o22WnToRCC0GOimpBw0cKMA/viewform)

[SPREADSHEET FOR 3060 AND 3060 Ti](https://docs.google.com/spreadsheets/d/e/2PACX-1vQd0xy7p5a2_JVSj-JI8cMt5t6x6o3e3_uUTUO6hRrpYVGjPdMdzQBlEJmq94_AU0JqwHHIuXYDDl5W/pubhtml)

&#x200B;

[SPREADSHEET FOR HYBRID AND HC](https://docs.google.com/spreadsheets/d/e/2PACX-1vSk_6AW8Zhfs_FnsDpDk_FNuJD-H-xmX1szUJ_RCQjjek4qnksP7BIGz5zi2BfUNqkz-jIA1J73yJcQ/pubhtml)

&#x200B;

Thanks to [u/brenden77](https://www.reddit.com/u/brenden77/) and [u/bradsour](https://www.reddit.com/u/bradsour/) for your help in maintaining the spreadsheets!",MinimumTumbleweed,2021-04-07 15:58:12,26,179,0.86
882,"I went from an i7-8700K at 5ghz to an i7-11700k at 5ghz and updated my mobo from z370 to Z590. All things being equal outside of this upgrade and having Resizable Bar on, my Watch Dogs Legion benchmarks went from 64FPS avg and 41 FPS 1% Low to 77 FPS a few and 61 FPS 1% Low!

Pretty decent gains. I think it’s a worthy upgrade for a new CPU during a time where it didn’t feel worthwhile. Ended up sticking with team blue due to familiarity of the BIOS settings.",StarkStorm,2021-04-07 07:08:07,0,14,0.24
883,"I'm currently rocking a 1060 6GB at the moment, contemplating on either waiting out the stock shortage or wait for the 4000 series, however, I was also contemplating on either a 4K or 1440p monitor. While thinking about this, I started to ponder about DLSS (easily my most anticipated feature when I upgrade) and whether or not I could use it to achieve supersampling on a 4K display. However, I was curious as to anyone else has tried this.",IAMJePROTOman,2021-04-07 04:33:56,19,36,0.78
885,"Hi, the title contains the whole question.

If it depends on the game, I'm talking about Skyrim, Dark Souls Remastered, and Fallout 4. Actually to disable Skyrim's V-Sync, I would have to do so in its .ini file, there is no option in its launcher menu.",TheFarticleParticle,2021-04-07 01:30:05,4,17,0.67
887,"For years, I have configured my settings on my FPS games according to the recommendations of experts:

G-Sync On + Nvidia V-Sync On + Limit my FPS by -5 FPS relative to my screen (in my case I limit to 138 FPS).

&#x200B;

Now, Nvidia has arrived on Apex Legends and Overwatch so I'm reviewing the mining I need to configure but I'm reading different opinions on the internet.

• **Should I continue to enable G-Sync with Reflex?** (I think it depends on whether you support image tearing or not).

&#x200B;

• **If G-Sync is enabled, automatically, I also enable V-Sync from Nvidia?**

&#x200B;

• **Should I continue to limit my FPS to 138 with Reflex?** I read that it was useless with Nvidia Reflex because it automatically limited my FPS.

In summary (as I understood it):

\- If I want the least latency possible it's just enable Reflex Boost without FPS limiting.

\- If I want a stable FPS (while having a little less latency): G-Sync Enabled + Reflex Boost + FPS limit at 138.

&#x200B;

I hope your advice will help me to finally understand this definitively.",7Z7-,2021-04-06 23:10:08,7,21,0.89
888,I need a good fan curve that will make my graphics card as quiet as possible both when gaming or when doing work.,MrTrashPanda17,2021-04-06 21:24:12,9,42,0.74
890,"Tried posting this on EVGA's forum and also tweeting at Jacob but got no response, guess I'll try here. This appears to be a bug with how the software detects the motherboard when a display is connected to the iGPU.

Motherboard: ASUS Prime z490-a

CPU: i9 10850k

GPU: EVGA RTX 3080 FTW3 Ultra

GPU is running latest drivers and newest vbios for Rebar. Motherboard is on BIOS version 2004 and has CSM disabled, Rebar enabled on home page and Rebar set to ""auto"" on PCI config. Boot method is UEFI.

When I first tried setting up Rebar it worked immediately. Since then I made this post about setting up an external hardware monitor [https://www.reddit.com/r/buildapc/comments/mip09c/you\_should\_know\_that\_aida64\_lets\_you\_build\_a/](https://www.reddit.com/r/buildapc/comments/mip09c/you_should_know_that_aida64_lets_you_build_a/)

I have been connecting that little screen to the iGPU. Went to try out Rebar yesterday and X1 was showing ""please consult your motherboard vendor"". Tried a few things and eventually tried disabling iGPU multi monitor support and unplugging the screen from the motherboard.

Rebooted and X1 picked Rebar back up again.

**TLDR:**

**X1 is bugged for Rebar if you have a display connected to the iGPU. Turn off the iGPU in BIOS and hook the screen up to the GPU should fix the issue.**",Free_Dome_Lover,2021-04-06 13:01:50,7,1,0.74
892,"About 30 minutes ago at time of writing, Scan listed two 3090 cards for sale - the Palit GamingPro at £1,895 and the Asus Strix OC at £2,240.  The Palit seems to have sold out pretty much immediately while the Strix is still available.

This seems like a departure from the rapid-selling *’SHUT UP AND TAKE MY MONEY’* behaviour across the GPU market in recent months.  Am I being overly optimistic or are we seeing the first glimmers of either sanity or filled demand?

Update: The Strix sold out in 50 minutes.  Which still seems slower than average in my limited experience.",Yuzral,2021-04-06 12:40:57,43,116,0.78
893,"My RTX 3080 Ventus x3 OC never drops below 60deg at ambient temp, even when the room is like 10 deg (UK spring 😂). Under load it gets super hot (high 80s).

Has anyone else thought about or have replaced the factory thermal pads?

If so, what did you replace with and how did it go/what were the results?",iamacerimmer,2021-04-06 12:38:38,6,22,0.75
897,"Questions in the title but i've been looking around the web a lot since the 3080 came out looking to see if any manufacturers would announce a ""dual fan"" type card for the 3080 like they have done with previous generation xx80 cards. The only place i've got confirmation of this not happening is Zotac which i reached out to asking if they would ever make a Twin Edge variant of the 3080.

A place that didn't give me a straight yes or no answer is ""Manli"" which made a mini 2080 a few years ago. I asked if they'd do something similar again and got a response of maybe we will, keep an eye out sorta thing.",xXNugget69,2021-04-06 09:39:42,1,44,0.56
898,"In afterburner I can't use ctrl+F command because is just for pascal gpus, how do I undervolt my gtx 670 now? do you know another way?",emanuelegay,2021-04-06 08:50:06,1,8,0.6
899,I just got the ASUS TUF OC 3080 and I want to put it under water. I’ve seen water blocks but I don’t want to do a custom loop. Is there a way to avoid a custom set up? I haven’t been able to find an aio for these cards.,iDabLikeAJew,2021-04-06 05:15:22,1,7,0.57
900,"&#x200B;

https://preview.redd.it/bsxeq0wh9hr61.jpg?width=2048&format=pjpg&auto=webp&s=2697ee350c294264b77167ff5863aeb8b64bc107",pizzaboy0908,2021-04-06 04:07:32,3,5,0.71
901,"Hi I have a 3090 FE that, like everyone else’s, runs quite hot even though I don’t crypto mine and don’t ever plan to. 

I know of opening up the card and replacing the thermal pads however I am a bit sheepish of doing such a procedure as it was a pain to get and was quite expensive and last thing I need is a dead card and out $1500. 

Is it worth it for someone like me to replace the pads or is it something I can live with? 

Lastly I saw in several videos replacing the backplate thermal pads are easier and would it be worth it to do that instead of the whole process or should I not bother? 

Sorry for the questions and appreciate any answers. Thank you!",SRGFernandez,2021-04-06 02:35:16,11,8,0.79
902,"EDIT: the build did not damage my PC, however I found it too challenging to resolve driver conflicts between my GTX 1660 super and the Tesla K80. Geforce drivers would not result in the Telsa K80 showing up in task manager or MATLAB's gpuDevice function. Tesla drivers resulted in the same, with poorer performance on the GTX card. For those looking to use a Tesla K80 in their PC too, make sure you have either a) integrated graphics in your CPU, b) discrete non-Nvidia GPU for display, or c) if Nvidia, a display card that is supported by the Tesla drivers (such as Quadro series cards). Additionally, make sure your BIOS supports above 4 decoding and resizeable BAR support, and that you have a way of actively cooling this card.



I'm looking to add a server-grade GPU (Tesla K80) to my desktop PC. I'm interested in using this second GPU for image segmentation and machine learning projects that I have lined up. It will likely perform on par or worse than my 1660S, but the 24GB VRAM is of particular use to me.

Current build: https://pcpartpicker.com/list/Zz2KLP

My main concern is incorrectly hooking up the power supply to the card, and inadvertently ""frying"" my GPU or the entire PC. I've purchased the following parts in hopes of being able to supply the necessary 300W drawn by the K80:

Tesla K80: https://www.amazon.ca/Dell-Tesla-K80-Accelerator-Refurbished/dp/B07GJ45V3D/ref=sr_1_1?dchild=1&keywords=tesla+k80&qid=1617665288&s=electronics&sr=1-1

8 pin CPU male to dual 8 pin PCIe female: https://www.amazon.ca/gp/product/B07M9X68DS/ref=ppx_yo_dt_b_asin_title_o04_s00?ie=UTF8&psc=1

ATX CPU 8 pin male to dual 8 pin PCIE male: https://www.amazon.com/gp/product/B07CZBZN5R/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&psc=1

850W PSU (already in build): https://www.amazon.com/CORSAIR-RM850x-Certified-Modular-Supply/dp/B015YEI8JG/ref=sr_1_3?dchild=1&keywords=corsair+rm850x&qid=1617665434&sr=8-3

I'm planning to connect the ""ATX CPU 8 pin male to dual 8 pin PCIE male"" to the ""8 pin CPU male to dual 8 pin PCIe female"", with the ATX CPU 8 pin male side connected to the PSU, and the dual 8 pin PCIE ends connected to the adapter which converts it to a CPU 8 pin male. Is this the correct way I should be supplying power to the GPU?

Furthermore, does it matter which of the ports on the modular ATX PSU I should use?

Overall, I have fairly low expectations for this card's performance. My greatest concern is damaging what I already have due to my lack of knowledge pertaining to power supply.

Other notes:

- I've verified that the total TDP of my proposed build does not exceed the PSU's capabilities (850 W)

- I'm planning to remove the GTX 1660S when installing the card, and downloading the appropriate drivers

- my BIOS supports above 4G decoding

- I've 3D printed a custom fan shroud that actively cools the card via two 60mm NF-A6x25 fans.",323465963,2021-04-06 00:09:00,0,19,0.5
903,"# Released:

1- Call Of Duty Cold War Black Ops

2- MineCraft RTX

3- Cyberpunk 2077

4- Shadow Of Tomb Raider (DLSS 1)

5- Battlefield V (DLSS 1)

6- Metro Exodus (DLSS 1)

7- Pumpkin Jack

8- The Fabled Woods

9- Wolfenstein Youngblood

10- Watch Dogs Legion

11- Control

12- Fortnite

13- MechWarrior V

14- Deliver Us The Moon

15- Bright Memory

16- Anthem (DLSS 1)

17- Monster Hunter Worlds (DLSS 1)

18- Crysis Remastered

19- Ghostrunner

20- Xuan-Yuan Sword VII

21- The Medium

22- Stay in the light

23- Nioh 2

24- Mount & Blade II: Bannerlord

25- Death Stranding

26- F1 2020 (DLSS 1)

27- Final Fantasy XV (DLSS 1)

28- Marvel's Avengers

29- Outriders

30- Enlisted

31- System Shock Remake

32- CRSED: F.O.A.D

33- War Thunder

34- Into The Radius

35- Edge Of Eternity

36- Mortal Shell

37- Call Of Duty Warzone

38- Call Of Duty Modern Warfare 2019

&#x200B;

# Under Beta Status:

Ready Or Not

Scavengers

Iron Conflict

Supraland

&#x200B;

# Announced:

Atomic Hearts

Boundary

F.I.S.T.

Five Nights At Freddy's Security Breach

Bright Memory Infinite",Hameeeedo,2021-04-05 23:24:45,47,118,0.65
905,"# Released:

1- Call of Duty Modern Warfare

2- Call Of Duty Cold War

3- Minecraft RTX

4- Quake 2 RTX

5- Cyberpunk 2077

6- Shadow of Tomb Raider

7- Battlefield V

8- Metro Exodus

9- Pumpkin Jack

10- The Fabled Woods

11- Wolfenstein Youngblood

12- Watch Dogs Legion

13- Control

14- Fortnite

15- MechWarrior V

16- Deliver Us The Moon

17- Bright Memory

18- World of Warcraft

19- Amid Evil

20- Crysis Remastered

21- Ghostrunner

22- Xuan-Yuan Sword VII

23- The Medium

24- Observer System Redux

25- Dirt 5

26- Godfall

27- The Riftbreaker

28- Stay in the light

29- Ring Of Elysium

30- Mortal Shell

31- Resident Evil Village

&#x200B;

# Chinese titles:

Justice

JX3

Moonlight Blade

&#x200B;

# Under Beta Status:

Enlisted

Ready or Not

The Orville

&#x200B;

# Pending games with working DXR demos:

Atomic Hearts

Boundary

&#x200B;

# Announced:

Atomic Hearts

Boundary

Hitman 3

Flight Simulator 2020

Dying Light 2

Far Cry 6

The Witcher 3

F.I.S.T.

Halo Infinite

Doom Eternal

Five Nights At Freddy's Security Breach

Grimmstar

In The Black

Sword and Fairy 7

Vampire Masquerade Bloodlines 2

Synced Off Planet

Convallaria

Project X

Bright Memory Infinite

STALKER 2",Hameeeedo,2021-04-05 17:54:23,185,241,0.85
906,"I have had my Dell G7 GTX 1060 Max Q Laptop for about 3 years now and its been good to me. I'm looking to buy a new Laptop so I can upgrade and maybe give my current 1060 laptop to my brother.

I just want to know if it is worth upgrading to a new Alienware M17 R4 GTX 3070 Laptop?

I would be paying a hefty penny for the laptop, easily double what I payed for my current laptop, but I'm willing to sink some money into a machine that would last me about 5 years. I appreciate any constructive criticism or advice, thanks! :)",MoparGuy96,2021-04-05 16:39:26,1,18,0.55
907,"I updated to the latest driver for ReBAR support on my 3080 FE. Tried running Hashcat today and ran into:

    clCreateContext(): CL_OUT_OF_HOST_MEMORY

Rolling back to 461.92 fixed the issue. Strange as ReBAR support still says ""Yes"" in System Information.

TL;DR, if you use Hashcat don't update to latest driver.",JesusWasANarcissist,2021-04-05 16:16:09,21,20,0.69
909,What are some of you using for a vertical GPU riser with the new Nvidia RTX gpu’s? I have a Lian Li Lancool II that I am trying to get a vertical riser for.,Mad_Moneyman,2021-04-05 11:57:59,1,8,0.57
910,"So odd question never thought I'd have to ask ...but unprecended times...

I bought and paid for a 3080 over....7 months ago? So long...:(
From the leading supplier in my country and every week I go down 5 to 10 places. 

At my current rate I'll get my 3080 in 2022 winter ...maybe :-O

So that's f%cking insane imo and we all know why this is and how that isn't improving any time soon despite constant pr spin and fanboy wishful thinking.  The 3080 arent coming anytime soon beyond a miracle happening.  I know this as I believed the lies of the retailer that id have my card by Xmas 2020 and when I posted on this , every forum told me they were just around the corner haha that was 4 months ago.

Even if they sort out the chips and covid we will still a very serious scalper issue which no authority seems to be taking on. If they continue to buy up all cards via at this point international criminal enterprises (which might not even be criminal) then nothing will likely change for a while.  

Also in my area the actual delivery people are still opening our packages and looking for and stealing ps5 and 3080.  And that's a new issue we've never seen before and specific to these items and the pandemic and influx of 'anyone can be a delivery person' now etc. And an unwillingness by companies to pursue theft beyond firing.

####So beyond that hot mess....
* by the time I get my 3080 in 2022 ....Will there be a superior card? 

As money isnt the object ,as i worked a 2nd job to buy this thing (ive never seen lol) but i needed for 3d design work months ago. Though i refuse to pay (encourage) scalpers and will only pay the retail price.

* Or at that point... as my mid range gaming pc is already 2 years old in 2021 , should I buy a new 3080 desktop build ?

***Any suggestions?***

*Pls and thanks.*",ilivedownyourroad,2021-04-05 11:19:33,10,71,0.64
911,Title says it all. What is better for value for 1080P gaming?,ItDoesntSeemToBeWrkn,2021-04-05 10:56:00,2,22,0.58
912,"When in the world is the Bios update for the Uprising models coming, others have had issues with the REVEL model bios and have said that the palit bios works for them. Has anyone gotten the palit bios to work for the uprising models like the 3080?",No-Palpitation-2662,2021-04-04 23:29:39,2,3,0.6
914,"Has anyone done it? 

Is it as effective as doing it for open air cards?

What size pads do I need to order?

Thanks!",cantgetthistowork,2021-04-05 01:40:09,5,10,0.67
915,Just updated my Z390 Phantom Gaming ITX with latest beta bios 4.4H and ReBar is on. This is on 8th Gen i7-8086K and RTX 3080 FE.,Nestledrink,2021-04-04 23:08:03,23,26,0.9
916,"I have a RTX 2080 with Ryzen 5 2600x, 16GB RAM. I also have a really bad monitor which has 59hz. I know that the monitor would be dragging my performance down however I'm curious to know if it's just my monitor or could it also be my CPU? What do you think is the best CPU for RTX 2080? I'm willing to upgrade my setup which includes getting a new CPU and a Monitor so suggestions for monitors (144hz or 240hz) would also be appreciated! Thanks!",Shipwrekz,2021-04-04 23:05:19,0,19,0.45
917,"I have a mITX build inside an NZXT H1. This case is a very tight build with less than ideal thermals, but I've made some mods to improve that. Also, prior to my 3090 I was running a 1080, which made barely any noise no matter what I was running.

When I put the new MSI Ventus 3X 3090 in this computer, however, the fans would kick up like a jet engine even during relatively undemanding games (e.g. Phasmophobia). HWiNFO64 gave me core temps of 95C and memory temps at a consistent 110C at almost all times. No wonder the fans were always going full speed!

Given all the stories about upgrading the thermal pads, I decided to do the same with my GPU. It certainly couldn't hurt.

I used Thermalright pads in 2mm and 3mm sizes. When I disassembled the card, here's what I found...

On the top of the PCB, only ONE row of memory chips had any thermal pads at all. On the back, the thermal pads were too thin to make contact in most cases, and some of the pads were mis-applied and barely touched the heat pipe.

To remedy this, I used the 2mm pads on the top, covering all the memory chips and replacing the one existing pad. On the back, I used the 3mm pads with lots of extra coverage to ensure a good connection between the chips and the heat pipes. I also expanded the coverage where the heat pipe is supposed to connect to the radiator, for better transfer.

The core was also SMOTHERED with compound. It took forever to clean off. I then used Thermal Grizzly Kryonaut on the core (X pattern plus 4 dots).

**RESULTS (Max Temps):**

BEFORE    
Core: 95C    
Memory Junc: 110C    
Hot Spot: 110C

AFTER    
Core: 75C (-20C)    
Memory Junc: 82C (-28C)    
Hot Spot: 86C (-24C)

Holy cow. I was expecting an improvement, but that is HUGE. And best of all, no matter what torture test I run, I barely hear the fans at all; this thing barely breaks a sweat now. And all it took was $30 worth of thermal pads and a dab of quality thermal compound!?

What are these manufacturers \[not\] doing that such simple maintenance can make such a massive difference? Good grief.",MattVanAndel,2021-04-04 21:20:40,59,69,0.89
919,Would a 550 watt 80+ bronze PSU or a 600 watt 80+ standard PSU be enough for a 3060 ti and a Ryzen 5 3600 with 16gb 3200mhz ddr4?,SenpaiBunss,2021-04-04 21:14:00,2,8,0.6
920,"In April 2020  I decided to get an upgrade to RXT2060 and a new 500W power supply.  Things were fine for about 6 months then it started having delays after organizing files and installing a Mod for Halo. Took it in again and they said it was all to do with bad drivers.  They did a complete reinstall of windows 10 and said it all had to do with driver issues possibly caused by a virus from downloaded software.??   Then the rebooting started, during anything it would randomly reboot.  Took it back to original place after stress tests and a different graphic card and it was deemed to be the new RXT2060.  Sent back RXT2060 in Jan and expected to wait quite a while but got a replacement quickly.  It still did the reboots almost immediately after start up and every couple of minutes.  Took it for Third opinion :  computer has been completely diagnosed as good, been through stress tests (Benchmark), tested using a higher power supply,  and the replacement RXT2060 with the up-to-date drivers and a 2nd windows 10 reinstall.  It is still rebooting.  Final opinion from 3rd place is that it is the graphics card that is the problem.   I read on a microsoft forum and somebody with a similar problem said it was all to do with bad drivers.  I'm on the verge of losing my mind.  Any thoughts?",Sandartist0817,2021-04-04 20:19:07,1,8,0.56
922,How long were the 20 series white strix cards produced for? Wondering if the 30 series ones are already done being produced.,stang01234556,2021-04-04 20:59:53,0,4,0.5
923,"Hey guys,

I completed my build and installed this 650w psu from Corsair:

[https://www.bestbuy.com/site/corsair-cx-m-series-650w-atx12v-2-4-eps12v-2-92-80-plus-bronze-modular-power-supply-matte-black/5845214.p?skuId=5845214](https://www.bestbuy.com/site/corsair-cx-m-series-650w-atx12v-2-4-eps12v-2-92-80-plus-bronze-modular-power-supply-matte-black/5845214.p?skuId=5845214)

Do you guys think I can aim for a 3080 or should I settle for a 3070 with this psu? Just wondering if it has enough juice and can reliably power these gpus. Its the CX 650M power supply. Rest of the parts are as follows:

MSI Tomahawk Max

16 gb Trident Z rgb 3600 CL16 ram

1 Tb WD SN750 SSD

Ryzen 3700X processor

Current gpu is a rx 580 and it works fine with the psu.

&#x200B;

Thank you.",Snoo_11263,2021-04-04 20:58:25,0,34,0.4
925,"Hello! I am the creator of [VkFFT](https://github.com/dtolm/VkFFT) \- Vulkan/CUDA/HIP Fast Fourier Transform library. I would like to invite you to the [GTC 2021](https://gtc21.event.nvidia.com/) panel of VkFFT, which will happen on April 13th at 4 PM CEST in the Higher Education and Research category. It will be focused on implemented optimizations and how to create cross-platform code that can scale from Raspberry Pi 4 to HPC GPUs like Nvidia A100. The session will also compare Vulkan, CUDA and HIP compute platforms on Nvidia A100 and AMD MI100 GPUs.

In this post, I would like to give you a sneak peek at a part of the talk regarding VkFFT/cuFFT/rocFFT performance comparison in single precision in 1D batched FFT test of all systems from 2 to 4096, representable as an arbitrary multiplication of 2s, 3s, 5s, 7s, 11s and 13s. The bandwidth is calculated as total memory transferred (2x system size) divided by the time taken, so the higher - the better.

[Nvidia A100 results](https://preview.redd.it/4niagf91c7r61.png?width=10000&format=png&auto=webp&s=8c4ade4b884e1a543f3fdcbc616afbd39a0aa93b)

[AMD MI100 results](https://preview.redd.it/7zqtmgl3c7r61.png?width=10000&format=png&auto=webp&s=09f7b13cdba122832b6cc039dc3f14eef4e0eacb)

The talk will also cover double-precision, multidimensional tests and their analysis, so I would really appreciate it if you can check it out!",xdtolm,2021-04-04 19:11:10,30,5,0.94
927,I have a gigabyte gaming oc rtx 3080. Tried to oc with offset. Above 1950 core boost games start to freeze or crash. Power limit etc is all way unlocked. Can undervolting get me above 2 ghz? My highest temp was 68c. Or that’s just the limit of my gpu?,dotaut,2021-04-04 17:21:05,3,8,0.71
928,"I really like tensor cores. DLSS and RTX voice is by far one of the coolest thing Nvidia has created. But my question is, why stop there?

For example, in CP2077, the NPC could dynamically adjust their routine based on the weather or if the player shoots near it, it will run a different direction each time.

Another example would be Ultimate Epic Battle Simulater 2 (an upcoming game) where tensor cores could be used for the troops.

I mean the possibilities are endless. AI in games would be more realistic and as a result more immersive assuming the developers used deep learning so the game is tailored to the player's experience. So my question is, Is it possible for game developers to use tensor cores to simulate game NPC AI? If yes, why haven't they?",trevorleong,2021-04-04 17:11:19,11,26,0.74
931,I am debating which graphic card should I aim for in the laptop I am planning to buy. I cannot find any direct comparison between these two. Recently I found a really good offer for 2080 super max-q laptop for £1500 (Lenovo 7i) and  I am wondering if it is worth it or should I aim for 2070 (base) or 3060 (base/max-q) in terms of performance. If anyone uses any of  these I am more than happy to read about your experiences with them.,YuumiPlayer69,2021-04-04 16:03:46,0,5,0.43
934,"Hi! I'm about to purchase a laptop for which I've shortlisted two options. I need your help to choose the right one.

Usage:-

1. Microsoft Office

2. A lot of web surfing on Chrome

3. Multitasking

4. Low to medium editing on Photoshop and Premiere Pro.

Accordingly, I've chosen a few options:-

Vostro 15 3500 (11th generation i5 G processor, 8 GB RAM with Iris Xe graphics)

Vostro 15 3500 (11th generation i5 G processor, 8 GB RAM and Nvidia GeForce MX330 with 2GB GDDR5 graphics memory)

Lenovo S540 (10th generation i5 U processor, 8 GB RAM and Nvidia GeForce MX250 with 2GB GDDR5 graphics memory)

Please help me out! Thanks in advance :)",chandravedant,2021-04-04 08:58:23,0,3,0.21
935,"Last time I tried Broadcast it was terrible in comparison to RTX Voice, wish RTX Voice worked on the 30 series cards.",Faawks,2021-04-04 07:31:07,5,26,0.86
936,"Long story short, I'm a PhD student and have been using a RTX 2060 to train my networks. Lately, I needed a bit more grunt so have been looking at upgrading to a 30xx. The type of prediction tasks I'm working on aren't *that* memory intensive (or at least the current paper I'm working on isn't). Batch size of 5k almost takes up all of my 2060's 6gb memory. So, between the 3060 and 3060 Ti, one has more memory but the other more CUDA cores. I also suspect that even though 3060 has 12gb, you can theoretically fit a larger model but it will take a long time to train. Which one would you choose?

&#x200B;

[Spec](https://preview.redd.it/wvny8ryap3r61.png?width=1442&format=png&auto=webp&s=6874e91e7578c5338136b44e61063d8de2407675)",swmfg,2021-04-04 06:29:51,5,22,0.73
937,My memory junction temperature reaches 105C under load and that's quite hot. Could I cause permanent damage to the card letting it operate at that temperature?,Dashurius,2021-04-04 06:07:31,0,20,0.5
938,"d I got a pc not to long ago and led lights and I decided to use blue as my setup color but its really bugging me that my graphics card is not blue. If there's a software or something that I can use to change the colors of it, it would be nice if anyone could link me to it or something that would be great.",Odd-Mistake-1124,2021-04-04 03:59:15,6,10,0.75
941,Anyone have any idea the thermal pad size for the die and also back side ? Can’t find any info on the web at all.. thanks,johnny87auxs,2021-04-04 02:29:05,0,10,0.5
943,"Hi, everyone!

I have recently learned that resizable BAR does not automatically work with any and all games that you launch. Nvidia apparently has to whitelist the game on a driver level for it to be enabled as it could potentially decrease performance in certain titles.

I was wondering if any of you know if it is possible to manually add a game to this list through the control panel? I would like to test the performance on some of the titles that are not officially whitelisted.

Thank you in advance for your help!",vibrahimov,2021-04-04 00:21:04,32,21,0.88
944,"Hey! I want to start getting in to mining, but I have a question about gpus. I currently have an RTX3080 in my build that I mainly use for gaming, but I also have another GTX1070ti just laying around. Can I put the 1070ti in to my computer for more efficient mining? I want to use my pc to mine in downtime, so I'd only use the 3080 for actual gaming but both gpu's for mining. Is this even possible? If so, is it as simple as installing the gpu in to the computer or..?",Secretsinblack,2021-04-03 23:44:49,0,14,0.39
948,"Looking at used pcs and mostly wondering if a 1650 is good. I'm planning on running games at 1080p, hoping for it to be able to get 120 fps on low settings in games like apex and around 60fps in other games in high settings. I3 9100f cpu and 8gb of ram",THe_0nce-ler,2021-04-03 22:17:44,4,11,0.61
949,"Long story short i have cpu bottleneck, my cpu doesnt let the gpu do the maximum work and it limits my frames on every game. Now the question is, does nvidia low latency have to do anything with this? Because im looking to increase the gpu usage on every game to reach that max fps, but sometimes its ridiculous and complete bullshit on cpu intensive games, like csgo(strechted, all low settings), i literally get 80fps, but in call of duty warzone with medium settings i get 70-100... Any tips?",tatamatinjo,2021-04-03 22:13:31,6,13,0.69
951,"Does anyone have the stock BIOS for the RTX 3070 Suprim X? i bricked mine and the Stock bios is currupted.

Cheers guys",TayRoan,2021-04-03 20:11:13,0,6,0.44
952,I am struggling to decide which one to keep for my gaming pc and which to sell to a friend. Probably difficult for me to decide because I know they both have problems with hot memory. Anyone got any opinions?,huddyman12,2021-04-03 19:47:50,0,5,0.38
953,"Intel is possibly the only chip maker that's fairly or under valued atm, amd is making 800m free cash flow a year and worth 90b, nvidia makes 4.3b and valued at 348b (insane) and intel has 15b free cash flow and valued at 218b, regardless of what your personal favourite brand/company is for making chips, intel is the clear winner financially and price wise. It also pays a dividend which means little but it's a bonus for what is a growing company numbers wise. I would also add I love dell and is a personal favourite stock to buy Atm but as they are not a chip maker doesn't really fit in here",stormpimple,2021-05-28 21:21:30,16,124,0.58
954,"Heyoooooooooooo. 

Whatever I'm not here to impress you idiots with a catchy opening:

Lets look at NVDA. 

Looking at the stability (reddish line)

https://preview.redd.it/u10pl6qodd171.jpg?width=1154&format=pjpg&auto=webp&s=c6d6162ccd8ef4135b215f79f481d6327feb4bba

We see that for the past few months whenever the price has increased, it stretches the red line until it snaps back down. Is this occuring again with this most recent price increase? You tell me (yes). 

This is further worrisome when you look at the expected moves:

https://preview.redd.it/zrbvo6a0ed171.jpg?width=1122&format=pjpg&auto=webp&s=0e50c0dfe36958ff7447f95dc071b13fd21fb0c3

Although earnings are coming up and they can be more drastic than normal, typically MM's and OD's don't enjoy greater-than-expected moves. 

The shorts are doing a fun dance:

https://preview.redd.it/t5b3qyp5ed171.jpg?width=1122&format=pjpg&auto=webp&s=e6fe8bc1ed2dc94b1cd3b184d6c954b543ba3688

The most recent price increases have been met with greater increases in shorting. This can be from a variety of reasons but globally seen as a bit of a bearish sign.

The options layout:

https://preview.redd.it/4jvpzchbed171.jpg?width=1116&format=pjpg&auto=webp&s=5732c90ccbf63e01f50240c13cb35a7f92820d40

The concerning aspect here is the largest majority of calls are at $600 (ITM) at \~30,000 of them. 

This produces:

https://preview.redd.it/apxxpm6ied171.jpg?width=1095&format=pjpg&auto=webp&s=34d04c8afd050167a62de53d532b49e3a1d3c009

Since those options are so ITM and volatility tends to move around earnings reports, let's look at how the options will effect the price if volatility increases:

&#x200B;

https://preview.redd.it/rmnd65mped171.jpg?width=346&format=pjpg&auto=webp&s=de87aabdccf8254bc8d3bdf0f482dafefdf71d99

So there are approximately 10,000,000 more shares that have to be sold with increases in volatility than purchased. So if tomorrow, volatility rises - I'd say be cautious. But if it is good news and liquidity becomes abundant, then everything favors an upside. 

There will be some mighty resistance, however - namely those 30k calls at $600. Overall, I'd be slightly gay bearish for the next week or so until either those calls are moved further upland or the price reverts back down.",HiddenGooru,2021-05-26 01:53:20,24,24,0.83
955,"**Historical Post Earnings Moves MEGA Compilation (Week 6) - $NVDA, $SNOW, $CRM, $COST, $BBY, $ZS, $DKS, $TD, $BMO and More**

&nbsp;

What's poppin' bull gang, Flux here with Week 6 of the Historical Post Earnings Moves MEGA Compilation. I hope you all made some good money following the spreadsheet last week, cause it's time to do it all again! Earnings season is just about over, so there is a good chance that this is going to be the final spreadsheet until Q2 rolls around. Thank you all for joining me for the ride!

&nbsp;

All that being said, I fucking love earnings season. It’s an absolute battleground out there. Insane volatility, breaking announcements, and huge moves being made every single day for weeks at a time. What’s not to love? Anyone has a chance to pick the correct tickers, roll the dice, and amass a small fortune. That being said, the unpredictable nature of earnings season often makes or breaks traders - many find that they’re one bad trade away from a complete blowout, so you always need to think about each trade critically. No shame in sitting it out altogether.

&nbsp;


---

#The Spreadsheet

To aid us in planning our trades this week, [**I've compiled a spreadsheet consisting of all of the Historical Post Earnings Moves of EVERY stock reporting earnings this week**](https://docs.google.com/spreadsheets/d/1gMemdx2iJkzSfoUg7o4YIUnnc4ftZfft-ZMAM315Xtw/edit?usp=sharing). Using this spreadsheet, we can determine which options to buy or sell to minimize risk and maximize probability for ANY given ticker. Obviously, past performance isn’t indicative of future success, but we can still use these numbers to gain a general idea of the expected earnings move of a given stock. Gone are the days of getting randomly blown out due to lack of information! If you’re struggling to find a given stock, click on the ticker symbol on the index page, it should hyperlink you straight to the table! If the above link isn’t working for you, refer to the link below!

&nbsp;

[Spreadsheet HERE](https://docs.google.com/spreadsheets/d/1gMemdx2iJkzSfoUg7o4YIUnnc4ftZfft-ZMAM315Xtw/edit?usp=sharing)

&nbsp;

Please note that scraping and compiling this data took *hours*. If the sheet has helped you out in any way, please drop an upvote or a comment and peep my socials! It would mean alot to me. Most websites also require you to pay for this data, which I think is a load of shit.

&nbsp;

---

#Interesting Observations and Sample Plays

Below I’ve compiled some interesting observations which can further aid us in making trades this week, alongside some sample plays for those who are new to playing earnings and need some guidance. If I missed anything, feel free to bring it to my attention!

&nbsp;

- **All major Canadian Banks report this week**. Some names in the lineup include BMO, RY, TD, and CM. BMO reports first out of the four, so we can look at their earnings results and corresponding price movement to predict the movements of the following three banks. Similar to the American banks in Week 1, I'm expecting huge beats across the board, alongside some comfortable upwards movement.

&nbsp;

- **Those with OTC / TSE access should look to make a collateral play on the banks.** Again, similar to Week 1, you could've played XLF alongside the American banks and made a fat bag. Those looking to run that play back should look into **$ZEB** - The IV is low as hell, and it only holds Canadian banks. Options on it are dirt cheap, with an option less than 1% OTM going for a grand total of $0.10. Every percent this thing moves will give you a 3-bagger. Unfortunately, the ticker isn't liquid whatsoever, and the bid ask spread isn't too appealing. You're gonna be buying at the ask, and selling at the bid, so even if we get a nice move, we're still gonna get trashed by slippage. ITM options may be the way to play this one - I couldn't find a better ETF alternative, so this one is the best we got. This play is definitely one of the riskier ones.

&nbsp;

- **Piggybacking off the last point, liquidity is suspect this week**. Majority of the companies reporting have godawful options chains. If you think you see an awesome play, make sure you check the volume and open interests in the option chain before committing to it. You'll find that lots of the tickers this week lack any real liquidity on the options chain, so there's gonna be a fucking crater in the bid-ask spread. You're guaranteed to be buying at the ask and selling at the bid, and this huge spread adds additional risk that will balloon your losses and shrink your winners. 

&nbsp;

- **ZScaler options are inefficiently priced.** Historically, ZScaler moves roughly 15% post earnings, but the options chain is only pricing in a 5% move this time round. This gives us gambler a huge edge, since we won't get IV crushed as hard, and we can buy our options for cheap. There are lots of strategies you can run this week, but I'm personally going to opt for a long strangle or long iron condor if I can get good fills.

&nbsp;

Obviously, since I gave data on over 40 companies, there's plenty that I’ve missed. Dive in, have a look around, and have some fun with it! Use the spreadsheet to aid you in picking the safest strikes, and get the best risk-reward possible. Feel free to share your findings too, I’d love to see what you guys come up with.

&nbsp;

---

# Conclusion

We’ve got an insane lineup of companies reporting earnings this week, meaning there’s a huge variety of plays to be made for traders of all skills and styles! Use the [spreadsheet](https://docs.google.com/spreadsheets/d/1gMemdx2iJkzSfoUg7o4YIUnnc4ftZfft-ZMAM315Xtw/edit?usp=sharing) to determine which stocks offer the best risk to reward ratio, and play accordingly! If enough people found these useful, I'll continue making them throughout the earnings season! If the sheet has helped you out in any way, please consider dropping an upvote or a comment, it would mean a lot to me! **Happy Trading Everybody! :)**",FluxRevived,2021-05-24 19:42:37,53,4,0.88
956,"In September, NVidia released the RTX 3000 series. They are the first cards in a long time to have almost double the performance/price of its predecessor. Demand has been extreme, they sell out immediately when they're available and cost 3-4x retail in used markets. Even though their cards are the strongest ray tracing cards in the market, their stock price hasn't moved since they released.

In the short term, there is a worldwide silicon shortage. NVidia needs to at least fulfill enough demand to meet earnings expectations. Since AMD, which is outperformed in ray tracing, killed earnings this quarter, NVidia will too.

In the long term, it will be open season for huge revenues from RTX 3000 sales as long as a superior line of GPUs doesn't release before the silicon shortage is dealt with.

If NVDA fulfills this huge GPU demand in the future, then their current price is a bargain.",beamsplosion,2021-05-22 02:43:19,34,58,0.68
957,"NVIDIA (NVDA) said Friday its board has approved a four-for-one split of its common stock in the form of a stock dividend.

The computer systems design services company said the move would make stock ownership more accessible to investors and employees. The dividend is conditioned on shareholder approval at the company's annual meeting in June to increase the number of authorized shares to 4 billion, the company said.

If approved, each NVIDIA (NVDA) shareholder of record at the close of business on June 21 will receive a dividend of three additional shares for every share held, which will be distributed after the close of trading on July 19.",HolderofFour,2021-05-21 20:53:29,1238,297,0.98
960,"As the cloud & big data continues to grow, as well as social media & 4k/8k video, data storage is becoming more important than ever.

Large social media sites take in a tremendous amount of data each day. This storage must not only be stored, but stored with redundancy as well as backups(usually to tape). Major sites such as Facebook and YouTube keep content that is over a decade old. Over time, the drives holding this content will fail and need to be replaced, leading to growing recurring demand as the size of the platform grows.

The need for storage has been growing for decades, but innovation in storage density and intense competition has limited profitability in the market in the past. That being said, there is reason to believe that the growth in storage density may stop keeping up with the growth in storage needs.

There is also reason to believe that transient growth in storage demand may drive higher Q2 earnings. A new crypto, Chia, has gobbled up about 3.5 Exabytes worth of storage in the past 3 weeks, growing at a rate of about 0.2 EiB per day(and rising). https://www.chiaexplorer.com/charts/netspace

For reference, about 288 Exabytes worth of hard drives were shipped in Q1 2021 https://www.tomshardware.com/news/hdd-shipments-in-q1-2021

Chia network size can be considered a lagging indicator for unexpected drive shipments. Generally, it can take a few weeks between when a drive is purchased and when it's actually accounted for on the network, as it takes time for it to be shipped, set up, and plotted. Chia wasn't even listed on exchanges until a week ago, so most of the growth seen is prior to Chia even having a price. At current prices, mining is incredibly profitable, with a $500 14 TB drive estimated to produce about $30 per day, and using very little power. So even if the network grows 10x to 40 Exabytes, it's still producing $3/day at current prices.

I have seen many anecdotes of drive shortages over the past couple weeks. Reviewing sites like Amazon, I have also seen high capacity drives go out of stock or require lead times of a few weeks.

This may be a bit reminiscent of GPU shortages among Nvidia and AMD as miners seek to buy up anything they can.

If we project continued growth at 0.25 Exabytes a day in unexpected demand from proof of storage over the next 48 days, plus the 3.5 Exabytes added since April 20(leaving out first 3 weeks in quarter as they were likely logged last quarter), that's about 15 Exabytes to be added in Q2 that are not part of normal usage, or about an extra 5% of Q1 demand.

What's perhaps most interesting is the impact this could have on margins. Unlike the GPUs used to mine which are consumer devices, the devices used for mining Chia includes enterprise grade hardware. Prices in the drive market are more flexible at the manufacturer level, and currently have much lower margins. If proof of storage currencies cause a drive shortage, it could have a significant impact on margins.

Seagate is also in a position to profit from this, but I'm a bit more worried about them as hard drive shipments have been on a long term decline and they aren't diversified into SSDs/flash like Western Digital is.",skilliard7,2021-05-12 15:42:34,5,19,0.57
961,"Hey y'all,

I have alot of cash lying around and am looking to buy the recent dip in tech stocks. Obviously timing the market is impossible but its pulled back enough for me here; I'm ready to start DCAing in. Here's what I have on my radar. Please lmk what you think/ WHAT YOUD BUY IF YOU COULD ONLY BUY 3 HIGH GROWTH TECH STOCKS RN.

**Boomer tech- 20% a year**

Nvda 

Faang 

**Core positions aggressive**

Sq

Meli

Twlo 

Etsy 

Pins

Crwd

mtch

Pltr

dkng

tdoc

Z/open

Roku/mgni 

**More speculative, longer time line**

lmnd

U

Fubo",Glum-Bookkeeper-4104,2021-05-12 05:09:54,18,85,0.67
962,"TLDR:    I did a bunch of math based on some reasonably good ideas to  determine  a  selection of stocks worth investing/reviewing. Lists of  stocks found  in  2020 and 2021 Experiment sections.

# Observations/Assumptions

* [Index funds have been shown to be the most successful stock investing instrument for most people](https://freakonomics.com/podcast/stupidest-money/)
* [Index    fund returns, such as the S&P 500, are now predominately   determined  by a handful of extremely large, mostly tech stocks.](https://www.investopedia.com/top-10-s-and-p-500-stocks-by-index-weight-4843111)
* [Most funds do not beat the index over a long period](https://finance.yahoo.com/news/dont-pay-investment-adviser-beat-144400899.html).
* The cost of stock trades at most firms is now $0.00 and some allow for fractional shares.
   * \*Edited: I should mention that when you make the trade you are paying a ""hidden"" fee of the spread between what you pay and what the stock was actually worth when you bought it as the Market Maker takes the split. Since you are either paying the spread, or management fees, you are going to be paying, you just don't have commissions on top anymore for the most part.
* During times of volatility, companies that had poor financials will likely find it challenging to survive.
* [Zombie companies](https://finance.yahoo.com/news/zombie-companies-hiding-uncomfortable-truth-183246812.html) are able to survive for longer periods during times of extremely cheap debt.
* Index funds have these 3 issues that are hard to get around:
   * You are unable to effectively [Tax-Loss Harvest](https://www.investopedia.com/articles/taxes/08/tax-loss-harvesting.asp)even though many of the holdings that make up the index would have  had   losses, thereby reducing the return compared to directly investing  in   that same set of stocks in the same proportions.
   * You have no control over the holdings within the fund and may be supporting things you don’t want to support.
   * Due    to the way the index works, any large stock that becomes part of the    index is potentially a huge drag on the index. This happened when  Tesla   was going to be added on 12/21/2020, which was announced on  11/16/2020,   forcing funds to buy the stock at the same time driving up  the price,   which had already been driven up by people buying the  stock knowing it   was then going to get added to the index forcing more  people to buy the   stock. If you think it sounds kind of circular,  that’s because it is.
* For most people it is impossible to time the market
* Stock prices have all available information at the time priced into them.
* The markets are relatively efficient over the long-term.
* Companies    with strong financials, a competitive advantage, good management, a    sustainable business model, etc. tend to do better than companies    missing one or more of those attributes over the long-term.
* Tech  seems to be heavily weighted in most indexes. I don't see this as    necessarily a problem. In my mind the digital landscape is infinite    compared to the physical world's finite space. With more tech being    found in every day devices, the advancement of [Industry 4.0](https://www.ibm.com/topics/industry-4-0), and younger generations more tech heavy than older generations will continue that trend in my opinion.

# Hypothesis

Using industry bench marking against the [best of the best of the best](https://www.youtube.com/watch?v=_huL5ynaI8Y)companies in each industry in equal measure should provide a well    diversified portfolio that over the long term should be able to beat the    S&P 500.

Industry Classification

* For Experiment 2020 the Sector was used to determine where companies should be compared.
   * This is made up of 11 sectors such as Information Technology, Communication Services, Utilities, etc.
   * This    seemed to be too restrictive and compared companies against each  other   that aren’t really accurate comparisons. See the example on ROE  below.
* So, for Experiment 2021 I used the Microsoft Excel Stock function to pull industries for all the stocks.
   * This looks like it pulls data mostly from Industry and Sub-industry.
   * This was successful on 98% of the stocks and for the final 2% I manually classified based on the taxonomy in the [Global Industry Classification Standard](https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard).
   * I    ended up needing to collapse the structure a little further.   Originally  there were 55 classes with many of the classes having less   than 10  parts.  I was able to collapse this to 44 classes. This will   likely be  tweaked a little further next year as I had mathematical   issues dealing  with averages/medians that were negative. There were   also just too many  categories with similar enough results that they   could be combined.

# Experiment 2020

750    stocks were analyzed against their peers in their industry. Stocks   were  given a score based on their relative percentage compared to the    industry index. For example, each companies’ average ROE of the last 4    years was compared to this index value with the following type of    breakdown:

* ROE < Index ROE = Poor = 1
* ROE > Index ROE = Good = 2
* ROE > 150% of Index ROE = Great = 3

For    example, the ROE communication services industry index value used was    10.10%. If a communication services company had a ROE average of 9%,    they would receive a poor rating. If they had a ROE of 10.5% they  would   receive a good rating. If they had a ROE of 25% they would  receive a   great rating.

This was done for all of the metrics below:

* ROE
* Revenue Growth %
* EBITDA %
* FCF %

The    relative scores used for each of the metrics was tweaked until there    was a good distribution of results. e.g., if the 150% revenue growth    only found 5 companies with a Great rating, that may need to be    decreased to 125% for a better distribution.

Any stock that received a poor in any of the 4 metrics was eliminated.

Example on ROE [https://imgur.com/a/kujNkWE](https://imgur.com/a/kujNkWE)

That left 53 stocks. EBITDA was then analyzed to see if it was declining, and if so, it too was eliminated.

This    left 45 stocks. These 45 were reviewed more thoroughly. What did the    company do? What were their competitive advantages? Are they currently    in any lawsuits? Does their debt look out of control? Do I see them    being a long-term sustainable choice? Is their IP about to expire?    Essentially boiling down to: Is there any reason that I want to exclude    them?

That left 26 across 7 sectors. [https://imgur.com/a/NsBdPtb](https://imgur.com/a/NsBdPtb)

These    26 stocks were bought in equal amounts in July 2020, August 2020, and    September 2020. To easily perform time weighted analysis of these   stocks  and determine if there was an opportunity cost, 10% of the total    purchase each period was also allocated to VFIAX.

The    chart below shows the total return of each stock including reinvested    dividends. MATH INDEX, second to the bottom, is the average of  returns.    [https://imgur.com/a/al60PZN](https://imgur.com/a/al60PZN)

2020 LIST OF STOCKS:

* ABMD
* ADBE
* ANET
* BWXT
* CRL
* DG
* ENR
* ETSY
* EXEL
* ISRG
* KLAC
* LKQ
* LRCX
* MNST
* MPWR
* MTCH
* OLED
* PAYC
* PHM
* PRAH
* TER
* TTD
* UI
* VEEV
* VMW
* VRTX

You can see VFIAX returned 28.20% vs the MATH INDEX of 36.56% over the same period, 30% higher returns.

For    those wondering how the exclusions did, they were only tracked  against   the first July purchase, but that comparison to date,  including   dividends for July purchase only, would be:

* MATH INDEX return of 39.24%
* Exclusions return of 33.75%
* VFIAX return of 30.05%

Overall after \~10 months we have 2 excellent results.

1. The full set of initial stocks had a greater return than the S&P 500
2. The ones that passed the more extensive due diligence returned an additional 5.5%

This is obviously a short period. Can we do it again this year? Should we go bigger? Yes.

# Experiment 2021

2,850    tickers of the largest US stocks were identified as the initial list.    The stocks had their last 5 years averaged for each of nine metrics:

* Revenue Growth % - shows growth rate of the company
* Profit Margin – shows how effective the business is at making money
* Operating Margin – shows how much money the company earns on its revenue
* FCF Margin – shows how efficient a company is with their cash
* EBITDA Margin – shows a companies’ operating profitability
* ROE – shows how well management balances profits, leverage, and assets to make money
* ROA – shows how effectively a company utilizes its assets to generate profits
* ROIC – shows how effective the company is at using its money to generate returns
* Debt/Equity Ratio – shows the financial stability of a company

More    metrics were used due to the increased data set. These stocks were   then  grouped by industry, and the average of the averages is taken to    determine the industry average for the last 5 years; I switched to    median based on a few outliers really throwing the average for some of    the metrics. If that was confusing, here is an example:

* 3    stocks that make up an industry averaged -10%, 15%, and 20% ROE over    the last 5 years. The median over the last 5 years for that industry  is   then 15% and all 3 of those stocks will be compared to that  benchmark.

Each   stock  was compared against its Industry benchmark for each of the   metrics  and given a score 1=Poor, 2=Good, 3=Great as well as a composite   score  out of 27. 9 metrics with a max score of 3 in each of the   metrics.  The scores are based on how much better they are then the   average. I  measured them against the benchmark using the same   methodology as  previously performed: Poor < 100%, Good < 150%,   Great > 150%.  Again, these may be tweaked slightly depending on the   particular  metric to find a useful distribution.

I    also ranked every stock against the entire list for each of the   metrics  and overall. For those wondering, the best stock in this   ranking was  CORT with a score of 2,097 and the worst was CYCN with a   score of  23,095. Because the overall rank is a combination of 9   categories with  values ranging from 1-2791, the theoretical best a   company could do  would be 9 and the theoretical worst a company could   do would be 25,119.  Anyone wondering why the number of stocks doesn’t   match the original  input is primarily due to mergers/acquisitions or   the stock being taken  private. Another stock was acquired during the   analysis, changing the  max number yet again.

Here is an example showing Aerospace & Defense scoring: [https://imgur.com/a/fKDYNXE](https://imgur.com/a/fKDYNXE)

Here is an example showing growth scoring (the Revenue Growth column is the company’s most recent year): [https://imgur.com/a/6hy5NuM](https://imgur.com/a/6hy5NuM)

Here is an example of the visualizations for the data:[https://imgur.com/a/bMH98rM](https://imgur.com/a/bMH98rM)

I    applied a series of filters to eliminated unwanted noise. I looked at    the top 5 stocks per industry (extending out for any ties), any stock    that scored a 25, 26, or 27 on the composite, or any stock that had a    high enough overall rank to justify being reviewed.

Next,    I read the description of \~300 stocks and looked through their    financials for any inconsistencies, such as one huge year throwing off    their average, profit margins higher than operating margins, highly    leveraged companies with poor growth, etc. My favorite find was that    Chemed Corporation provides hospice/palliative care and owns    Roto-Rooter. Yes, I did end up keeping them, no there are not great    synergies between the sectors of the business, yes, they are aware of    this. I also eliminated industries I wasn’t interested in reviewing,    such as REITS due to the need to look at different metrics like FFO, Oil    and Gas because it’s oil and gas, etc. These activities eliminated    \~150. I would like to get back to REITs, but I’d need to build a    separate model.

I then looked at    each stock in more detail compared to its peers that made the cut. Are    all the rest of them in the double digits for growth, are the profit    margins substantially less, which one is in a better debt situation,    etc. Who deserves to be on this list? This eliminated \~75.

We    were down to 84 stocks at this point. I then attempted to look at  each   company's investor presentation, annual report, etc. to better    understand what the company does, their revenue model, risks, etc. I was    not nearly as thorough on this portion this year compared to last  year   just due to the substantial increase in companies, 26 vs 84. I  only   eliminated 1 company which left us at the grand total of 83  companies   across 31 industries. Breakdown here: [https://imgur.com/a/8P9dmd9](https://imgur.com/a/8P9dmd9)

I then purchased all of these in equal proportion a few days ago:

* AAON
* AAPL
* ACN
* ADBE
* AEIS
* ALGN
* AMAT
* ANET
* APH
* ATR
* ATVI
* AX
* BLD
* CDNS
* CGNX
* CHD
* CHE
* CORT
* CPRT
* DLB
* DORM
* EPAM
* ESNT
* ETSY
* EW
* EXPD
* EXPO
* FAST
* FB
* FIX
* FOXF
* FTNT
* GGG
* GOOG
* GRMN
* HEI.A
* IDA
* INS
* INTC
* INTU
* IRBT
* ISRG
* JCOM
* KLAC
* LRCX
* LULU
* MASI
* MED
* MKSI
* MKTX
* MNST
* MORN
* MPWR
* MSFT
* NMIH
* NRC
* NVDA
* ODFL
* OLED
* OLLI
* PAYC
* PAYX
* PRLB
* QLYS
* REGN
* RMR
* ROAD
* SCCO
* SFBS
* SLP
* STMP
* TDY
* TER
* TREX
* TROW
* TTD
* TYL
* UI
* V
* VEEV
* VRTX
* WAL
* YETI

Notes

* I    partnered up for both the 2020 and 2021 experiments. This was  critical   for both expanding my initial idea, brainstorming methods to  build the   model, assistance on the code, gathering data, and reviewing  for  errors.  This was a team effort, and I by no means deserve all the   credit.
* All data is shown through close of market 4/30/2021.
* Unless specified, all returns are showing reinvested dividends in the total return.
* Interestingly    5 out of the 19 stocks that were eliminated in the last round of the    2020 experiment made it to this year’s list. 15 out of 26 of last  year’s   final picks also made it. I’ll post an update once I have more  than a   few data points. If you have any questions, I’ll do my best to  answer   them. Hope you enjoyed the journey.
* The indexes ended up heavily weighted in tech/semiconductors. This is the way the math pointed me, so that's the way I went.

\*I    am not a financial advisor or anything else I should put here to   ensure  it is clear that I did this for myself and am sharing my results   and am  in no way forcing you to push buttons to buy things you don’t    understand or requiring justification for this run on sentence and    henceforth. You are welcome to do whatever you like with the    information, though if you’re going to sell it that’s some pretty messed    up \*\*\*\*. Past results are no guarantee of future returns.",FinancialWhoas,2021-05-07 17:54:26,90,60,0.86
963,"Hi,

I was thinking to invest in the S&P500 index instead of cherry-picking stocks (through Ireland ETF). The reasons are that my country doesn't have a tax treaty with US and to lower the risk of individual stocks.

But by looking into S&P index constituents there are many stocks that looks overvalued to me (based on PE ratio, I will assume that 25PE is a reasonable PE for value stocks for a time to come):

\- AMZN PE 62.25 - its earnings would have to increase 250% to reach PE 25. Through which business segment? Internet sales - with covid over, people would spend more time in brick and mortar shops, expansion possibilities in new countries is very limited as there are local players.  Prime Video? Look at Netflix - new users do not add so quickly, I'm expecting this segment to have a low earnings increase. AWS - there are more competitors and many business are not so fond of paying to Amazon much more than what they are currently paying, I'm estimating possible growth of 10% Y2Y in the next 5 years. 

\- TSLA - while it has a strong brand the valuation that is higher than VW and Toyota combined is questionable. The graveyard is full of people who shorted TSLA although

\- V (Visa Inc) - PE 54.81 - debit card payments are now the norm even in third-world countries outside of the world. To reach 100% growth in earnings I think you'll have to wait long.

\- Mastercard - see Visa Inc

\- NVIDIA PE 83.98 - when crypto mania is over,  graphic cards would not be such a great business, compare this to Samsung's PE 21.35, Nintendo's PE 16.41 or TSMC 28.68

\- Adobe PE 42.26 - Adobe to grow more than Microsoft? Good luck with that. This is a business software company, compare that with SAP PE 25.27. There are some labor requirements that give Adobe an advantage so my guess is that 35 PE would be reasonable

Obviously, I'm assuming some things wrong, but did I underestimate all these companies?",AdamovicM,2021-05-07 05:45:51,14,96,0.65
964,"It is common advice to simply invest in a low-cost mutual fund or ETF for the S&P 500 index or perhaps for the whole market.  Warren Buffet says ""I do not think the average person can pick stocks.""  Certainly it makes the most sense for many people to simply pick standard index funds for their 401(k), for example.

But what about the ""better than average"" investor?  Yes, I know that it may be presumptuous to assume that I could do better than professional fund managers, but it seems that it shouldn't be difficult to find companies within the S&P 500 that beat the average more often than not.

To test this idea, I took a look at the S&P 100 (not the full 500) and how each company did compared to the average over the past 10 years.  I picked the companies that consistently beat the average over the full 10 years, 5 years and 3 years.  Using a similar weighting as the index itself, I came up with the following portfolio of 20 stocks:

* **Communication Services**: GOOG, DIS, NFLX
* **Consumer Discretionary**: AMZN, TSLA, NKE, HD
* **Consumer Staples**: TGT, COST
* **Financials**: MA, V
* **Health Care**: UNH, DHR, TMO
* **Information Technology**: AAPL, MSFT, NVDA, ADBE
* **Industrials**: HON, UNP

I did not choose any companies from the Utilities, Materials, Real Estate or Energy sectors, but collectively these entire sectors comprise 10.1% of the S&P 500.

This portfolio would have performed *significantly* better than the index over the past 10 years.  Even if you remove TSLA, the returns are about 3x over the index.

These are all well-known companies, many of whose products or services I use on a regular basis.  I know that ""past performance is no guarantee of future results"", but it seems to me that that these high performing companies are more likely to continue to beat the average than not.

For an investor that is willing to keep an eye on their portfolio and make changes when necessary, instead of forgetting about it for 10 years, why wouldn't a bucket of stocks like this be a better choice than an index fund?  Why should we settle for the average instead of going with companies that are consistently better than average?",andrwsc,2021-05-04 05:03:46,15,75,0.63
965,"https://nvidianews.nvidia.com/news/nvidia-announces-cpu-for-giant-ai-and-high-performance-computing-workloads

“NVIDIA today announced its first data center CPU, an Arm-based processor that will deliver 10x the performance of today’s fastest servers on the most complex AI and high performance computing workloads.

The result of more than 10,000 engineering years of work, the NVIDIA Grace™ CPU is designed to address the computing requirements for the world’s most advanced applications — including natural language processing, recommender systems and AI supercomputing — that analyze enormous datasets requiring both ultra-fast compute performance and massive memory. It combines energy-efficient Arm CPU cores with an innovative low-power memory subsystem to deliver high performance with great efficiency.

“Leading-edge AI and data science are pushing today’s computer architecture beyond its limits – processing unthinkable amounts of data,” said Jensen Huang, founder and CEO of NVIDIA. “Using licensed Arm IP, NVIDIA has designed Grace as a CPU specifically for giant-scale AI and HPC. Coupled with the GPU and DPU, Grace gives us the third foundational technology for computing, and the ability to re-architect the data center to advance AI. NVIDIA is now a three-chip company.”

Shares up 4% on the news wonder what that means for the ARM deal

Edit: https://www.globenewswire.com/news-release/2021/04/12/2208550/0/en/NVIDIA-Announces-First-Quarter-Fiscal-2022-Revenue-Tracking-Above-Outlook.html

Raised guidance too wow",day_bowbow,2021-04-12 17:17:09,1740,220,0.98
966,"I'm looking to concentrate my portfolio down to 15 stocks to maximize earnings. I'm currently at 24 stocks and it's been very difficult to trim down and I was hoping the public can give their input.

My current holdings:

1. ABNB
2. GOOGL
3. AMZN
4. AAPL
5. CRWD
6. DIS
7. ENPH
8. ETSY
9. FB
10. JPM
11. LMT
12. MSFT
13. NKE
14. NVDA
15. PYPL
16. PTON
17. PINS
18. ROKU
19. SE
20. SQ
21. TSM
22. TDOC
23. TSLA
24. TWLO

I'm looking to get rid of NKE, LMT, JPM, DIS, PYPL, TSLA and possibly ENPH. This drops my holdings down to 17. 

Apologize for the long list but really looking for inputs out there. I believe all these listed companies are great and love their business strategy and management. However, difficult decision need to be made to consolidate.",Newyorkntilikina,2021-04-11 02:22:31,31,82,0.78
967,"# What catalysts/deals are said to be revealed shortly?

**Summary of A, B, C below:** CEO says their biggest deal is with “one of the largest auto companies in the world, and they are in serious, late stage deal talks with 10 auto companies, 26 total have taken demos of their new technology. The announcements will be any time now given the timing described below.

\--------

# A. March 22 CEO Yahoo Interview

[https://finance.yahoo.com/video/4d-imaging-radar-provides-100-190645624.html](https://finance.yahoo.com/video/4d-imaging-radar-provides-100-190645624.html)

\-At the 5:00 mark the CEO says they'll be releasing new deals within weeks

\-At the 5:22 mark the CEO says they're engaged with Valeo-(a nearly 20 billion EUR per year manufacturer that sells radar and more to[ $GM](https://stocktwits.com/symbol/GM),[ $F](https://stocktwits.com/symbol/F),[ $DDAIF](https://stocktwits.com/symbol/DDAIF) (Mercedes), and others)

\--------

# B. March 18 CEO webcast

[https://www.sec.gov/Archives/edgar/data/0001816696/000121390021016441/ea137987ex99-2\_industrial.htm](https://www.sec.gov/Archives/edgar/data/0001816696/000121390021016441/ea137987ex99-2_industrial.htm)

\-We have an order from “**one of the largest car companies in the world** for pre-production”

\-“We expect to end up 2021 with a **booking value of more than half a billion dollar** in our hand.""

\-“We have **more than** **10 car manufacturers** that we are in advanced evaluation process. Actually, last phases. Sometimes it's -- even our -- after (inaudible) that we have shortlisted and some of them are in final evaluation stages. We believe that all of those 10 companies will take decisions on their next generation radar during this year. And we expect to end up 2021 with a booking value of more than half a billion dollar in our hand.""

\-""We have today **three purchase orders from a robotaxi,** from a delivery robot company”

\--------

# C. March Investor Presentation

[https://www.sec.gov/Archives/edgar/data/1816696/000121390021016441/ea137987ex99-1\_industrial.htm](https://www.sec.gov/Archives/edgar/data/1816696/000121390021016441/ea137987ex99-1_industrial.htm)

\-A soon to be named auto company is entering a deal with Arbe that will result in 300 million in sales for one model, and could account for 10x (3 billion) in sales for more models.

\-The auto company is likely a US company because it is described as “Western” while the OEM described next to this mystery Western company in the presentation is described as “European”(If it’s a Western and not European, it’s likely a US company) *(\*See investor presentation slide 22)*

\-Elon Musk is quoted in the Arbe investor presentation - “Lidar is doomed” (\*Agree or disagree with Musk feeling this way today, the company is making a point in their presentation about the value of their \~$100 radar on chip IP outperforming the Lidar tech that can costs $1,000’s)

\-Arbe is a “First Mover” and “Market Leader” in 4D imaging radar technology-(Slide 16). This positions them to be chosen first to take the place of traditional radars in the exact same slot that is already built in for radar use, but can now be used for 4D imaging radar chips.

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# What new customer/company fits the description of the largest new deal?

**Customer description #1 -** It is “One of the largest automobile companies in the **world”** *(\*See the Arbe CEO’s merger webcast))*

**Customer description #2 -** It is a “Leading, Global, Western” company\*-(presumably not with a homebase in Europe for reasons described above\*\*\*)\*\* *(\*See Investor presentation slide 22)*

**Company that meets both descriptions** **=** One of the US’s “Big Three” -- **General Motors $GM, Ford $F, or Chrysler/Stellantis $STLA** *\*Although there are no guarantees that it will be one of these 3, there are not many other companies that fit both above descriptions given by Arbe*

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# Who is Arbe Robotics / $ITAC and what do they do?

\-$ITAC recently merged with Arbe Robotics to create a publicly traded company

\-Their product is the first and only available long-range, 4D Imaging Radar (so little to no competition)

\-Their 4D Imaging Radar:

\>Is used in personal cars, trucking, delivery, industry, agriculture, mining, etc. \*(Primary / most profitable focus is the automotive industry)

\>Is needed for every level of vehicle autonomy (Tier 1, 2, 3, 4, 5)

\>Supposedly outperforms Lidar and Cameras, especially in fog, rain, dust, glare, dark, and other poor conditions (see performance details below)

\>Fits in the same slot that current, old radars fit in, but their radar provides over 100x better quality, and a 4th dimension, allowing you to “see” objects in a new way

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# Is Arbe’s technology a “disruptor” with a large market opportunity?

1. Qamcom’s CEO explains why Arbe’s technology is a disruptor that supersedes existing alternatives - “Choosing Arbe as a partner was an obvious choice since there is no other radar chipset solution on the market that is comparative,” said Johan Lassing, chief executive officer of Qamcom. “Traditional or contemporary radar solutions don’t solve the challenges that autonomous vehicles face. Arbe revolutionized radar by creating a sensor that provides a never-before-seen image which is close to the image that vision based sensors achieve that also has the properties of radar – Arbe’s 4D Imaging Radar Solution has the potential to be the primary sensor candidate for the sensor suite of any autonomous and semi-autonomous applications and next generation perception platforms.”
2. The CEO says their new 4D Visual Radar technology is designed to fit in the same spot as existing radars, making it immediately usable by auto companies[ ](https://podcasts.apple.com/il/podcast/173-noam-arkind-arbe-robotics/id1353975287?i=1000501753796)
3. The 4D Imaging Radar is suitable for every level of vehicle autonomy (1, 2, 3, 4, 5)
4. Already has “key partnerships” with Nvidia, Valeo, Denso, and other reputable/large companies involving their radar-on-chip technology (\*See slide 9 of investor presentation)
5. The technology can be used outside of cars - e.g. mines, agriculture, trucking, delivery, more -[ ](https://venturebeat.com/2021/01/11/qamcom-will-bring-arbes-4d-imaging-radar-to-trucks-mines-and-farms/)
6. CEO claims their main competitor is Mobileye (\*Mobileye was bought out by Intel for $15 million). CEO claims Mobileye will have a chipset in 2025 that is similar to what Arbe already has today (\*See investor webcast link below)
7. Resolution and performance supersedes all existing radar technology[ ](https://www.embedded.com/imaging-radar-development-platform-offers-2k-resolution/)
8. The Arbe CEO explains their IP value “We believe that the gross profit and the gross margins of this business are attractive, more than 65%. This is because -- this is not just silicon. These are real algorithms, real IP-embedded on our chipset and we believe that we're going to maintain those margins for the long run as well as high EBITDA margins and free -- very good free cash flow.""
9. [https://finance.yahoo.com/news/arbe-named-cool-vendor-gartner-120000037.html](https://finance.yahoo.com/news/arbe-named-cool-vendor-gartner-120000037.html)
10. [https://www.youtube.com/watch?v=JzE\_7vvO53Q](https://www.youtube.com/watch?v=JzE_7vvO53Q)
11. [https://www.youtube.com/watch?v=Yc4MfzbbtuI&t=140s](https://www.youtube.com/watch?v=Yc4MfzbbtuI&t=140s)
12. CTO explains how Lidar is unnecessary and superseded by Arbe’s new 4D radar imaging technology -[ https://www.youtube.com/watch?v=mroFpiZ7LKo](https://www.youtube.com/watch?v=mroFpiZ7LKo)
13. CEO Forbes opinion article - ask for link (Dated 4/9/21)
14. The company owns multiple patents to support their market edge, including patents for their specific radar-on-chip technology and radar interference mitigation technology

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# Valuation/Profitability considerations

\-Arbe CEO said “We believe that the gross profit and the gross margins of this business are attractive, more than 65%. This is because -- this is not just silicon. These are real algorithms, real IP-embedded on our chipset and we believe that we're going to maintain those margins for the long run as well as high EBITDA margins and free -- very good free cash flow.""[ https://finance.yahoo.com/amphtml/news/qamcom-arbe-collaborate-bring-power-150000097.html?soc\_src=social-sh&soc\_trk=tw&tsrc=twtr&\_\_twitter\_impression=true](https://finance.yahoo.com/amphtml/news/qamcom-arbe-collaborate-bring-power-150000097.html?soc_src=social-sh&soc_trk=tw&tsrc=twtr&__twitter_impression=true)

\-The Arbe CEO says ""When Mobileye passed $300 million in revenue, the figure that we are expecting for 2025, Intel bought them for $15 billion.”

\-The Spac transaction values Arbe at a low $572 million enterprise value, implying only a 1.8x multiple on 2025 forecasted revenue and a 4.4x multiple on 2025 forecasted pro forma Adjusted EBITDA \*This presumably does not account for new or unexpected deals that may arise of the 10 auto companies they are currently in final stage talks with, or the company referred to as “one of the largest auto companies in the world”

\-ITAC/Arbe has a small, 7.7 million share public float which could move quickly when catalysts are revealed (\*Institutional elements of the non-public float include a PIPE paid for by respected “strong hand” institutional investors such as M&G Investment Management, Varana Capital, Texas Ventures, and Eyal Waldman-(founder and CEO of Mellanox Technologies $MLNX))

\-The institutional portion of the float is unlikely to sell - “What matters is not the price or the valuation at the time of the flotation, but in the long term; especially when the **holdings of all the existing shareholders are vested for at least a year**, so you don't sell in a hurry“[ ](https://en.globes.co.il/en/article-israel-has-more-unicorns-than-all-of-europe-1001366171)

\-The CEO recently recommended that shareholders hold shares until they reach a $15 billion dollar market cap-(This is his 3rd company and he believes this company will reach that)(\*This source is described as “Israel's largest and most popular news and content website”) -[ ](https://www.ynet.co.il/articles/0,7340,L-5907598,00.html)

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# Industry peers to compare against current market cap / valuation

\-[$MVIS](https://stocktwits.com/symbol/MVIS)

\-$VLDR

\-$LAZR

\-$AEYE

\-$AEVA

\-$THBR

\*-\*Mobileye (was bought out by Intel for $15 billion)

*-\*There are others, but this is a sampling*

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# Stock details

\-Common shares are trading around NAV at the time of this post

\-Warrants are redeemable with typical SPAC rates: 1 for 1 at an 11.50 strike price, with a 5 year expiration (redeemable only if the common SP stays above $18 for 20 of 30 trading days)

**----------------------------------------------------------------------------------------------------------------------------------------------------**

# Summary

Arbe developed and patented a new type of 4D radar imaging technology that negates the need for expensive lidar and vastly improves existing camera/radar performance (over 100x better than existing radar). Arbe is the “first mover” in the market, with little to no competition. The new 4D imaging radar fits in the same slot in a car that the older radar technology uses, making the transition easy for auto companies. The total market for the product includes all Tiers of vehicles (1, 2, 3, 4, 5).

The price was designed to be virtually the same as existing radars-($100 per unit, $150 for premium), and is drastically more affordable than paying $1,000’s for lidar. Arbe’s 4D radar vastly outperforms the more expensive Lidar in many conditions such as fog, rain, dust, glare, dark, and more, making it indispensable for both ADAS and autonomous applications.

\*Value will be confirmed by catalyst/deals soon, as the CEO has many quotes describing deals they are signing to be publicized shortly (see above).

**----------------------------------------------------------------------------------------------------------------------------------------------------**

\*Disclaimer\* Not investment advice. I am not a financial advisor. Please research the above links and other sources.",InvestTradeEarn,2021-04-10 13:56:28,20,10,0.76
968,"It's official - ARKX is available for trading today (3/30/2021).

Here is the top 20 holdings in ARKX (sorted from largest weight to smallest weight):

Company Ticker Weight(%) Shares Market Value($)

TRIMBLE INC TRMB 8.47 1156 $86,353.20

THE 3D PRINTING ETF PRNT UF 6.1 1636 $62,168.00

KRATOS DEFENSE & SECURITY KTOS 5.62 2203 $57,322.06

L3HARRIS TECHNOLOGIES INC LHX 4.97 255 $50,729.70

[JD.COM](https://jd.com/) INC-ADR JD 4.91 610 $50,062.70

KOMATSU LTD 6301 JT 4.56 1547 $46,545.40

LOCKHEED MARTIN CORP LMT 4.47 125 $45,588.75

IRIDIUM COMMUNICATIONS INC IRDM 4.23 1132 $43,163.16

THALES SA HO FP 3.9 407 $39,789.41

BOEING CO/THE BA 3.48 145 $35,506.15

NVIDIA CORP NVDA 3.32 66 $33,895.62

SPIRIT AEROSYSTEMS HOLD-CL A SPR 3.26 687 $33,209.58

DEERE & CO DE 3.18 87 $32,389.23

[AMAZON.COM](https://amazon.com/) INC AMZN 2.99 10 $30,520.30

TERADYNE INC TER 2.74 235 $27,969.70

ALPHABET INC-CL C GOOG 2.59 13 $26,462.15

DASSAULT SYSTEMES SE DSY 2.55 121 $26,035.27

TELEDYNE TECHNOLOGIES INC TDY 2.55 65 $26,050.70

GARMIN LTD GRMN 2.01 160 $20,539.20

VIRGIN GALACTIC HOLDINGS INC SPCE 1.95 672 $19,884.48

&#x200B;

 I can't post the entire list because it might contain ""forbidden"" tickers, and mods will delete this post.

For the entire list and more info, you can search for ""ARK Space Exploration ETF (ARKX) - Holdings Reveal"" on youtube ( sorry, mods keep deleting my post because of youtube link).

Hopefully, the information here will be useful to everyone.",learner4f,2021-03-30 09:19:10,113,183,0.9
969,"[https://www.cnbc.com/2021/03/29/ark-invests-arkx-space-exploration-etf-to-begin-trading-on-tuesday.html](https://www.cnbc.com/2021/03/29/ark-invests-arkx-space-exploration-etf-to-begin-trading-on-tuesday.html)

Ark Invest, Cathie Wood’s firm with multiple actively managed exchanged-traded funds, will debut its latest fund on Tuesday: a [space exploration ETF](https://www.cnbc.com/2021/01/13/cathie-woods-ark-invest-plans-space-exploration-etf-arkx.html).

The ETF’s [top 10 holdings](https://etfs.ark-funds.com/hubfs/1_Download_Files_ETF_Website/Fact_Sheets/ARKX_Factsheet.pdf) by weight:

1. [Trimble](https://www.cnbc.com/quotes/TRMB) \- 8.3%
2. [The 3D Printing ETF](https://www.cnbc.com/quotes/?symbol=PRNT) \- 6.1%
3. [Kratos](https://www.cnbc.com/quotes/KTOS) \- 5.6%
4. [L3Harris](https://www.cnbc.com/quotes/LHX) \- 5%
5. [JD.com](https://www.cnbc.com/quotes/JD) \- 4.8%
6. [Komatsu](https://www.cnbc.com/quotes/6301.T-JP) \- 4.6%
7. [Lockheed Martin](https://www.cnbc.com/quotes/LMT) \- 4.5%
8. [Iridium](https://www.cnbc.com/quotes/IRDM) \- 4.3%
9. [Thales SA](https://www.cnbc.com/quotes/HO-FR) \- 4%
10. [Boeing](https://www.cnbc.com/quotes/BA) \- 3.6%

Ark’s new fund also includes [Virgin Galactic](https://www.cnbc.com/quotes/SPCE) (1.95% weight) among [its 39 constituent holdings](https://ark-funds.com/arkx), as of Friday.

Link to full holdings: [https://ark-funds.com/wp-content/fundsiteliterature/holdings/ARK\_SPACE\_EXPLORATION\_&\_INNOVATION\_ETF\_ARKX\_HOLDINGS.pdf](https://ark-funds.com/wp-content/fundsiteliterature/holdings/ARK_SPACE_EXPLORATION_&_INNOVATION_ETF_ARKX_HOLDINGS.pdf)

Any surprises here? For me it's the inclusion of 3d printing ETF, which makes sense. Also at #11 is Nvidia with 3.3%, #27 is Netflix with 1.25%. I'm not too familiar with the space theme so that's a bit surprising for me.",photowanderer,2021-03-29 15:21:08,428,295,0.94
970,"The Fourth Industrial Revolution is characterised by the fusion of the digital, biological, and physical worlds, as well as the growing utilisation of new technologies. It is the trend towards automation and data exchange in manufacturing technologies and processes which include:

* Cyber-physical systems (CPS) / Cyber security
* Cloud Computing
* Ai
* Advanced Robotics / automation
* Big-data
* 3D printing
* Quantum computing (hypothetically)
* Robotic process automation (RPA)
* Semi-conductors
* Biotechnology / Healthcare
* IoT manufacturing
* Renewable energy
* Manufacturing / Mining
* Crypto (I have no experience in this besides some small positions in BTC and ETH, feel free to drop any DD and knowledge)

Of course there's discussions which one are part of the industry 4.0 so I might be missing a few.

since I believe that we are still at the start of this revolution, I want to invest in promising companies related to those industries. Some companies already have proven themselves, others are still in the 'startup' fase.

**Hereby a list of the companies from which I think are the best or will be the best in the corresponding sector. What sectors and which must-have companies am I missing?**

**Note:** some sectors are very broad so they might overlap.

&#x200B;

* **Cyber-physical systems (CPS) / Cyber security**
   * **CrowdStrike - $CRWD**
      * Offers a broad spectrum of solutions with the main goal of cyber-security. Some well-known clients where they have solved hacks are Sony Pictures and the DNC (Democratic National Committee). The company is the market leader in the cloud-based endpoint security segment and is also expanding into 5G network security.
   * **Cloudflare - $NET**
      * Offers a wide range of network services to companies around the world. Cloudflare's intelligent global network spans more than 200 cities in more than 100 countries. It provides network security and improved network performance and reliability to an increasing proportion of the total Internet used. More than 15% of the internet is used via Cloudflare
   * **BlackBerry - $BB**
      * They are working on AI powered cybersecurity
      * They also work on QNX. QNX is a real-time embedded OS that controls software systems in (modern, especially EV) cars and forms the basis of solutions such as BlackBerry Radar, an IoT based asset tracking system for the transport sector.
      * Spark Suites: Spark provides visibility and protection for all endpoints, including personal laptops and smartphones used for work. It uses AI, machine learning, and automation to provide better cyberattack prevention.
   * **SUMO LOGIC - $SUMO - DD from** u/FlynnPierce
      * SaaS platform focused on data analytics and they will likely be the first to be able to call themselves a cloud-native solution for continuous intelligence. To be fair, they themselves pioneer this concept of “continuous intelligence” where companies can have real-time insight and communication with their data.
      * On March 10, 2021 they acquired DFLabs to enhance their cyber security offering, and claim that the SOAR system they inherit from the acquisition is 10x more effective in improving security operations productivity.
      * Benefits over competitors: design and ease of use, scalability and oriented quality.

&#x200B;

* **Cloud Computing**
   * I'll include Amazon and Microsoft since they deserve a spot in this list. But Amazon and Microsoft are already some of the biggest in the world and make all sorts of stuff. It's entirely possible their innovations will be integral to aspects of the 4th Industrial Revolution, but it may also only be a relative drop or glass in the larger bucket that they currently represent.
   * **Amazon - $AMZN**
   * **Microsoft - $MSFT**
   * **Cloudflare - $NET - See DD in previous category**
   * **Fastly - $FSLY - Need DD**
   * **Digital Ocean - $DOCN - Need DD**

&#x200B;

* **Ai**
   * **Google - $GOOGL - Need DD**
   * **C3Ai - $AI - Need DD**
   * **Nvidia - NVDA - Need DD**
   * **Intel - INTC - Need DD**

&#x200B;

* **Advanced Robotics / automation**
   * **Teradyne - $TER**
      * Focusses on industrial automation, semiconductor testing, wireless testing and storage testing. Customers are Samsung, Qualcomm, Intel, Analog Devices, Texas Instruments and IBM. **Some of their business units are:**
      * The System Test Group: they build test machines for printed circuit boards and hard drives
      * LifePoint: test machines for manufacturers of wireless modules and consumer electronics.
      * Universal robots: provides collaborative robots (cobots) that work side by side with production workers. UR-cobots automate tasks such as machine loading, packaging, gluing, painting, polishing and assembling parts
      * Mobile Industrial Robots: offers autonomous mobile robots for the management of internal logistics (for loads under 1,500 kg). These robots are currently used in the transportation, healthcare, pharmaceutical, metal and plastics, fashion, technology and food industries.
      * AutoGuide Mobile Robots manufactures modular industrial mobile robots (for loads up to 45,000 kg). These high payload robots are used for assembly, material handling, storage and distribution across multiple industries.
   * **Cyberdyne - $CYBQY - Need DD**
   * **ABB - $ABB - Need DD**

&#x200B;

* **Big-data**
   * **Palantir - $PLTR**
      * This is the way
   * **SalesForce - $CRM**
      * Big data CRM (big data customer relationship management) refers to the practice of integrating big data into a company's CRM processes with the goals of improving customer service, calculating return on investment on various initiatives and predicting clientele behavior.
      * Salesforce is the leader in the CRM sector. Recently, Salesforce has acquired the big data firm “Tableau” for $15.3 billion and Slack for $27.7 billion, adding muscle in its fight with some major leaders. Moreover, the integration of Salesforce CRM and Big Data will enable businesses in analyzing customer patterns and preferences.
   * **SnowFlake -$SNOW - Need DD**

&#x200B;

* **3D Printing**
   * **Desktop Metal - $DM**
      * Co-founders are MIT alumnus Ric Fulop and 4 other MIT professors.
      * They have a new patent called ""single pass jetting"". It takes most 3D printing machines several times to print one layer, Desktop Metal can do it in one go. This makes them by far the fastest in the entire industry (up to 4x faster) - Speed ​​means lower costs, what DM printers can do in 1 day, takes other printers 3-4x that time.
      * They have secured a global distribution network of more than 80 partners in 60 countries offering their Live Parts software as SaaS. Live Parts is an AI software that allows users to automatically generate printable object designs. The program allows users to enter specifications for an object and then create a computer model that can be printed. As a result, they are assured of huge income in addition to their hardware
      * Today, Desktop Metal announced that it launched Desktop Health, a line specifically devoted to healthcare-adjacent products. The line encompasses a number of different technologies, including binder jetting, bioprinting and various materials.
   * **Nano Dimension - DD is from their website**
      * Nano Dimension’s DragonFly System is a one-stop solution for agile hardware development and innovative circuit design across a wide array of industries. It empowers companies to securely control entire development cycles through in-house additive manufacturing of PCBs and non-planar electronics with speed and precision, while reducing R&D costs. With it’s Lights-Out Digital Manufacturing (LDM) printing technology, this is the industry’s only comprehensive manufacturing printing platform for round-the-clock 3D printing of electronic circuitry.
   * **Markforged - $AONE - Need DD**

&#x200B;

* **Quantum Computing**
   * **IonQ - $DMYI**
      * A quick introduction to QC: a normal computer exists of bytes, so 0 OR 1, a QC has qubits, so possibly 0 AND 1 at the same time. In theory this will improve the computational power of computers in a massive way and therefore QC wil be able to solve different classes of problems
      * The qubits that make up QCs are prone to error given the fragile nature of the quantum states. There are 2 quantum states: ion trap (IonQ, Honeywell) and superconducting qubits (IBM, Google). These have about a 0.5% chance of an error during a so-called 2-qubit gate operation ([https://en.wikipedia.org/wiki/Quantum\_logic\_gate](https://en.wikipedia.org/wiki/Quantum_logic_gate)), thus limiting the complexity of the computation you will be able to do.
      * So a lot of research is being done to improve these physical error rates, but an improvement of more than 0.01% seems to be difficult.  This is where error correction becomes important. People have come up with error correction codes that can tolerate error rates and create a much lower error rate by creating what's called a logical qubit. ([https://en.wikipedia.org/wiki/Physical\_and\_logical\_qubits](https://en.wikipedia.org/wiki/Physical_and_logical_qubits)).
      * It takes a lot of physical qubits to make 1 single logical qubit.  Most researchers believe that with a few hundred to a few thousand very good logic qubits you can solve very impactful problems in the world and thus create significant value.  IonQ expects to achieve this in 7 years ([https://ionq.com/posts/december-09-2020-scaling-quantum-computer-roadmap](https://ionq.com/posts/december-09-2020-scaling-quantum-computer-roadmap))

&#x200B;

* **Robotic process automation**
   * **Blue Prism - $PRSM - Need DD**
   * **UiPath - $UIPTH (IPO later this year)**

&#x200B;

* **Semi-Conductors:**
   * **ASML Holding - $ASML** \- ASML makes the machines to produce semi-conductors. It's the absolute leader in this sector. It's currently the largest supplier of photolithography systems for the semiconductor industry.
   * **Intel - $INTC - Need DD**
   * **Advanced Micro Devices - $AMD - Need DD**
   * **Nvidia - $NVDA - Need DD**
   * **Taiwan Semiconductor Mfg - $TSM - Need DD**

&#x200B;

* **Biotech / Healthcare**
   * **Crispr Therapeutics - $CRSP - Need DD**
   * **Beam Therapeutics - $BEAM - Need DD**

&#x200B;

* **Internet of Things manufacturing**
   * **PTC - $PTC - Need DD**

&#x200B;

* **Renewable Energy**

&#x200B;

* **Construction / Mining**
   * **MP Materials (NYSE: MP) - DD from** u/FlynnPierce
      * is a rare earth mining and processing company who owns and operates THE ONLY rare earth mine source in the US. This resource provides the essential metallic and magnetic raw materials used in most modern technology from Electric Vehicles to windmills and robotic arms. Yeah. That’s HUGE. There is obviously a massive need for these resources going forward and MP is the only chance the US has of competing with China in this demand. Of course, China operates in a market condition where they can exploit working conditions and the workforce in ways that American companies cannot, and MP claims to engage in their mining activity sustainably. Noting that MP (Mountian Pass) Mine is in California, we can assume they are doing their best to remain in compliance with a green energy future. MP NET INCOME Q4 2019: 1M MP NET INCOME Q4 2020: 24M

&#x200B;

* **Crypto**
   * **Bitcoin**
   * **Etherium**

&#x200B;

**EDIT 1: 'm not from the states so I can't buy any of Cathie's ARK ETF's**

**EDIT 2: Added MP Materials (mining / construction) and SUMO (cyber security) to the list**",SnooObjections2665,2021-03-24 07:48:19,540,196,0.92
971," Nvidia might be a bit expensive today, but looking at the future and their competitors, I’m still long on Nvidia and this is why:

1. In the last 6 months, their webpage traffic has almost doubled. From 22M in September to 36M in February. More visitors to their webpage tells me that more people are interested in their products.
2. They are looking to hire more people than their competitors. Nvidia has currently around 1000 open positions, compared to 700 for AMD and 650 for Intel. This tells me that the company is growing. But it’s also interesting to see what kind of people they are hiring. I like that they are looking to hire people for their Autonomous Vehicles Platform - huge future opportunity.
3. Highest employee rating in the industry. People like working for Nvidia (if we should trust sites like Glassdoor and Indeed), more so than their competitors. The CEO approval is at an all time high and I believe that this will help them attract even more great people in the future.

On top of this, financials looks rock solid with increasing revenue year over year.

Source: [https://dillibits.com/index.php?t=NVDA](https://dillibits.com/index.php?t=NVDA)

Your thoughts?",robertrydefalk,2021-03-17 17:31:30,51,26,0.85
972,"Teradyne Inc, Ticker: **TER (+38% mentions)**

Market cap: $19.5Bn

Teradyne Inc supplies automation test equipment for semiconductors, wireless products, data storage and complex electronic systems in the consumer electronic, automotive, industrial, communications and aerospace sector.

Essentially, the chip powering the phone or laptop you are reading this from has most likely been tested by Teradyne.

Teradynes biggest customers include Samsung, Qualcomm, Nvidia, Intel, Boeing, Texas Instruments, 3M, and IBM.

Don’t have time to read the whole thing? I’ll summarise below

3 main reasons why I like this stock:

* Overall semiconductor market future
* Finances and balance sheet
* Cathie Wood investment

2 possible downsides:

* Low future earnings forecasts
* Recent price volatility

Future

Almost everything requires a semiconductor now, and that will only grow further in the future, some of the biggest examples are:

* The majority of mobile phones sold nowadays are smartphones, and while that growth has slowed down over the last few years, 1.5 billion a year are still sold.
* The ecosystem surrounding mobile phones is growing rapidly, think tablets, smart watches, headphones, laptops, speakers.
* Internet-of-things devices are booming, think Alexa, smart lighting, ovens, fridges,heating, mirrors etc.
* Car technology (especially in electric cars) is mostly driven by semiconductor technology, shifting further and further away from analog technology
* Gaming, from Playstations to VR headsets, again all require semiconductor technology
* Automated manufacturing

Even without COVID, supply cannot keep up. There have been huge shortages this year for semiconductors causing pinches everywhere *(have you tried purchasing a PS5 recently?)* meaning lots of pent-up demand, even without, a number of HUGE factories have been built or will be built that are expected to ramp up supply. examples of those:

* [Samsung’s $17bn factory](https://www.extremetech.com/computing/319926-samsung-files-documents-to-build-new-17-billion-fab-in-the-united-states)
* [TSM’s $12bn plant](https://www.fool.com/investing/2020/05/15/taiwan-semiconductor-to-build-a-12-billion-chip-pl.aspx)
* [Intel’s $7bn plant, completed in 2020](https://hexus.net/tech/news/cpu/145990-intel-fab-42-now-ready-pump-leading-edge-products/)
* [List of all current fabrication plants to give you an idea of size of market](https://en.wikipedia.org/wiki/List_of_semiconductor_fabrication_plants)

All of this will require automation and testing.

Long-term, it’s very safe to assume that irrespective of economic or technological shifts, semiconductor demand will not only sustain, but surge. A few things on the horizon that will likely affect this:

* 5G technology being rolled out worldwide
* Space technology & tourism growth
* AI & data technology

The biggest kicker? Teradyne provide the majority of the automation and testing for all of these sectors, meaning any growth here only benefits them.

Furthermore, to me they are also proofed from the whole *“economy opening up means a move away from tech“* as it’s not like people will stop using electronic devices, unlike companies like Zoom which will see a big drop in usership as normality returns.

Finances

Even during a COVID year, Teradyne grew revenues from $2.29bn to $3.12bn, an increase of 36%.

They grew their net income even further, going from $467m to $784m, an increase of 67%.

Earnings per share *(profit by number of shares)* also grew, from $2.6 to $4.28 (**+64%**) last year which is astounding. (*general consensus is anything above 25% growth is good).*

When taking the price of the stock into account, and looking at Price-to-Earnings ratio *(Price of the stock vs the earnings per share of a stock, the lower the better)* Teradyne has a PE ratio of 24.9x, which is way better than the industry average of 38x.

From a debt position, Teradyne is very healthy with an equity-to-debt ratio *(the lower the better, below 1 means more equity than debt)* of 0.18.

Cathie Wood Investment

Cathie Wood, the very aggressive bullish investor whos ETF [ARK Invest](https://finance.yahoo.com/quote/ARKK/performance/) saw returns of 152% last year, [has recently purchased a further 139,619 shares](https://247wallst.com/investing/2021/03/12/cathie-woods-ark-invest-buys-and-sells-3-12/) to add to the current position.

Extra purchasing here shows long-term confidence, as this was added after ARK had to rebalance and sell some Teradyne shares last year.

Possible Downsides

Some analysts are predicting modest future revenue growth at 5.8%, compared to the industry average of 16.2%.

Furthermore, the price this year has seen some large volatility, suffering from the sell-off that affected technology and growth stocks earlier this year. If more sell-offs ensue, this could cause the price to drop further in the short term.

Summary

Teradyne commands a large portion of a market that is only growing further every year. A financially healthy and well managed company, with high revenue and EPS growth, along with some strong investment backing. While there may be some volatility in the price of the stock short-term, long-term this company still has tremendous potential.",akokaz1,2021-03-17 13:07:24,47,20,0.89
973,"What Warren Buffet calls the ‘economic moat’ we refer to as ‘competitive advantage’. The term refers to a companies ability to keep competition at bay over the long term life cycle of the business, maintain majority market share and favourable economics. What force is stopping or limiting the competitions capability to compete? What stops the competition from cutting their lunch? A company can have one or more of the five types of economic moats: intangible assets, cost advantage, efficient scale, switching costs, network effect. 

Here are Some examples of the economic moats/competitive advantage of some companies (or what I believe to be the moat) :

Apple — Apple’s brand power, the belief in its product superiority by consumers and its ability to create a large cult following, allows the company to price its products at double the competitions and still outsell the competition in the market place. 

Coca-Cola — The powerful brand behind Coke gives them the ability to demand higher margins and outsell the competition. Coke the brand is directly associated with happiness. Coke is a product where the customer will reject the competitions equivalent at a discount, and buy the Coke product at a premium. 

Intel — Intels vertical integration and its operations across the entire supply chain line in the chip sector, gives intel the ability to outdo the competition on every level and hold majority market share. One year intel will focus on chip innovation, the next year it will focus on production innovation and capabilities. Despite fierce competition from AMD and NVIDIA, intel has maintained its market share of the industry.

Amazon.com — Amazon is an operating system for society and daily lives of individuals. It has created a cult following who truly believe Amazon is a necessity of life equal to water, food and oxygen. Some Amazon prime members have and do become suicidal when they lose access to their account. The brand has made itself into an integral part of the day to day lives of individuals, and has made life without Amazon inconceivable for its customers. 

Facebook — Facebook takes advantage of network effects, product and brand power. As more people start using Facebook, then more people will be attracted to Facebook because their friends and everyone they know use it, it becomes a social necessity. Facebooks product and brand is so powerful, even its strongest and fiercest critics still use it. 

[Economic Moats](https://www.investopedia.com/terms/e/economicmoat.asp)",Mr-Pink_,2021-03-17 09:13:43,13,18,0.71
974,"Franklin Templeton released a bunch of  thematic active ETFs in February 2020 & March 2021. They seem pretty interesting, with a disruption/innovation theme to each of them. Matthew Moberg & Joyce Lin are the fund managers.

All these ETFs have done very well in the recent past (but then again, 2020 was an exceptional year & past performance doesn't imply future), but they have fallen quite a bit over the past 1 month, giving us potential entry points to ""buy the dip."" Here's my humble attempt at a summary:

[**Disruptive Commerce ETF $BUYZ**](https://www.franklintempleton.com/investor/investments-and-solutions/investment-options/etfs/portfolio/29096/franklin-disruptive-commerce-etf/BUYZ)**:**

1. Claims to invest in innovative companies benefitting from transformation in the e-commerce space
2. Claims to provide access to companies that are related to new online markets, streamlined procurement systems, and game-changing ways to deliver goods and services
3. Portfolio: large growth, where its top 5 holdings are popular ECommerce plays: $SE, $SHOP, $FVRR, $AMZN, $MELI, followed by interesting choices like $SQ, $PYPL, $DOCU, $UBER and $TDOC
4. Performance: +173.76% over the past year, -0.01% YTD, -16.25% over the last 1 month
5. Expense Ratio: 0.50%

&#x200B;

[**Exponential Data ETF $XDAT:**](https://www.franklintempleton.com/investor/investments-and-solutions/investment-options/etfs/overview/30780/franklin-exponential-data-etf/XDAT)

1. Claims to invest in companies focused on or expected to benefit from the creation, collection, cleaning, analyzing, storage, securing, transport, selling, and/or use of data
2. Claims to provide access to companies that the investment manager believes benefit from or facilitate big data, data infrastructure, data analytics, and innovative use cases and applications of data which include artificial intelligence, augmented and virtual reality, software-as-a-service, personalized advertising and personalized healthcare among others
3. Portfolio: large growth, mainly tech as top holdings: $SNAP, $PINS, $FB, $GOOG, $TTD, $TWLO etc.
4. Performance: was formed only in January 2021, -2.71% YTD, -9.31% over the last 1 month
5. Expense Ratio: 0.50%

&#x200B;

[**Genomic Advancements ETF $HELX**](https://www.franklintempleton.com/investor/investments-and-solutions/investment-options/etfs/overview/29097/franklin-genomic-advancements-etf/HELX)**:**

1. Claims to invest in innovative companies related to genomic-based technologies designed to enhance the quality of life
2. Claims to provide access to companies benefitting from or facilitating the use of new research including DNA sequencing, gene editing and personalized medicine
3. Portfolio: mid-cap growth, with top holdings: Intellia, Repligen, Wuxi Biologics, Illumina, Natera etc. Has an around \~38% overlap with the more famous $ARKG
4. Performance: +126.11% over the past year, -2.03% YTD, -16.28% over the last 1 month
5. Expense Ratio: 0.50%

&#x200B;

[**Intelligent Machines ETF $IQM**](https://www.franklintempleton.com/investor/investments-and-solutions/investment-options/etfs/overview/29098/franklin-intelligent-machines-etf/IQM)**:**

1. Claims to invest in innovative companies furthering techniques that automate or enhance everyday tasks
2. Claims to provide access to companies that are developing technologies that support machine learning as well as those using automated processes
3. Portfolio: large growth, with interestingly diversified top holdings: $TSLA, $AAPL, $ISRG, $TSM, $AXON, $ADSK, $NVDA etc.
4. Performance: +137.14% over the past year, -0.36% YTD, -10.64% over the last 1 month
5. Expense Ratio: 0.50%

&#x200B;

**So, what do you people think about them? Which ones do you like / see room for medium-to-long term growth?**

Thanks for reading!",learn-and-earn-,2021-03-16 19:53:22,20,16,0.8
975,"Plus has received more than 10,000 preorders for its autonomous truck driving system, which is expected to be commercially available in 2022 in the U.S., China and Europe.

Plus, a self-driving truck technology company, has made several recent announcements:

The company will use NVIDIA DRIVE Orin system-on-a-chip (SoC) in its autonomous driving systems.A former Navistar exec has joined Plus as chief platform officer.Plus recently raised $200 million in new funding.

Plus was founded in 2016 and specializes in self-driving technology for large-scale autonomous transport. The company is starting mass production of its autonomous driving system for heavy trucks this year. 

According to a press release, the company will expand its feature set and operating design domain over time through over-the-air software updates. By working with the NVIDIA engineering team to further evolve its system, Plus will make it possible for trucks powered by its system to achieve fail-operational performance for on-road safety.

“Enormous computing power is needed to process the trillions of operations that our autonomous driving system runs every fraction of a second. NVIDIA Orin is a natural choice for us and the close collaboration with the NVIDIA team on a custom design for our system helps us achieve our commercialization goals,"" says Hao Zheng, Plus CTO and cofounder. ""We have received more than 10,000 pre-orders of our system, and will continue to develop our next-generation product based on the NVIDIA DRIVE platform as we deliver the systems to our customers.""

The Plus autonomous driving system is designed to make long-haul trucks safer and more efficient. Because of the size and weight of heavy trucks, which can total 80,000 lbs. with a fully-loaded trailer, they need more time to come to a stop and to maneuver.

Plus’ system uses lidar, radar and cameras to provide a 360° view of the truck’s surroundings. Data gathered through the sensors help the system identify objects nearby, plan its course, predict the movement of those objects and finally control the vehicle to make it move safely.

The NVIDIA Orin, which can deliver 254 trillion operations per second, can handle the large number of concurrent operations and support deep neural networks to process and make decisions using the data on heavy trucks outfitted with the Plus autonomous driving system. Orin is also designed for ISO 26262 Functional Safety ASIL-D at the system level for safety.

“Plus and its automated trucks are delivering true social benefits today through improved safety and efficiency,” says Rishi Dhall, vice president of autonomous vehicles, NVIDIA. 

To support the global deployment of its self-driving truck technology, Plus has added two new senior hires; Mooney, who was most recently senior vice president of global product development at Navistar and Chuck Joseph, who joined from Amazon’s Global Transportation Technology Group.

The company also closed $200 million in new funding in February led by new investors Guotai Junan International, CPE, and Wanxiang International Investment. Existing investors including Full Truck Alliance (FTA) also participated. Plus will use the funding to develop a sales and support network to help fleets integrate the Plus automated trucking system into their daily operations. The company will also scale deployments in the U.S. and China, and expand internationally to Europe and other parts of Asia.

Plus also recently announced collaborations with Amazon AWS, Blackberry QNX, and Ouster










https://www.forconstructionpros.com/trucks/trucks-accessories/heavy-trucks-class-7-8/article/21319412/plus-plus-nvidia-partner-on-heavy-truck-autonomous-driving-system",thinkB4WeSpeak,2021-03-12 04:39:00,54,8,0.9
976,"The Most Undervalued SPAC of 2021, SVAC.

Starboard Acquisition ($SVAC - $10.06) – Cyxtera

OVERVIEW :

Cyxtera, the 3rd largest data center group in the world, has agreed to go public via Starboard Acquisition Corp ($SVAC). This may be one of the most unglamorous and un-exciting SPAC mergers to date, but my belief is that this is one of the cleanest, if not the cleanest, companies to go public through a SPAC, and will ultimately be a major player in the market within the data center category.
First, let’s start with Cyxtera’s business model. What you’re looking at here is two-fold. Cyxtera is both a REIT as a large owner of 61 data centers across 29 markets on 4 continents, but also an integrated tech company – providing colocation (equipment, space, and bandwith rentals) to their customers. In short, they house data – literally and technologically. The business model is relatively simple. Customers sign contracts (guaranteed income) for data housing in one or multiple of Cyxtera’s facilities, and in return gain flexibility and access to agility for their data needs. Every large company in the world uses the types of facilities and technology that Cyxtera provides – from State Farm to the New York Yankees to Nvidia.

FINANCIALS & STRATEGY:

Diving into some deeper data about Cyxtera, we can learn about the financial health of Cyxtera, and how they utilize their revenues that they collect through their contracts. First, and extremely importantly, Cyxtera is already both profitable and operating at scale. 2020 revenues of $690M and adjusted EBITDA of $213M is a showstopper for a company that is coming to market through a SPAC, many of which are pre-revenue and have a long ramp time to profitability. The deal with Starboard Acquisition values Cyxtera at $3.4 Billion – with only room for growth – as the need for the services that Cyxtera offers only growing substantially year over year.
Staggeringly, only 3% of Cyxtera’s revenue go towards customer retention. For anybody not in marketing, that is an absolutely astounding number. Only needing 3% of your revenue to retain customers at scale would have any financial executive or investor frothing at the mouth and falling over themselves to be a part of it. In turn, 70% of Cyxtera’s revenue goes towards growth, expansion, and development. That is in a class of it’s own, truly. Those dollars go towards building an extensive partner ecosystem, built efficiently through a go-to-market strategy that creates a symbiotic relationship between Cyxtera and their partners. Partners of Cyxtera enjoy integration capabilities, meaning they can sell Cyxtera’s services as a part of their own, expanding the suite of t ools they can offer to prospective clients. The closer you can get to a one stop shop in the technology space, the more likely you are to attract business – this is the overall goal.

Did I mention that the management of $SVAC (not Cyxtera) has already succ essfully run and sold a similar companyinthepast?TheexecutivechairmanpreviouslyranTerremarkWorldwide,whichsold to Verizon, and coincidentally, ultimately ended up in the hands of the largest player in the data center space, Equinix.

MARKET COMPARISONS:

Logically, it’s important to evaluate the space that any new public company is entering. In Cyxtera’s case, they are the 3rd largest player. The largest players are $EQIX and $DLR. For the purposes of this writeup, we will only look at comparisons from a market perspective.

$EQIX
Most recent closing price: $622.71 Shares outstanding: 89M
Market Cap: $55 Billion Institutional Ownership %: 95%
Eqix is a massive data center player, arguably the best there is. Here, it’s important to compare outstanding shares to the number Cyxtera will have. In this case, Cyxtera will have an approximately equal number of shares – and has rapidly growing institutional ownership, with 82% positive change in recent weeks on $SVAC and a total % of 59% currently.

$DLR
Most recent closing price: $135.08 Shares outstanding: 280M
Market Cap: $37 Billion Institutional Ownership %: 96%
DLR is the 2nd largest data center player. They have over 3x the outstanding shares of Cyxtera & $EQIX. You’ll notice that DLR is trading at 13x the price that $SVAC sits today. These are not perfect comps, but this is what the world values these types of companies at. These aren’t even outlandish valuations – and data centers often carry very respectable dividends. In this case, 3.44%.
Players in this space typically trade at 6-9x their sales, approximately 7-23x free cash flow, and over 20x EBITDA. As it stands, considering the nature of SPACs, $SVAC is not anywhere near these numbers. But, Cyxtera will get there – the industry itself has proven it over and over. The growth in share price over time is inevitable.

MERGER:

The final piece to touch on for now will be how this business combination will take place. This is a VERY special SPAC deal and has incentives that have gone unnoticed by the market. Shares of $SVAC include a 1/6 warrant. The units include 1/6 warrant in ADDITION to a share to compensate for the risk of holding through the business combination. This makes $SVAC set up in a better space than almost any other SPAC trading near NAV price. In addition, if the ticker does poorly as it moves towards the business combination, you’ll receive additional warrants to compensate for the risk. These units are excessively attractive.
The deal itself, my goodness. Insider shares are locked for a year OR until the stock hits $12. This means if you get in below this number, you are very unlikely to suffer through dilution/redemption that will create downwards pressure.

CONCLUSION:

Ultimately – the decision is yours to make. Personally – I like the stock. This is an opportunity to purchase a stake in a company that is significantly undervalued and unnoticed at it’s current price, and with some of the cleanest financials on the market, it’s hard to ignore the safety that this ticker brings – especially welcome safety in a tumultuous time in world history. Adjusted to include the warrants that are included in the units, you’re looking at the lowest priced SPAC that has announced a deal, period. The lowest price, with one of the highest and most stable potentials of any SPAC out there. Data centers are cash cows, and this one hasn’t even begun to moo in the market. I see potential for a huge amount of growth in a rapid period, with very competent management and a solid market strategy leading the way. At $10, there’s not a better deal on the market. Analysts have called the potential ‘explosive’. I call it kingmaking.

Oh – if you aren’t convinced yet - Cyxtera also announced expansion today. And the market missed it, because no ticker was mentioned. Check it out here:

https://www.businesswire.com/news/home/20210309005171/en/Cyxtera-Expands-Enterprise-Bare- Metal-Service-to-Amsterdam-and-Frankfurt

REFERENCE MATERIAL:

https://seekingalpha.com/article/4412584-svac-market-overlooking-tontine- warrants?utm_campaign=twitter_automated&utm_content=article&utm_medium=social&utm_sourc e=twitter_automated

https://www.sec.gov/Archives/edgar/data/1794905/ 000110465921025980/tm217463d1_ex99-2.htm

https://www.fool.com/investing/2021/03/06/a-major-data-center-player-is-going-public- through/?source=eptyholnk0000202&utm_source=yahoo- host&utm_medium=feed&utm_campaign=article",PBJBlitzkrieg,2021-03-10 04:37:21,4,4,0.55
978,"TECH STOCK RALLY CONTINUES (Buy?) 2021  
$NVDA $RBLX $UPST $RUBY several more covered  
a Lot of actionable ideas in this one.   
\#stockmarket #Video   
https://youtu.be/vrHlT0fF69o",Aretetrading_Twitter,2021-05-24 23:17:45,1,0,0.6
980," 

Stock Market end of week review! (actionable) 2021

$UPST $RBLX $ROKU $NVDA several more

Don't forget 1pm EST Saturday LIVE u/YOUTUBE 10 ten stock ideas for next week and Q and A 

\#stockmarket #video

https://youtu.be/EBTy7xTgsS0",Aretetrading_Twitter,2021-05-22 01:42:10,2,2,0.75
981,"Tech Stocks Rally! (Buy/Sell?) 2021 

 Tons of actionable ideas  

 $ROKU $TSLA $UPST $NVDA several more covered 

  \#StockMarket #Video 

https://youtu.be/gbfCOAhKxHk",Aretetrading_Twitter,2021-05-20 23:42:26,2,0,0.67
982," 

Tech stock Sell Off (Actionable)2021 Actionable entries & exits are given with a lot of talk about why the key levels are picked. I also walk through how we used chart pattern recognition & RSI to determine entry into $NVDA and $SNAP

[https://youtu.be/q03R\_CbpUk8](https://youtu.be/q03R_CbpUk8)",Aretetrading_Twitter,2021-04-29 23:25:04,3,2,0.67
986,"Hi,

I am looking for old investment letters that highlight investments in companies (before they became multibaggers). The idea is to reverse engineer the thesis and see how it played out / what they saw that the market didn't.

The companies are:

* Monster Beverage Corporation (MNST)
* Booking Holdings (BKNG)
* Amazon (AMZN)
* Boston Beer Company (SAM)
* Nvidia Corporation (NVDA)
* Activision Blizzard (ATVI)
* Ross Stores (ROST)
* Edward Lifesciences (EW)
* [Stamps.com](https://Stamps.com) (STMP)
* Autodesk (ADSK)
* Copart, Inc. (CPRT)
* Fair Isaac Corporation (FICO)
* Moody's Corporation (MCO)
* UnitedHealth Group (UNH)
* Mastercard (MA)
* Visa (V)
* Adobe (ADBE)
* Lockheed Martin (LMT)",simplevalue,2021-01-03 04:48:05,35,14,0.89
988,">[SoftBank Group](https://www.wsj.com/market-data/quotes/JP/XTKS/9984) Corp. [9984 **1.03%** ](https://www.wsj.com/market-data/quotes/JP/XTKS/9984?mod=chiclets)is nearing a deal to sell British chip designer Arm Holdings to [Nvidia](https://www.wsj.com/market-data/quotes/NVDA) Corp. [NVDA **-1.20%** ](https://www.wsj.com/market-data/quotes/NVDA?mod=chiclets)for more than $40 billion, according to people familiar with the matter, the latest in a series of big asset sales by the Japanese technology conglomerate.  
>  
>The cash-and-stock deal being discussed would value Arm in the low $40 billions, the people said. The terms under discussion would mark a big win for SoftBank, which [bought Arm four years ago for $32 billion](https://www.wsj.com/articles/softbank-agrees-to-buy-arm-holdings-for-more-than-32-billion-1468808434) and had struggled to jump-start growth in the business.  
>  
>Arm and Nvidia have been in exclusive talks for several weeks and a deal could be sealed early next week, the people said — assuming it isn’t derailed at the last minute.  
>  
>Arm designs microprocessors that power most of the world’s smartphones. By joining forces with Nvidia, the combined company would be a powerhouse in the chip industry.   
>  
>Nvidia is a fast-growing industry player whose chips are used to run the intense calculations for graphics—and play a key role in videogaming, cloud-computing and other activities for which [the coronavirus pandemic](https://www.wsj.com/news/collection/coronavirus-6dcf2a21) has stoked demand. That has sent its shares up more than 100% this year, making it the best-performing stock in the S&P 500 index.   
>  
>Should a deal come together, it would be one of the largest transactions so far this year and potentially the largest semiconductor deal ever. Though business disruptions stemming from the pandemic have dented global deal volume, consolidation has kept up pace in the semiconductor industry as chip makers seek scale and expand their product portfolios to support the increasing number of everyday items that are connected to the internet. Such linkage is commonly referred to as the Internet of Things. Another of the year’s biggest deals was [the $22 billion purchase](https://www.wsj.com/articles/analog-devices-in-talks-to-buy-maxim-integrated-for-more-than-17-billion-11594593796) of [Maxim Integrated Products](https://www.wsj.com/market-data/quotes/MXIM) Inc.[MXIM **-0.53%** ](https://www.wsj.com/market-data/quotes/MXIM?mod=chiclets)by fellow chip maker [Analog Devices](https://www.wsj.com/market-data/quotes/ADI) Inc.  
>  
>A sale to Nvidia could prompt scrutiny from antitrust regulators and potentially pushback from Arm’s customers, which include major chip makers and electronics manufacturers such as [Intel](https://www.wsj.com/market-data/quotes/INTC) Corp., [Samsung Electronics](https://www.wsj.com/market-data/quotes/SSNHZ) Co. and [Apple](https://www.wsj.com/market-data/quotes/AAPL) Inc.  
>  
>The Wall Street Journal reported in July that SoftBank was [exploring options for Arm](https://www.wsj.com/articles/softbank-explores-options-for-chip-designer-arm-holdings-11594672437) including a full or partial sale or an IPO. Arm had said it planned to transfer two Internet of Things services units into new entities that would be owned and operated by SoftBank as part of a move to focus on its core semiconductor-Ip business. It later [reversed course on that move](https://www.wsj.com/articles/arm-ltd-halts-spinoff-of-two-internet-of-things-businesses-to-softbank-11598304239), saying it would instead keep the operations in-house.  
>  
>SoftBank, for its part, had been under pressure to shore up its flagging stock price and promised some $40 billion in asset disposals. Most or all of that is already under way or completed and its shares are up more than 20% this year. Among the sales: big chunks of its holdings in China’s Alibaba Group Holding Ltd. and [T-Mobile US](https://www.wsj.com/market-data/quotes/TMUS) Inc. following the wireless provider’s merger with Sprint Corp.  
>  
>SoftBank has also purchased [options tied to around $50 billion worth of individual tech stocks](https://www.wsj.com/articles/softbanks-bet-on-tech-giants-fueled-powerful-market-rally-11599232205) this year. The sheer size of the bet has had an outsize effect on the overall stock market, driving prices higher, the Journal has reported.   
>  
>At SoftBank, Chief Executive Masayoshi Son has been working with a small team to negotiate the Arm deal including the chief executive of the chip company, Simon Segars, Chief Financial Officer Yoshimitsu Goto, as well as Rajeev Misra, CEO of the firm’s giant Vision Fund, and Akshay Naheta, another executive at the fund.",WalterBoudreaux,2020-09-12 17:26:03,114,40,0.99
989,"**PsychoMarket Recap - Thursday, May 27, 2021**

Stocks traded mixed today, with the S&P 500 (SPY) and Dow Jones (DIA) rising while the tech-heavy Nasdaq (QQQ) fell modestly as market participants looked toward the new weekly jobless report. Market participants continue to closely monitor incoming inflation data, though it seems fears that the Federal Reserve will be forced to tighten monetary policy have tempered in recent weeks, with the SPY roughly 3 points away from its record level. 

This week, the indexes have largely consolidated, an encouraging sign following the volatility experienced in the first weeks of May. Market participants continue to look towards incoming economic data to further judge whether inflation will lead to a sustained jump in prices, causing the Federal Reserve to raise interest rates, or be a transitory side-effect as the US economy roars back following the coronavirus-induced recession. Personally, I am in the latter camp and am not concerned about sustained inflation. 

Todd Jablonski, chief investment officer at Principal Global Asset Allocation said, “Inflation has gone from being on no one’s radar screen maybe five years as a lead concern, to now being at the absolute forefront as you see the economy rebound off of COVID lows. There has been a tremendous acceleration in earnings, coupled with massive monetary and fiscal stimulus.”

members of the Federal Open Market Committee (FOMC), reiterated their stance that they were not yet concerned that new inflation data would force the Fed to tighten monetary policy sooner than expected. St. Louis Federal Reserve President James Bullard said he believed increases in inflation would be “mostly temporary” and that the Fed was “not quite there yet” when it came to discussing tapering its asset purchase program. In separate comments, Kansas City Federal Reserve President Esther George said she did not want the Fed to be “overly reliant on historical relationships and dynamics in judging the outlook for inflation.” 

Richard Clarida, Vice Chairman of the Federal Reserve, also said “there will come a time in upcoming meetings” when the Fed would consider tapering the asset purchase program but that “it is going to depend on the flow of data”. The Fed is currently buying $120 billion a month in government-issued and government-backed securities, and has pledged to continue doing that until the economy is more fully recovered.

This reaffirms the market that the Fed is not on a set timeline when it comes to rolling back current accommodative policies and will, as they have said time and again, wait for concrete data before any considerations are made. This follows a similar statement from Jerome Powell back in April 14, which proves market participants shouldn’t worry about quantitative easing tapering, in my opinion. Powell said, “We will reach the time at which we will taper asset purchases when we have made substantial further progress towards our goals from last December. That would in all likelihood be before, well before, the time we would consider raising interest rates. We have not voted on that order but that is the sense of the guidance.”

The Department of Labor’s Weekly Unemployment Report showed jobless claims fell for the fourth straight week to yet another pandemic-era low, an encouraging sign that the labor market is improving following the extremely disappointing April Jobs report, which showed 266,000 new jobs added in the month, far below estimated of more than 1 million and a sharp deceleration in job growth compared to March. 

* **Initial jobless claims, week ended May 22:** 406,000 vs. 425,000 expected and 444,000 the week prior
* **Continuing claims, week ended May 15:** 3.642 million vs. 3.680 million expected and a revised 3.738 the week prior

**Highlights** 

* Boeing (BA) agreed to pay at least $17 million to settle enforcement cases with the Federal Aviation Administration over production issues with its 737 jets. Stock reacted positively to the news. 
* Durable goods orders, or orders for manufactured goods intended to last at least three years, unexpectedly declined in April, ending an 11-month streak of increases, the Commerce Department said Thursday, an encouraging sign. 
* “Meme stocks” are on the move again, with AMC gapping up 40% on the day. Gamestop (GME) and AMC have both been on monster runs this week.
* Paytm, India’s largest digital payment platform, is reportedly aiming to go public later this year with a valuation of $25-$30 billion.
* Shares of Ford (F) have been on fire since the company announced it was making a big investment to manufacture EVs and recently unveiled the all-electric Ford F-150 pickup, one of the company’s most popular models. \\
* Amazon (AMZN), Microsoft (MSFT) and Alphabet (GOOG, GOOGL) are all involved in a bidding process to provide cloud services to Boeing, according to multiple reports. 
* Disney’s (DIS) California-based parks will welcome non-California natives starting June 15.
* **\*\*Please note that current stock price was written in the morning and does not reflect intraday changes\*\***
* Applied Materials (AMAT) with three target raises. Stock currently around $137
   * JP Morgan from $146 to $160
   * Susquehanna from $155 to $170 
   * Mizuho from $155 to $158 
* Burlington Stores (BURL) target raised by Telsey Advisory Group from $320 to $370 at Outperform. Stock currently around $328
* DR Horton (DHI) target raised by Wells Fargo from $110 to $115 at Overweight. Stock currently around $94
* Nvidia (NVDA) with a host of target raises. Average price target $730 at Buy. Stock currently around $628
* Palo Alto Networks (PANW) with two target raises. Stock currently around $368
   * Deustche Bank from $395 to $410 at Buy
   * Northland Securities from $420 to $440
* Restoration Hardware (RH) target raised by Wedbush from $550 to $700 at Outperform. Stock currently around $639
* UnitedHealth Group (UNH) target raised by Truist Securities from $450 to $480 at Buy. Stock currently around $413
* Western Digital (WDC) target raised by Benchmark from $87 to $92 at Buy. Stock currently around $75

“A wise man will make more opportunities than he finds.” - Francis Bacon",psychotrader00,2021-05-27 20:27:00,25,3,0.93
990,"If we know company A is doing right in what it does in the long run. Why would people care about the minor turbulence along the way?  for example, when some news drop or market supply and demand change, a related stock can drop so much. Why would people sell their stock if they believe in the long-term underlying value of the business? If A has a promising future, then isn't it always the lowest point right now in the present compare to the future?

Is most people in the market just trying to make a short-term quick buck rather than holding a stock long-term?

maybe not the best example, lets say Nvidia, they make good chips, and it's safe to assume they will continue to make better chips. In that case, their value will grow and the turbulence and news at the moment don't really matter. (unless they made some very bad decision with super long term consequences)",user_withoutname,2021-05-27 05:38:01,2,6,0.76
992," 

With Nvidia being the creator of the GPU (Graphic Processing Unit), its benefitting from all the recent trends and ones to stay. Their chips are being used by industry leaders Amazon's AWS, Microsoft's Azure Cloud, Alphabet's Google Cloud, International Business Machines' IBM Cloud, and Alibaba Cloud.

Their GPUS are crucial in the success of AI. Everyone is trying to develop their own AI processor but at this point, the GPU is still the go to for both researchers and data centers wanting to run AI and other sophisticated algorithms. For example, it will supply NIO the electric vehicle car company in China with its chips for its newest sedan the ET7.

Another reason why everyone should own Nvidia stock is because of their GRACE CPU. Although Intel holds 90% of the CPU market, their GRACE CPU now will have 10 times the performance of any leading CPU on the market!

Theres more details in the video i made below. Just wanted everyone to be aware of what Nvidia is doing and why it may be worth either having on your watch list or a stock to own. In addition they are also doing a 4 to 1 stock split on July 19th which will make each share valued at roughly $150 according to todays stock price.  
[https://youtu.be/n5alFa4QNm8](https://youtu.be/n5alFa4QNm8)",gagan45678,2021-05-24 21:59:12,0,6,0.42
993,"Full disclosure - made and deployed by myself. Censored the subreddit name because I figured it might be banned here for spam. Nevertheless, this isn't a ""status of that sub"" post, and wanted to share the results of something interesting I did that involves stocks.

&#x200B;

I built an algorithm that tracks mentions and sentiment of stocks across just the WallStreetBets sub (weighted by upvotes, etc.) -- rebalanced monthly. The strategy involves analyzing stocks and conducting sentiment analyses on their mentions to buy or sell. There's a healthy amount of $GME and $AMC, some $SPCE, some $NVDA, and 13 other stocks.

&#x200B;

Right now I'm up 44% YTD, compared to the SP500's 13%.

&#x200B;

Some stats (and a picture of the returns):

&#x200B;

[https://i.imgur.com/hqigfrX.png](https://i.imgur.com/hqigfrX.png)

&#x200B;

\- The strategy is **backtested** only to the beginning of 2020, but I'm working on it. It's got an **annualized return of 26%** (compared to 16% for the SP500)

&#x200B;

\- **Max drawdown** of -8.7% (thought this was pretty interesting - W\*B would be a very cool hedge for financial markets at large. Rode COVID like a wave)

&#x200B;

\- **Sharpe Ratio**: 2.22. Here's an \[investopedia link\]([https://www.investopedia.com/terms/s/sharperatio.asp](https://www.investopedia.com/terms/s/sharperatio.asp)) for those of you that can read

&#x200B;

\- Profit-Loss ratio of 3.48.

&#x200B;

\- Avg win of 0.85%

&#x200B;

\- Avg loss of -0.24%. The fact that this number's absolute value is lower than average win is a good thing

&#x200B;

Anyways, invested around $60k in January myself, I'm at around $90k rn. Not one of my main investment vehicles, and maybe not the smartest investment, but I make myself feel better by telling myself it's smarter than Y\*LOing on puts.

&#x200B;

**Before you comment: I don't style myself some wizard or think that this will really hold up forever. Just thought it was pretty cool and wanted to share.**",billybumpkins,2021-05-23 22:08:39,26,11,0.76
994,"Good Saturday morning to all of you here on r/StockMarket. I hope everyone on this sub made out pretty nicely in the market this past week, and is ready for the new trading week ahead.

Here is everything you need to know to get you ready for the trading week beginning May 24th, 2021.

# **Stocks could be volatile in week ahead amid turbulence from cryptocurrency - [(Source)](https://www.cnbc.com/2021/05/21/stocks-could-be-volatile-in-week-ahead-amid-turbulence-from-cryptocurrency.html)**
*****
> The trading pattern of the past two weeks – particularly alongside cryptocurrency’s movements – suggests stocks could continue to be volatile in the week ahead.
*****
> Investors are watching the wild swings in bitcoin and trying to gauge whether technology shares can gain traction after a rally attempt in the past week.
*****
> The Dow and S&P 500 were lower in the past week, but Nasdaq was slightly higher, helped by a positive move in tech, as well as buying in biotech and big cap growth names like FANG members Alphabet, Facebook and Netflix.
*****
> A steep plunge in bitcoin after China announced new regulations soured the mood for risk assets during the past week. The U.S. also called for stricter compliance with the IRS. Further, on Friday, China said it would crack down on bitcoin mining and trading.
*****
> “What’s interesting is the market is being bullied around by where bitcoin goes,” said Peter Boockvar, chief investment officer with Bleakley Advisory Group. Bitcoin plunged by as much as 30% on Wednesday, to about $30,000. Though it recovered to above $42,000, it slid again on Friday.
*****
> The cryptocurrency was down about 9% late Friday, hovering around $36,000, according to Coin Metrics.
*****
> “Bitcoin is a poster child for risk appetite,” said Boockvar. “It tells you the stock market is more on uneven ground, if we’re getting dragged along by bitcoin.”
*****
> There is some key data in the week ahead. Consumer confidence, home price data and new home sales are out on Tuesday. Durable goods will be released Thursday, and the consumer sentiment report is issued Friday.
*****
> But the most important data will be the personal income and spending data, which includes the personal consumption expenditure price deflator, the Fed’s preferred inflation measure.
*****
> “The key to next week is going to be the inflation numbers. The inflation numbers are now becoming the new payroll numbers in terms of market performance,” said Boockvar. “What will also be interesting is inside the consumer confidence numbers, is where the inflation expectations go.”
*****
> The consumer price index was surprisingly hot when released last week, showing core inflation at a year over year pace of 3% in April. The core PCE price index was up 1.8% year over year in March.
*****
> In the week ahead, earnings season is winding down but there continue to be reports from retailers, like Best Buy, Costco and Nordstrom. NVIDIA and Dell also report.
*****
> # No correction yet
> As the market has chopped around this month, dip buyers have stepped into the declines and snapped up perceived bargains.
*****
> Some strategists do not see a correction just yet, though pullbacks could continue.
*****
> “For me, my framework is we can only get a 10% correction when we have a liquidity set back, when we have a policy tightening,” said Barry Knapp, managing partner of Ironsides Macroeconomics. “In any of the little disturbances, we are getting about a 4% to 6% pullback.
*****
> Knapp said investors are fretting too much about higher interest rates being a problem for technology companies. “You should be in the cyclical parts of tech,” he said. Knapp noted that subsectors like semiconductors and software should do well with the economic reopening and global manufacturing rebound.
*****
> Tech squeaked out a slight gain in the past week, gaining 0.1%, but semiconductors popped nearly 3%. Software was up 0.2%.
*****
> The Nasdaq was 0.3% higher on the week to 13,470, while the Dow was off a half percent at 34,207. The S&P 500 was down 0.4% to 4,155.
*****
> The best performing sector was real estate investment trusts, up 0.9%, followed by health care, up 0.7%. Biotech was higher on the week with the IBB iShares Nasdaq Biotech ETF, up 1.1%.
*****
> “It wouldn’t shock me if we went straight back to new highs,” Knapp said. “Part of the reason I thought we would trade in a range, was earnings season was done but net revisions is surging.”
*****
> He said earnings for the S&P 500 are now expected to be up 7% more for the year than when the first quarter reporting season began.
*****
> Knapp expects the Fed may discuss tapering its bond buying at its Jackson Hole meeting in late summer, and that is the likely trigger for a correction. Back to World War II, he said the first correction after a recession was triggered by the Fed normalizing policy.
*****
> “Last cycle, we had eight of those,” he said. “Every attempt they made to normalize policy caused one of these risk off events.”
*****
> Knapp said it’s natural for investors to be focused on the Fed now. “It’s an uncertainty shock,” he said. “It will cause a correction and everyone is focused on it. The Fed has not really changed its policy since the depths of the pandemic.”
*****
> Knapp said Treasury yields have drifted lower during efforts in Washington to reach a bipartisan plan on infrastructure spending. But he expects the market to react differently in the next two weeks, since he expects those efforts will clearly fail and Democrats will focus on a big spending program that will increase the deficit.
*****
> The bitcoin crypto mania was lifted by the idea of big spending from Washington, and the infrastructure spending could be positive. “The thing that was the surprise in 2021 that really drove the mania was the blue wave and then the spending blowout,” he said, noting bitcoin gained on the potential for inflation and big deficit spending.
*****

# **This past week saw the following moves in the S&P:**
###### **([CLICK HERE FOR THE FULL S&P TREE MAP FOR THE PAST WEEK!](https://i.postimg.cc/SNr7XsYn/finvizmaps1.png))**

# **S&P Sectors for this past week:**
###### **([CLICK HERE FOR THE S&P SECTORS FOR THE PAST WEEK!](https://i.postimg.cc/GtPPx3MS/finvizgroups1.png))**

# **Major Indices for this past week:**
###### **([CLICK HERE FOR THE MAJOR INDICES FOR THE PAST WEEK!](https://i.postimg.cc/ZY6LSjTF/alphatrends1.png))**

# **Major Futures Markets as of Friday's close:**
###### **([CLICK HERE FOR THE MAJOR FUTURES INDICES AS OF FRIDAY!](https://i.postimg.cc/WbjwbrzR/finvizfuts1.png))**

# **Economic Calendar for the Week Ahead:**
###### **([CLICK HERE FOR THE FULL ECONOMIC CALENDAR FOR THE WEEK AHEAD!](https://i.postimg.cc/02qcMFtB/econcal1.png))**

# **Percentage Changes for the Major Indices, WTD, MTD, QTD, YTD as of Friday's close:**
###### **([CLICK HERE FOR THE CHART!](https://i.postimg.cc/Qddgc3c0/marketdata3.png))**

# **S&P Sectors for the Past Week:**
###### **([CLICK HERE FOR THE CHART!](https://i.postimg.cc/cJKQ5B93/spxsectors1.png))**

# **Major Indices Pullback/Correction Levels as of Friday's close:**
###### **([CLICK HERE FOR THE CHART!](https://i.postimg.cc/jS2NLhr1/marketpullbacklevels1.png))**

# **Major Indices Rally Levels as of Friday's close:**
###### **([CLICK HERE FOR THE CHART!](https://i.postimg.cc/dt4rsxgd/marketrallylevels1.png))**

# **Most Anticipated Earnings Releases for this week:**
###### **([CLICK HERE FOR THE CHART!](https://i.imgur.com/Q5m35tO.png))**

# **Here are the upcoming IPO's for this week:**
###### **([CLICK HERE FOR THE CHART!](https://i.postimg.cc/KvrQnfwv/ipos1.png))**

# **Friday's Stock Analyst Upgrades & Downgrades:**
###### **([CLICK HERE FOR THE CHART LINK #1!](https://i.imgur.com/PKIAGRB.png))**
###### **([CLICK HERE FOR THE CHART LINK #2!](https://i.imgur.com/IEcMlNw.png))**

*****

> # Economic Surprise Index Tips Negative For The First Time In A Year

> While the overall trend of economic data has been for further improvement, things have slowed recently relative to expectations. In the charts below, we show the charts of the Citi Economic Surprise indices for the US, Emerging Markets, the Eurozone, and the entire world. Broadly speaking, positive readings indicate that economic data is coming in better than forecasts while negative readings indicate the opposite. Every region of the globe has pulled back over the past couple of months but for the most part, current readings remain at the high end of their historical ranges. In fact, the indices for Emerging Markets, Eurozone, and the whole globe all sit in the top 3% of all readings in their histories. The one place that is not the case is the US. Since last summer, the surprise index has been trending lower off of record levels, and just yesterday, it hit it tipped negative for the first time since June 2nd of last year.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/CESI.png))**

> Lasting 248 trading days, this was the longest streak of consecutive positive readings in the index's history dating back to 2003. The only other streak that lasted nearly as long was a 189 day long one which came to an end in June 2018.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/CESI-1.png))**

*****

> # Post-Election-Year June: Third Worst S&P 500 Month

> June has shone brighter on NASDAQ stocks over the last 50 years as a rule ranking sixth with a 0.9% average gain, up 28 of 50 years. This contributes to NASDAQ’s “Best Eight Months” which ends in June. June ranks near the bottom on the Dow Jones Industrials just above September since 1950 with an average loss of 0.2%. S&P 500 performs similarly poorly, ranking ninth, but essentially flat (0.1% average gain). Small caps also tend to fare well in June. Russell 2000 has averaged 0.8% in the month since 1979.

> In post-election years since 1953, June still ranks poorly and its average loss for DJIA increases to –1.1% while S&P 500′s modestly positive performance becomes a 0.6% loss. DJIA struggles the most, advancing in just four post-election year Junes (1977, 1985, 1997 and 2017). Russell 2000 fares best, up seven times in ten years with an average gain of 1.2%. NASDAQ lands in the middle, advancing 50% of the time with an average gain of 0.4%

> ###### **([CLICK HERE FOR THE CHART!](https://64.media.tumblr.com/baf2bcec363b55b19e25cde2661623df/feae79c5b2f9f78d-88/s400x600/6b9c15c89838e0b90c212cd3faa79d598c7bc187.jpg))**

*****

> # May Manufacturing Starting Off Strong

> The first manufacturing data for May came out this morning with the release of the New York Fed's Empire State Manufacturing Survey. General business conditions remain at historically strong levels although there was some slowing in May as was expected. After hitting the highest level since October 2017 last month, it was expected to fall to 23.9 in May. The index did in fact decline, but only to 24.3. While lower, that is still around some of the strongest levels (excluding last month) in three years as more businesses continue to report improvements in business conditions than weakness.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-Empire-1.png))**

> Breadth in this month's report was pretty mixed; namely with regards to current conditions versus expectations. Every index is still showing an expansionary reading with particular strength out of the indices for the present situation. In fact, most of those indices still sit in the top decile of their historical range with a few like those for unfilled orders, delivery times, and prices even at or just off of record highs. But there were a handful that moved lower: delivery times, inventories, and number of employees.

> Regarding expectations, it was much harder to find an increase. Delivery times and technology spending were the only two of these indices to rise month over month. While many indices for expectations still sit at historically strong levels, there are more that are middling within their respective historical ranges. Overall, the report showed that New York area firms have seen a peak in optimism even as they continue to report strong conditions.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-Empire-Table.png))**

> Demand certainly appears to be one area without much in the way of weakness. New orders rose 2 points month over month to 28.9. That is the highest level in just over 15 years and the only other readings as high occurred throughout late 2003 to mid-2004. Those orders are making their way out the door at an increased rate too as shipments climbed to 29.7. That index has been making a vertical climb since the winter as it reached its highest level since August 2007.

> Despite this, NY area firms are not fulfilling orders fast enough. Last month saw the Unfilled Orders index rise by one of the largest amounts in a single month on record, and it continued to climb albeit by a much smaller 0.2 points in May. The only month on record with a higher reading in unfilled orders was September 2001. Inventories were one of the few current condition indices to fall in May, although the reading still indicated growth. In other words, those unfilled orders are not necessarily drawing down on inventory levels.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-Empire-2.png))**

> Supply chains are one of the main areas that are likely holding things back. Higher readings in the delivery times index mean that businesses are reporting that it takes longer for products to reach their destination. Even after falling 4.5 points in May off of the April record, the current level sits well above the prior record high of 16.2 from March 2018.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-Empire-3.png))**

> In addition to taking longer for products to get to where they are going, the price point is on the rise. Both indices for prices paid and received rose to record highs in May. In fact, over the past two months, there has not been a single respondent to have reported a decrease in prices paid. That is the first time that has occurred since February and March 2012.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-Empire-4.png))**

> Last week saw a blockbuster job openings report and the Empire Fed survey is showing a similar willingness to take on more workers. The current conditions index for the number of employees continues to show that businesses are on net increasing their workforce, though at a slowed pace from April. Additionally, the index is at a much less elevated part of its range (the 81st percentile) relative to other indices within the report, but the much more elevated reading in expectations (98th percentile) would indicate the businesses would like to take on far more workers. That is, there appears to be a bit of a disconnect between the actual number of new hires and businesses' expectations to take on more workers. Potentially as a result of an inability to hire enough workers, the average workweek has continued to climb. At 18.7, the index is at its highest level in a decade.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-Empire-5.png))**

*****

> # Homebuilder Sentiment Holds Steady

> Our new Constitution is now established, everything seems to promise it will be durable; but, in this world, nothing is certain except death and taxes,” Benjamin Franklin

> The national average on a 30 year fixed rate mortgage currently sits around 3.06%, little changed over the past month. Homebuilder sentiment as measured by the NAHB Housing Market Index similarly went unchanged in May staying at 83. Although it has been six months since the record high of 90 without much of a push back up to those record levels, homebuilder sentiment continues to come in well above anything observed prior to the pandemic. Commentary from the NAHB noted that the strong reading on homebuilder confidence is thanks to the low housing inventories, low rates, and strong demand, despite the headwinds of rising costs. While that could have played into the small decline in traffic, future sales did tick higher.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-NAHB-HL.png))**
> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-NAHB-Table.png))**

> Whereas the headline number was flat on the month, readings based on each region saw much more variety. By far the largest move was for the Northeast. Since running back up to the record high back in February, homebuilder sentiment in the Northeast has fallen for three straight months and is now at the lowest level since January. The decline in sentiment in the Northeast is relatively recent. Whereas the region tied its record high earlier this year, the other regions all peaked out in the fall. For the Midwest, the declines have kept coming with 3 point declines in each of the past three months alone. The West and South, on the other hand, have found some respite. The South has ticked higher by 2 points in back-to-back months as it reached the highest level since December. Meanwhile, the West was unchanged at 91 in May.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-NAHB-Region.png))**

> As for homebuilder stocks, the iShares US Home Construction ETF (ITB) had been trading in overbought territory throughout most of the spring but in the past couple of weeks, it has come back down to Earth. Last Wednesday, ITB successfully tested its 50-DMA with a small bounce at the tail end of the week. So far today, it has turned lower alongside the broader market with a 1.35% decline. While that means Friday's close marks a lower high, for the time being, the uptrend is still intact.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/051721-ITB.png))**

*****

> # Increased Caution Across Sentiment Indicators

> The S&P 500 has been holding up at its 50-DMA in the past week while more speculative areas of the market (i.e. crypto) have experienced wild swings. As a result, sentiment on the part of individual investors has not seen much of a move. The American Association of Individual Investors' weekly reading on bullish sentiment was little changed this week climbing half of one percentage point to 37%. Although that was not a large move in the past week, sentiment has taken a big hit over the past month having fallen from well above 50%. In spite of that big drop and even though sentiment is around the lowest levels of the past half-year, the current sentiment level is within one percentage point of the historical average. In other words, optimism is low versus recent history but is very much middling from a longer term perspective.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/052021-AAII-Bull.png))**

> Meanwhile, bearish sentiment fell 0.7 percentage points to 26.3%. Unlike bullish sentiment, that is a bit lower than the historical average of 30.5%

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/052021-AAII-Bear.png))**

> Those corresponding moves meant the bull-bear spread climbed to 10.7 from 9.5 the prior week. Excluding last week, that is still one of the lowest readings since February.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/052021-AAII-Bull-Bear.png))**

> Neutral sentiment has been the star of the show recently. The gain this week was tiny at only 0.2 percentage points, but nonetheless, it marked the fifth consecutive week in which neutral sentiment has risen. At 36.7%, it is now at the highest level since the second week of 2020.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/052021-AAII-Neutral.png))**

> The Investors Intelligence survey of equity newsletter writers took a less optimistic tone this week as bullish sentiment fell 4.1 percentage points to a ten-week low of 54.5%. Bearish sentiment was unchanged at the highest level since the end of March. The survey also questions respondents on whether or not they expect a correction. That reading rose 4.1 percentage points to 28.3% in the biggest one-week uptick since the last week of April when it rose 4.7 percentage points. That leaves the reading at the highest level since the week of March 10th. Before that, you would need to go back to September 23rd to find as high of a reading.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/052021-II-Correction.png))**

> Another sentiment reading that has taken an even more dramatically negative tone lately has been the National Association of Active Investment Managers Exposure Index. This index measures how exposed to equities managers are where readings of 200 would mean they are leveraged long, 100 would be fully invested long, 0 would be neutral, -100 is fully short, and -200 is leveraged short. This week saw the index fall another 2.65 points after a massive 40-point decline last week. That is the lowest level since last March and April of last year. Altogether, while sentiment still favors bulls, there has been a more cautious tone that has been reflected in managers reducing exposure to equities. Click here to view Bespoke's premium membership options for our best research available.

> ###### **([CLICK HERE FOR THE CHART!](https://media.bespokepremium.com/uploads/2021/05/052021-NAAIM.png))**

*****

# **STOCK MARKET VIDEO: Stock Market Analysis Video for Week Ending May 21st, 2021** 
###### **([CLICK HERE FOR THE YOUTUBE VIDEO!](https://www.youtube.com/watch?v=Z_tS1h2lZeo))**

# **STOCK MARKET VIDEO: ShadowTrader Video Weekly 5.23.21**
###### **([CLICK HERE FOR THE YOUTUBE VIDEO!]())**
(NONE FOR THIS WEEK.)

*****

Here are the most notable companies (tickers) reporting earnings in this upcoming trading week ahead-

*****

> * **(T.B.A. THIS WEEKEND.)**

*****

###### **([CLICK HERE FOR NEXT WEEK'S MOST NOTABLE EARNINGS RELEASES!](https://i.imgur.com/Q5m35tO.png))**
###### **([CLICK HERE FOR NEXT WEEK'S HIGHEST VOLATILITY EARNINGS RELEASES!](https://i.imgur.com/TKfp5UF.png))**
###### **([CLICK HERE FOR THE MOST ANTICIPATED EARNINGS RELEASES BEFORE MONDAY'S MARKET OPEN!]())**
(N/A.)


*****

Below are some of the notable companies coming out with earnings releases this upcoming trading week ahead which includes the date/time of release & consensus estimates courtesy of Earnings Whispers:

*****

> # ***Monday 5.24.21 Before Market Open:***
> ###### ([CLICK HERE FOR MONDAY'S PRE-MARKET EARNINGS TIME & ESTIMATES LINK!](https://i.imgur.com/pB6x6U1.png))

> # ***Monday 5.24.21 After Market Close:*** 
> ###### ([CLICK HERE FOR MONDAY'S AFTER-MARKET EARNINGS TIME & ESTIMATES LINK!](https://i.imgur.com/Mosaz4I.png))

*****

> # ***Tuesday  5.25.21 Before Market Open:***
> ###### ([CLICK HERE FOR TUESDAY'S PRE-MARKET EARNINGS TIME & ESTIMATES!](https://i.imgur.com/d3fhtyA.png))

> # ***Tuesday 5.25.21 After Market Close:*** 
> ###### ([CLICK HERE FOR TUESDAY'S AFTER-MARKET EARNINGS TIME & ESTIMATES!](https://i.imgur.com/bYKrdSM.png))

*****

> # ***Wednesday 5.26.21 Before Market Open:*** 
> ###### ([CLICK HERE FOR WEDNESDAY'S PRE-MARKET EARNINGS TIME & ESTIMATES!](https://i.imgur.com/8DhtY1V.png))

> # ***Wednesday 5.26.21 After Market Close:*** 
> ###### ([CLICK HERE FOR WEDNESDAY'S AFTER-MARKET EARNINGS TIME & ESTIMATES!](https://i.imgur.com/EORqeZb.png))

*****

> # ***Thursday 5.27.21 Before Market Open:*** 
> ###### ([CLICK HERE FOR THURSDAY'S PRE-MARKET EARNINGS TIME & ESTIMATES!](https://i.imgur.com/j76bD3l.png))

> # ***Thursday 5.27.21 After Market Close:*** 
> ###### ([CLICK HERE FOR THURSDAY'S AFTER-MARKET EARNINGS TIME & ESTIMATES LINK!](https://i.imgur.com/WeDwv7n.png))

*****

> # ***Friday 5.28.21 Before Market Open:*** 
> ###### ([CLICK HERE FOR FRIDAY'S PRE-MARKET EARNINGS TIME & ESTIMATES LINK!](https://i.imgur.com/9sP6ZBz.png))

*****

> # ***Friday 5.28.21 After Market Close:***
> ###### ([CLICK HERE FOR FRIDAY'S AFTER-MARKET EARNINGS TIME & ESTIMATES!]())
(NONE.)

*****

# DISCUSS!

What are you all watching for in this upcoming trading week?

*****

> # (T.B.A. THIS WEEKEND.)
**(T.B.A. THIS WEEKEND.)** (T.B.A. THIS WEEKEND.).

> #([CLICK HERE FOR THE CHART!](http://elite.finviz.com/chart.ashx?t=SPY&ty=c&ta=st_c,sch_200p,sma_50,sma_200,sma_20,sma_100,bb_20_2,rsi_b_14,macd_b_12_26_9,stofu_b_14_3_3&p=d&s=l))

*****

I hope you all have a wonderful weekend and a great trading week ahead r/StockMarket.",bigbear0083,2021-05-22 10:54:16,10,3,0.82
995,"**PsychoMarket Recap - Friday, May 21, 2021**

Stocks traded mixed today, with the S&P 500 (SPY) and Nasdaq (QQQ) declining modestly after yesterday’s rally. It’s encouraging to see the market holding on to yesterday’s gains following the volatility experienced in recent weeks. It seems overall market sentiment is improving following a surge in inflationary fears after the release of the April Consumer Price Index. The SPY closed 0.08% down, the QQQ closed 0.56% down, and the Dow Jones (DIA) closed 0.36% up.

Markets have recently been shaken by the prospect that a rise in inflation may prompt the Federal Reserve to tighten monetary policy sooner than expected. However, as has been reiterated in the recap before, there are several reasons why a change in monetary policy seems very unlikely. In the Federal Reserve’s April meeting minutes, “participants generally noted that the economy remained far from the Committee’s maximum-employment and price-stability goals”.  Jerome Powell and other monetary officials have reiterated several times that they want to see a “string” of strong labor reports before major adjustments to policy are considered. The April Job Reports showed only 266,000 jobs added back to the economy, widely missing analyst expectations and marking a sharp deceleration in job growth from March, bolsters that argument.

As the US economy reopens, we are seeing a surge in consumer spending (we saw a 10.8% increase in spending in March), supply is having a hard time catching up to rising demand, which of course, causes a rise in prices. As the economic reopening continues and supply in various consumer industries is able to catch up, inflation is expected to slow down. In a nutshell, this is why Jerome Powell and other monetary officials consistently refer to current inflationary pressures “transitory”.

On a slightly sour note, the meeting minutes also noted “a number of participants suggested” that as the economy continues to quickly, “it might be appropriate at some point in upcoming meetings to begin discussing a plan for adjusting the pace of asset purchase”, which have currently been going at a rate of $120 billion per month. However, this is not a surprising statement and one Powell himself has said before. Back in an April 14 meeting, Powell said, “We will reach the time at which we will taper asset purchases when we have made substantial further progress towards our goals from last December. That would in all likelihood be before, well before, the time we would consider raising interest rates. We have not voted on that order but that is the sense of the guidance.” As a reminder, quantitative easing is a process in which the Fed buys government bonds in order to inject money into the economy. It is only natural that as the economy recovers, less money needs to be injected into the economy in this manner. The Federal Reserve gave absolutely no signal it was even considering beginning discussion on raising interest rates, which is what market participants are really concerned about. [Read the entire meeting minutes here](https://www.federalreserve.gov/monetarypolicy/files/fomcminutes20210428.pdf)

**Highlights**

* Shares of Nvidia (NVDA), one of the leading semiconductor companies, jumped after the company announced a 4-1 split. This means that after the split goes through, every share of  NVDA will become 4 and the price will adjust accordingly.
* In the midst of surging prices, the housing market has begun showing signs of slowing down. Today, the National Association of Realtors showed that existing home sales fell 2.7% in April compared to the month prior. That is well below the expectation of 1% growth and may be a sign the rise in prices may be slowing in the near-term. However, compared to April 2020, existing home sales are up 33.9%.
* Snap (SNAP) said it will acquire WaveOptics, a British Augmented Reality company, for over $500 million. The company has recently been making a big push into the world of wearable AR technology.
* China's internet watchdog said on Friday that companies including ByteDance, Baidu, and Microsoft (MSFT) improperly collected user data in the country.
* Yesterday, the US Department of Treasury announced it was taking steps to crackdown on digital assets by requiring any transfer worth $10,000 or more to be reported to the Internal Revenue Service (IRS)
* China’s Financial Stability and Development Commission, which is chaired by Vice Premier Liu He, released a statement today saying it is necessary to “crack down on digital asset mining and trading behavior and resolutely prevent the transmission of individual risks to the social field.”

“All our dreams can come true, if we have the courage to pursue them.” - Walt Disney",psychotrader00,2021-05-21 21:03:24,12,2,0.89
997,"It's no surprise that these semiconductors have done well over the past few years. Although these companies will have mild corrections, I think it's safe to say they will have a big impact on the technology driven future. 

With that said, I'd like to get peoples opinions on the pros and cons of each of these companies. 

What products do they offer?

How is one better than the other?

Will the function/price ratios of their product be cyclic or will there be a clear winner?

Just to bring up a few.

Here is some quick information on these companies:

**NVDA**: Company focuses on GPUs. Has a great GPU for both gaming and crypto. GPUs thrive in crypto and Neural Networks (AI).

MC\~350B, EV/EBITDA\~60, low debt, good growth

**AMD:** Has made a huge push in the CPU niche and has gained popularity with the gamers. Their CPUs are valued at the best function/price ratio. Pretty sure they are working on a promising GPU.

MC\~90B, EV/EBITDA\~40, low debt, good growth

**INTC:** The most experience and clout in the industry. Look around you, you'll probably see an intel sticker. Recent restructure of company with seems promising. Heavy in the DB and cloud niche which will be massive in the future (and currently is). Also, working on GPUs, not sure on the progress.

MC\~223, EV/EBITDA\~6.7, debt, could have less, good growth

&#x200B;

At first glance the cheapest to most expensive from a valuation standpoint looks as followed INTC, AMD, NVDA, respectively. 

Looking forward to the responses!",Revolutionary-Cry-38,2021-05-20 02:41:26,7,17,0.82
998,"**PsychoMarket Recap - Wednesday, May 19, 2021**

The stock market opened deep in the red but managed to climb throughout the session to pare much of the losses. For example, the Nasdaq (QQQ) opened 1.73% down but managed to close the day 0.12% up. Despite the market declining modestly the last three days, it is encouraging to see volatility decreasing this week  after the wild swings the market experienced in the last few weeks. As said before, I thought the initial sell-off after the April Consumer Price Index was released was overblown for several reasons and am encouraged by this week’s price action.  

Leadership in equity markets has see-sawed between cyclical and value stocks and technology stocks, as market participants weigh the prospects for a strong economic rebound as the US economy continues to reopen with the possibility that the pick-up in activity may generate a surge in inflation. After leading the market higher in April, in the last month, the Nasdaq is down 4.77% compared to 0.79% down in the S&P 500. In my view, this dip could represent a great opportunity given earnings have been extremely strong and many companies have significantly raised guidance moving forward. 

The Federal Reserve released its April Meeting Minutes (basically a written record of what happened in the meeting), which said that “participants generally noted that the economy remained far from the Committee’s maximum-employment and price-stability goals” and reiterated, for like the millionth time, that they did not believe a near-term adjustment of monetary policy was needed. Much of the recent volatility in the market is due to investors afraid that a surge in inflation may cause the Federal Reserve to tighten monetary policy, so hopefully this commentary by the Fed can calm things down. [Read the entire meeting minutes here](https://www.federalreserve.gov/monetarypolicy/files/fomcminutes20210428.pdf)

However, it is important to note, the minutes covered the meeting before the release of the April Jobs Report, which came in much weaker than expected (which bolsters the Fed’s argument that employment remains far from their goal) and the Consumer Price Index, which showed a greater-than-expected increase in consumer prices. That said, the recent reports are extremely unlikely to change the Fed’s view given Powell and other monetary officials have said they expect any inflation to be “transitory” and want to see a “string” of strong labor reports before adjustments to the current policy are considered.

As the US economy reopens, we are seeing a surge in consumer spending (we saw a 10.8% increase in spending in March), supply is having a hard time catching up to rising demand, which of course, causes a rise in prices. As the economic reopening continues and supply in various consumer industries is able to catch up, inflation is expected to slow down. In a nutshell, this is why Jerome Powell and other monetary officials consistently refer to current inflationary pressures “transitory”. In an April 28 meeting, Jerome Powell said, “Amid progress on vaccinations and strong policy support, indicators of economic activity and employment have strengthened. Inflation has risen, largely reflecting transitory factors. Overall financial conditions remain accommodative, in part reflecting policy measures to support the economy and the flow of credit to U.S. households and businesses.” 

Moreover, it is important to note that Federal Reserve Chair Jerome Powell has consistently reiterated he expects any rise in inflation to be “transitory” as the economy continues to recover from the March and bottom and want to see a “string” of strong labor reports totaling 1 million before. Talking about the March Job report, Powell said, “We want to see a string of months like that \[like in March\] so we can really begin to show progress toward our goals. We just need to keep reminding ourselves that even though some parts of the economy are starting just great, there’s a very large group of people who are not.” Finally, the April Job Report, which showed the economy gained only 266,000 jobs compared to the 1 million expected and marked a sharp deceleration in growth compared to March, bolsters Powell’s argument that large segments that the Federal Reserve will move slowly in changing policy. 

**Highlights**

* After declining in recent weeks, the sell-off in cryptocurrencies across the board intensified, with Bitcoin (BTC) falling below $40,000 after the People Bank of China (PBOC) doubled down on it’s stance and released a statement reiterating that digital tokens shouldn’t be used for transactions. The PBOC posted in their official WeChat account, “Virtual currencies should not and cannot be used in the market because they’re not real currencies”. It’s important to note the statement doesn’t have any new regulatory steps, according to Yu Lingqu, a vice director at the China Development Institute think-tank in Shenzhen. 
* Ford Motor (F) is expected to unveil an all-electric version of its bestselling F-150 pickup truck tonight
* The US dollar dipped on Tuesday for the fifth straight session, reaching its lowest level against a basket of currencies since late February on waning fears that inflation spikes could prompt the Federal Reserve to raise interest rates sooner than anticipated, another great sign that inflationary fears are overblown. 
* Nvidia (NVDA) is extending its cryptocurrency mining limits to newly manufactured GeForce RTX 3080, RTX 3070, and RTX 3060 Ti graphics cards. After nerfing the hash rates of the RTX 3060 for its launch in February, Nvidia is now starting to label new cards with a “Lite Hash Rate” or “LHR '' identifier to let potential customers know the cards will be restricted for mining. NVDA offers a separate, specialized mining processor that has the best performance for mining but will not be able to handle graphics. 
* In a Ford factory in Michigan, President Biden promoted his $174 billion plan to promote and accelerate the adoption of electric vehicles across the United States and planned to roll-back vehicle emission standards. According to the fact sheet, Biden's plan ""proposes cost-sharing grants to support new high capacity battery facilities in the United States” and backs grants to fund the retooling of shuttered factories ""to build advanced vehicles and parts.""
* Michael Burry, the investor famous for calling the 2008 housing market bubble and portrayed by Christian Bale in the movie “The Big Short”, recently unveiled a huge bearish bet on Tesla. Scion Asset Management, Burry’s firm, said in a regulatory filing it had put options on 800,100 shares of Tesla, as of the end of Quarter 1, a value of $534 million. Details on the strike price of the puts, their value and whether they are part of a broader trade are not publicly available.
* Interestingly, Berkshire Hathaway (BRK.B) has sold nearly all of its Wells Fargo (WFC) stock, a position the company has held since 1989. In a regulatory filing on Monday, Berkshire said it owned just $26.4 million of shares of WFC as of March 31, down from around $32 billion in January 2018.
* **\*\*Please note that current stock price was written premarket and does not reflect intraday movement\*\***
* L Brands (LB) target raised by Barclays from $66 to $82 at Equal-Weight. Stock currently around $68
* Him & Hers Health (HIMS) target raised by Citigroup from $16 to $20 at Buy. Stock currently around $10.60
* CVS Health (CVS) with various target raises. Stock currently around $89
   * Barclays from $92 to $100 at Overweight
   * Wolfe Research from $82 to $93 at Outperform
   * BMO Capital Markets from $90 to $96 at Market Perform
* AutoZone (AZO) target raised by Wells Fargo (WFC) from $1600 to $1700 at Overweight. Stock currently around $1465
* General Electric (GE) target raised by Barclays from $15 to $16 at Overweight. Stock currently around $13
* FMC target raised by Wells Fargo from $131 to $133 at Overweight. Stock currently around $117
* Walmart (WMT) with a host of target raises after the company reported better-than-expected earnings. Average price target of $173 at Buy. Stock currently around $141
* Home Depot (HD) with a host of target raises after the company beat earnings estimates. Average price target $347 at Outperform. Stock currently around $314
* Domino’s Pizza (DPZ) target raised by Robert W Baird from $455 to $485 at Outperform. Stock currently around $432

“Luck is what happens when preparation meets opportunity.” ―Seneca",psychotrader00,2021-05-19 20:55:50,19,0,0.96
999,"**This is not an attack. This is not cynicism. This is a genuine discussion. I am here to learn and I'm open to changing my mind and hearing opposing views.**

I've been hearing the same argument since early 2019. ""When the tech bubble pops... bla bla bla... so don't go all in on tech stocks"". Yet here we are. Tech stocks are stronger than ever. What strong indication is there that tech stocks will just suddenly pop and the rest of the market will be stronger than them? I'm talking long term.

Perhaps it's time to face our new reality and accept the fact that we live in a highly technological society where everything to a huge degree depends on tech.

Now I don't mean every tech stock is the same. I'm talking about big names. I'm saying that one can outperform S&P500 by going all in on big tech stocks or just investing in only-tech ETFs.

I for one simply cannot see Apple, Amazon, Google, Facebook, Nvidia, Microsoft, etc. going anywhere anytime soon. And for that very reason I don't see anything wrong going all in on those stocks.

Once again, I'm talking LONG TERM (5+ years).

Bottom line is: pick a few tech stocks (trustworthy names such as Facebook, Apple, Nvidia, Alphabet, Microsoft) OR pick a good tech ETF OR if you feel adventurous pick a leveraged ETF (NYSE:FANG+, FNGU, etc.) and forget about S&P500 and other sectors.

**This is not financial advice.** This is not a suggestion. DYOR. I am NOT recommending anyone to buy or sell anything. This is NOT portfolio advice. This is **O N L Y** a discussion and I want to be proven wrong because **I know I'm biased** and believe in tech stocks too much. I just feel that tech is here to stay and it will be stronger by day (VR/AR, blockchain-dependent tech, many other things coming up that will be massive over time).",egobamyasi,2021-05-16 22:20:34,253,86,0.93
1000,"https://preview.redd.it/wck74wobywx61.png?width=953&format=png&auto=webp&s=379cada9e49b7e70a90f835a654e2b7a832db7b5

Hey Community !!!!

In previous post I just wanted you to be aware of float within the company and wanted to make sure you don't miss this opportunity, while in meantime a current and full DD done on company and its holders. my original post was at around 2.90 and originally it was posted in r/pennystocks also. after it has run up the next day in pre market and we had this massive market flash sell off.

&#x200B;

First lets get some basics out of the way ; 

**Alfi, Inc. provides interactive intelligent artificial intelligence and machine learning software solutions. Alfi, Inc. was formerly known as Lectrefy, Inc. and changed its name to Alfi, Inc. in January 2020. The company was founded in 2018 and is based in Miami Beach, Florida.**

* Market Cap - **43M**
* Founded - **2018**
* Currently Price - **$4.41**
* Original IPO price was **$5-7**
* **3M shares float**
* **13D filling on 7th of May 2021 ( 3 insiders currently hold 63%)**
* **Noticeable Partners - Nvidia, AT&T, Lenovo, Google, AWS (Amazon).**
* **Lee Aerospace bought 4.3M Shares ---->** [Sec filling](https://secfilings.nasdaq.com/filingFrameset.asp?FilingID=14937171&RcvdDate=5/7/2021&CoName=ALFI,%20INC.&FormType=SC%2013D&View=html)
* **Nelson Mullins Riley & Scarborough LLP bought 3.1M shares ---->** [Sec filling for 1.7M](https://secfilings.nasdaq.com/filingFrameset.asp?FilingID=14937156&RcvdDate=5/7/2021&CoName=ALFI,%20INC.&FormType=SC%2013D&View=html)   
* [Sec filling for 1.4M](https://secfilings.nasdaq.com/filingFrameset.asp?FilingID=14937145&RcvdDate=5/7/2021&CoName=ALFI,%20INC.&FormType=SC%2013D&View=html)

**Dr. Paul Antonio Pereira, DBA**

Statement taken from his LinkedIn account and his business idea and plan behind ALFI **(Alfi vs Uber)**

Imagine a company like Uber with a market cap of $75 bb. Never made a profit and in a heap of problems with their drivers. 

Yeah, Uber does not own the cars and have an app to control everything. But right there is their problem. The 20% revenue share is just not cutting it and maybe when they migrate to remote control bikes and self driving cars Uber will make a profit by eliminating the biggest factors in their equation. Small profit share and third party equipment.

Let’s compare Alfi. You can test drive Alfi and we remotely control everything. The user experience, the reporting, the payments etc. We own the hardware and software so have full scope in the evolving user experience. No third party drivers and anybody to tell us how it's done. Now here is the best part. We take the lion share of revenue with 80 % even after all the commission and incentives are paid. 

So, if Uber can build a business model with no profitability in sight and use third party equipment, the cars and driver's and still raise billions then what can we say for Alfi??

Alfi’s business model is well defined. The drive/user experience is remotely controlled from HQ and the hardware/vehicles/tablets are all owned by Alfi and similar to Uber when they eventually migrate to self-driving cars.

Alfi's market is huge and growing at double digits every year.

&#x200B;

https://preview.redd.it/j720m5a1cxx61.jpg?width=640&format=pjpg&auto=webp&s=0afca55688a484fc02cadd39861a47d5c4a87b61

Now imagine scaling Alfi globally with our self-driving tablets and remotely controlled machine models. I wonder what that would look like? Well Alfi’s model is very specific and our path to profitability delineated. For every Alfi we generate $30 per day. For a 1,000 tablets it adds up to $12 mm per year and 100,000 tablets will be $1.2 Billion per year. Now here is the best part. We run with extremely robust net income margins relating to $1 billion in net profit per year.

But wait. It does not end here. Alfi’s model continues to scale because Alfi is translated in any language and applicable in any industry with “Waiting Time”. 

So imagine what Alfi looks like with 1 million tablets distributed worldwide.

&#x200B;

#    Alfi's ""Covid Ready Partition Kits""​ for Taxis in the UK and EU.

&#x200B;

https://preview.redd.it/nuvcwitgcxx61.jpg?width=715&format=pjpg&auto=webp&s=0d1185f362361cad315e24c260b71b40e807b5df

Alfi is playing their part providing free of charge polycarbonate divider kits for taxi cabs in Northern Ireland and the UK. With growing concern over the Covid 19 pandemic and what the ""New Normal"" looks like, many taxi drivers are left to their own means to find solutions for safely transporting passengers. Some ride shares such as Uber are insisting on passengers wearing masks but there is no way of enforcing this. Others are left to their own means and have implemented homemade plastic solutions that look horrible and make passengers feel as if they are sitting in a plastic bag. 

Alfi's team came up with a practical solution supplying hard coated aviation grade polycarbonate dividers preinstalled with the Alfi digital screens mounted on the dividers. 

This practical solution not only protects the passengers and the driver but provides the passengers with a concierge service showcasing their route and places of interest, bars and restaurants that are open and allowing business owners to get their messages to the passengers as they travel in proximity to their location.

In addition, Alfi's powerful computer vision machine learning models are capable of providing much needed COVID metrics for visual signs of the virus and creating hotspots by location of each incident.

&#x200B;

**Full investors presentation is available on their website !!!!!!!!!!!!!!!!!!!!**  <--**MAKE SURE TO READ**

#    HERE IS WHAT WE TAKE FROM ALL OF THIS INFORMATION.

&#x200B;

* Alfi research & development completed.
* Alfi will be making revenue as early as Q4 2021
* IPO proceeds will be used for commercilization
* Targeting a 100,000 ride-share network by 2025
* Establish Sales/Call/ Service Centre

**SaaS clients currently in proccess** 

1. NEOH Brazil 
2. BWI
3. Hammersmith Malls
4. AEO
5. Vinci Airports
6. SGI Mexico (Paul Mitchel Salons)

Most of revenue for Alfi will come through Q4 2021, however in Q2 there will still be revenue coming in also. Please check image attached below to check where this income will come from.

&#x200B;

https://preview.redd.it/87nj0n8kgxx61.jpg?width=1313&format=pjpg&auto=webp&s=c30eeec2a3df341aee799f75f003f04b8acded29

Finally to finish on this information. At this moment two big competitors are Facebook and Google on advertising, however unlike ALFI both of those companies share customers data instead of keeping it anonymous and we already know how many times both Google and Facebook been in newspapers for sharing information without customer consent.

No cookies.

No personal data or information.

no stored facial images.

&#x200B;

https://preview.redd.it/ol5z6qnthxx61.jpg?width=973&format=pjpg&auto=webp&s=91a2bcdd687b1d106776af6fff9a8f702085527d

&#x200B;

**In 30 days  Alfi tablet has potential to generate $93k just in a taxi alone. the potential of this company is crazy and the team behind have taken small company to billions value companies before.** 

**I see ALFI worth 10x more of its current value with real revenue generation starting by years end.**

&#x200B;

#                    Monday comes YOU KNOW WHAT TO DO.$ALF

#                  ALSO LETS NOT FORGET ALFI !!!! HE IS WITH US !!!

https://preview.redd.it/99wivfx8ywx61.jpg?width=225&format=pjpg&auto=webp&s=2dd398c70b3a078944ca1f300c8a426d1ef97bc6",Donisxb,2021-05-08 17:25:47,13,12,0.81
1001,"New IPO original price $4-7 dollars but got listed in last few days which was probably worst day to be listed on with market sale off.

Alfi is an AI enterprise SaaS platform powering computer vision with machine learning models, and deep learning to deliver the right content, to the right person at the right time in a respectful and ethical manner.

&#x200B;

$ALF working with NVIDIA, AT&T and many more which you can check on their website. 

&#x200B;

this stock has potential to quadruple because of its tiny float like many other stocks where it shoots up to 10-30 just because of its float while there is no offerings or anything like that so get in. CEO of company is previous CEO in past of stock $DNMR who also to sent from $4 dollars to $60 because of its low float and you can check that yourself.

&#x200B;

market cap 39m

only 3m float which means any buying sends the stock up",Donisxb,2021-05-06 07:57:37,22,44,0.88
1002,"
Hello, sorry if this comes off as ignorant as I’m new to this. 

For basic ml use on python for a stock indicator, and perhaps eventually low frequent trading(very low, maximum of ~20 swing orders/week), which one should I go with? 

I initially wanted to go with Raspberry as that’s all I knew and for the cheap price but I found the Jetson to be a strong consideration as it is marketed for AI learning. 

Thanks",MajorSTDHolder,2021-04-02 17:09:18,9,16,0.91
