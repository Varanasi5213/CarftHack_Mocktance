{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_STOCK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7aSfzVdgegN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiHq0X8Gi3xI"
      },
      "source": [
        "df=pd.read_csv(\"NVIDIA_Stock.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJVekoAcjo10",
        "outputId": "3bb58b96-d469-4f51-f5f0-98aaec96d590"
      },
      "source": [
        "df = df[list(df)[-11:]]\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(260, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRwkoPNhj-gv"
      },
      "source": [
        "n_past = 10\n",
        "n_future = 5 \n",
        "n_features = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfZoecZBkJNy",
        "outputId": "6d05ce8f-491a-4a65-e8c6-1de0e5ab0422"
      },
      "source": [
        "260*.75"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ldst4pkkEmK",
        "outputId": "dfd7a6c9-386c-4ff0-98fe-b10d45067a68"
      },
      "source": [
        "train_df,test_df = df[0:195], df[195:]  # 75% and 25%\n",
        "train_df.shape,test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((195, 11), (65, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0L8B4ewnVIC"
      },
      "source": [
        "train = train_df\n",
        "test = test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vT71ItMkV7C"
      },
      "source": [
        "def split_series(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations\n",
        "  #\n",
        "  # n_future ==> no of future observations \n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNElGOMdkZJl"
      },
      "source": [
        "X_train, y_train = split_series(train.values,n_past, n_future)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
        "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
        "\n",
        "X_test, y_test = split_series(test.values,n_past, n_future)\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
        "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG_4XURNkam-",
        "outputId": "7c44410d-719b-4447-b558-953b7cf95368"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 10, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI4zXuarkeHE",
        "outputId": "b5ec49e9-0d41-4f7c-cfb8-8ea7c1783ab8"
      },
      "source": [
        "# E2D2\n",
        "# n_features ==> no of features at each timestep in the data.\n",
        "#\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = tf.keras.layers.LSTM(512,return_sequences = True, return_state=True)\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 = tf.keras.layers.LSTM(512, return_state=True)\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "#\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "#\n",
        "decoder_l1 = tf.keras.layers.LSTM(512, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 = tf.keras.layers.LSTM(512, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
        "#\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "#\n",
        "model_e2d2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 10, 11)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  [(None, 10, 512), (N 1073152     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  [(None, 512), (None, 2099200     lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_3 (RepeatVector)  (None, 5, 512)       0           lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  (None, 5, 512)       2099200     repeat_vector_3[0][0]            \n",
            "                                                                 lstm_11[0][1]                    \n",
            "                                                                 lstm_11[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  (None, 5, 512)       2099200     lstm_13[0][0]                    \n",
            "                                                                 lstm_12[0][1]                    \n",
            "                                                                 lstm_12[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 5, 11)        5643        lstm_14[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,376,395\n",
            "Trainable params: 7,376,395\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmeOIy2BkjRx",
        "outputId": "ced9263e-29f5-4a61-dbb7-49878d0632a6"
      },
      "source": [
        "#reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
        "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=700,validation_data=(X_test,y_test),batch_size=32,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/700\n",
            "6/6 [==============================] - 10s 798ms/step - loss: 299.0763 - val_loss: 215.4418\n",
            "Epoch 2/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 295.2372 - val_loss: 213.3658\n",
            "Epoch 3/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 293.7525 - val_loss: 211.9187\n",
            "Epoch 4/700\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 292.4993 - val_loss: 210.4999\n",
            "Epoch 5/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 291.2738 - val_loss: 209.1811\n",
            "Epoch 6/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 290.0666 - val_loss: 207.8293\n",
            "Epoch 7/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 288.8473 - val_loss: 206.4690\n",
            "Epoch 8/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 287.6396 - val_loss: 205.1081\n",
            "Epoch 9/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 286.4433 - val_loss: 203.7445\n",
            "Epoch 10/700\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 285.2519 - val_loss: 202.3941\n",
            "Epoch 11/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 284.0574 - val_loss: 201.0526\n",
            "Epoch 12/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 282.8737 - val_loss: 199.7243\n",
            "Epoch 13/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 281.6893 - val_loss: 198.3861\n",
            "Epoch 14/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 280.5076 - val_loss: 197.1038\n",
            "Epoch 15/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 279.3615 - val_loss: 196.0043\n",
            "Epoch 16/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 278.2186 - val_loss: 194.8402\n",
            "Epoch 17/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 277.0778 - val_loss: 193.7265\n",
            "Epoch 18/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 275.9540 - val_loss: 192.5864\n",
            "Epoch 19/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 274.8083 - val_loss: 191.3967\n",
            "Epoch 20/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 273.6798 - val_loss: 190.3015\n",
            "Epoch 21/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 272.5496 - val_loss: 189.1420\n",
            "Epoch 22/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 271.4113 - val_loss: 188.0258\n",
            "Epoch 23/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 270.2932 - val_loss: 186.8887\n",
            "Epoch 24/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 269.1550 - val_loss: 185.7682\n",
            "Epoch 25/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 268.0281 - val_loss: 184.5988\n",
            "Epoch 26/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 266.9002 - val_loss: 183.4990\n",
            "Epoch 27/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 265.7712 - val_loss: 182.3571\n",
            "Epoch 28/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 264.6390 - val_loss: 181.2372\n",
            "Epoch 29/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 263.5039 - val_loss: 180.1082\n",
            "Epoch 30/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 262.3779 - val_loss: 178.9726\n",
            "Epoch 31/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 261.2549 - val_loss: 177.8441\n",
            "Epoch 32/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 260.1257 - val_loss: 176.7054\n",
            "Epoch 33/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 258.9985 - val_loss: 175.6225\n",
            "Epoch 34/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 257.8784 - val_loss: 174.4619\n",
            "Epoch 35/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 256.7549 - val_loss: 173.3488\n",
            "Epoch 36/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 255.6288 - val_loss: 172.2053\n",
            "Epoch 37/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 254.5023 - val_loss: 171.0984\n",
            "Epoch 38/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 253.3889 - val_loss: 169.9658\n",
            "Epoch 39/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 252.2606 - val_loss: 168.8544\n",
            "Epoch 40/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 251.1389 - val_loss: 167.7199\n",
            "Epoch 41/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 250.0273 - val_loss: 166.6235\n",
            "Epoch 42/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 248.9230 - val_loss: 165.4921\n",
            "Epoch 43/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 247.7983 - val_loss: 164.3733\n",
            "Epoch 44/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 246.6885 - val_loss: 163.2511\n",
            "Epoch 45/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 245.5624 - val_loss: 162.1232\n",
            "Epoch 46/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 244.4373 - val_loss: 161.0061\n",
            "Epoch 47/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 243.3201 - val_loss: 159.9055\n",
            "Epoch 48/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 242.1977 - val_loss: 158.7562\n",
            "Epoch 49/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 241.0788 - val_loss: 157.6544\n",
            "Epoch 50/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 239.9605 - val_loss: 156.5422\n",
            "Epoch 51/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 238.8536 - val_loss: 155.4255\n",
            "Epoch 52/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 237.7325 - val_loss: 154.2987\n",
            "Epoch 53/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 236.6175 - val_loss: 153.2136\n",
            "Epoch 54/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 235.5009 - val_loss: 152.0719\n",
            "Epoch 55/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 234.3910 - val_loss: 150.9590\n",
            "Epoch 56/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 233.2761 - val_loss: 149.8604\n",
            "Epoch 57/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 232.1785 - val_loss: 148.7170\n",
            "Epoch 58/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 231.0516 - val_loss: 147.6225\n",
            "Epoch 59/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 229.9308 - val_loss: 146.4808\n",
            "Epoch 60/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 228.8076 - val_loss: 145.3743\n",
            "Epoch 61/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 227.6840 - val_loss: 144.2688\n",
            "Epoch 62/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 226.5616 - val_loss: 143.1137\n",
            "Epoch 63/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 225.4401 - val_loss: 141.9920\n",
            "Epoch 64/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 224.3170 - val_loss: 140.8722\n",
            "Epoch 65/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 223.1895 - val_loss: 139.7575\n",
            "Epoch 66/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 222.0714 - val_loss: 138.6179\n",
            "Epoch 67/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 220.9420 - val_loss: 137.5073\n",
            "Epoch 68/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 219.8376 - val_loss: 136.3984\n",
            "Epoch 69/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 218.7081 - val_loss: 135.2384\n",
            "Epoch 70/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 217.5792 - val_loss: 134.1306\n",
            "Epoch 71/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 216.4625 - val_loss: 133.0073\n",
            "Epoch 72/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 215.3359 - val_loss: 131.8892\n",
            "Epoch 73/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 214.2184 - val_loss: 130.7651\n",
            "Epoch 74/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 213.1095 - val_loss: 129.6485\n",
            "Epoch 75/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 211.9960 - val_loss: 128.5227\n",
            "Epoch 76/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 210.8702 - val_loss: 127.4118\n",
            "Epoch 77/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 209.7421 - val_loss: 126.2679\n",
            "Epoch 78/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 208.6082 - val_loss: 125.1527\n",
            "Epoch 79/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 207.4788 - val_loss: 124.0230\n",
            "Epoch 80/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 206.3528 - val_loss: 122.9076\n",
            "Epoch 81/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 205.2257 - val_loss: 121.7612\n",
            "Epoch 82/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 204.1038 - val_loss: 120.6741\n",
            "Epoch 83/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 202.9816 - val_loss: 119.5175\n",
            "Epoch 84/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 201.8591 - val_loss: 118.4090\n",
            "Epoch 85/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 200.7413 - val_loss: 117.2908\n",
            "Epoch 86/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 199.6170 - val_loss: 116.1754\n",
            "Epoch 87/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 198.4938 - val_loss: 115.0550\n",
            "Epoch 88/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 197.3714 - val_loss: 113.9243\n",
            "Epoch 89/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 196.2456 - val_loss: 112.7795\n",
            "Epoch 90/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 195.1133 - val_loss: 111.7030\n",
            "Epoch 91/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 193.9875 - val_loss: 110.5108\n",
            "Epoch 92/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 192.8495 - val_loss: 109.3928\n",
            "Epoch 93/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 191.7281 - val_loss: 108.2590\n",
            "Epoch 94/700\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 190.5828 - val_loss: 107.1252\n",
            "Epoch 95/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 189.4738 - val_loss: 105.9988\n",
            "Epoch 96/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 188.3502 - val_loss: 104.8529\n",
            "Epoch 97/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 187.2180 - val_loss: 103.7650\n",
            "Epoch 98/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 186.0877 - val_loss: 102.6102\n",
            "Epoch 99/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 184.9507 - val_loss: 101.4813\n",
            "Epoch 100/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 183.8241 - val_loss: 100.3679\n",
            "Epoch 101/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 182.7016 - val_loss: 99.2228\n",
            "Epoch 102/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 181.5765 - val_loss: 98.1103\n",
            "Epoch 103/700\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 180.4449 - val_loss: 96.9764\n",
            "Epoch 104/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 179.3194 - val_loss: 95.8703\n",
            "Epoch 105/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 178.1986 - val_loss: 94.7280\n",
            "Epoch 106/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 177.0738 - val_loss: 93.6310\n",
            "Epoch 107/700\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 175.9503 - val_loss: 92.4782\n",
            "Epoch 108/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 174.8291 - val_loss: 91.3985\n",
            "Epoch 109/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 173.7063 - val_loss: 90.2281\n",
            "Epoch 110/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 172.5875 - val_loss: 89.1439\n",
            "Epoch 111/700\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 171.4761 - val_loss: 87.9988\n",
            "Epoch 112/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 170.3552 - val_loss: 86.8831\n",
            "Epoch 113/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 169.2341 - val_loss: 85.7592\n",
            "Epoch 114/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 168.1134 - val_loss: 84.6620\n",
            "Epoch 115/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 166.9928 - val_loss: 83.5072\n",
            "Epoch 116/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 165.8695 - val_loss: 82.4086\n",
            "Epoch 117/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 164.7486 - val_loss: 81.2830\n",
            "Epoch 118/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 163.6383 - val_loss: 80.1775\n",
            "Epoch 119/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 162.5091 - val_loss: 79.0432\n",
            "Epoch 120/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 161.3896 - val_loss: 77.9149\n",
            "Epoch 121/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 160.2744 - val_loss: 76.8178\n",
            "Epoch 122/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 159.1553 - val_loss: 75.7015\n",
            "Epoch 123/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 158.0392 - val_loss: 74.5780\n",
            "Epoch 124/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 156.9191 - val_loss: 73.4437\n",
            "Epoch 125/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 155.7964 - val_loss: 72.3388\n",
            "Epoch 126/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 154.6803 - val_loss: 71.2104\n",
            "Epoch 127/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 153.5653 - val_loss: 70.1132\n",
            "Epoch 128/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 152.4442 - val_loss: 68.9843\n",
            "Epoch 129/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 151.3220 - val_loss: 67.8507\n",
            "Epoch 130/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 150.2116 - val_loss: 66.7978\n",
            "Epoch 131/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 149.0857 - val_loss: 65.6160\n",
            "Epoch 132/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 147.9742 - val_loss: 64.5338\n",
            "Epoch 133/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 146.8549 - val_loss: 63.3880\n",
            "Epoch 134/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 145.7396 - val_loss: 62.3048\n",
            "Epoch 135/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 144.6232 - val_loss: 61.1650\n",
            "Epoch 136/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 143.5081 - val_loss: 60.0409\n",
            "Epoch 137/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 142.3941 - val_loss: 58.9477\n",
            "Epoch 138/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 141.2787 - val_loss: 57.8221\n",
            "Epoch 139/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 140.1589 - val_loss: 56.6903\n",
            "Epoch 140/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 139.0398 - val_loss: 55.5842\n",
            "Epoch 141/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 137.9282 - val_loss: 54.4643\n",
            "Epoch 142/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 136.8141 - val_loss: 53.3617\n",
            "Epoch 143/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 135.7019 - val_loss: 52.2358\n",
            "Epoch 144/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 134.5871 - val_loss: 51.1289\n",
            "Epoch 145/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 133.4699 - val_loss: 50.0093\n",
            "Epoch 146/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 132.3576 - val_loss: 48.9082\n",
            "Epoch 147/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 131.2469 - val_loss: 47.7789\n",
            "Epoch 148/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 130.1384 - val_loss: 46.6901\n",
            "Epoch 149/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 129.0430 - val_loss: 45.5669\n",
            "Epoch 150/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 127.9559 - val_loss: 44.4669\n",
            "Epoch 151/700\n",
            "6/6 [==============================] - 3s 564ms/step - loss: 126.8620 - val_loss: 43.3658\n",
            "Epoch 152/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 125.7555 - val_loss: 42.2207\n",
            "Epoch 153/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 124.6635 - val_loss: 41.1475\n",
            "Epoch 154/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 123.5753 - val_loss: 40.0542\n",
            "Epoch 155/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 122.5021 - val_loss: 38.9368\n",
            "Epoch 156/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 121.4413 - val_loss: 37.8604\n",
            "Epoch 157/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 120.3924 - val_loss: 36.7686\n",
            "Epoch 158/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 119.3488 - val_loss: 35.6975\n",
            "Epoch 159/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 118.3222 - val_loss: 34.6207\n",
            "Epoch 160/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 117.3422 - val_loss: 33.5726\n",
            "Epoch 161/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 116.4138 - val_loss: 32.5345\n",
            "Epoch 162/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 115.5401 - val_loss: 31.5411\n",
            "Epoch 163/700\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 114.6771 - val_loss: 30.5762\n",
            "Epoch 164/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 113.8851 - val_loss: 29.6325\n",
            "Epoch 165/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 113.1779 - val_loss: 28.7102\n",
            "Epoch 166/700\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 112.5351 - val_loss: 27.8615\n",
            "Epoch 167/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 111.9891 - val_loss: 27.0939\n",
            "Epoch 168/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 111.5664 - val_loss: 26.3976\n",
            "Epoch 169/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 111.2998 - val_loss: 25.7961\n",
            "Epoch 170/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 111.0628 - val_loss: 25.2833\n",
            "Epoch 171/700\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 110.8822 - val_loss: 24.8062\n",
            "Epoch 172/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 110.8079 - val_loss: 24.4108\n",
            "Epoch 173/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 110.6570 - val_loss: 24.0699\n",
            "Epoch 174/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 110.5744 - val_loss: 23.8067\n",
            "Epoch 175/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 110.5170 - val_loss: 23.5941\n",
            "Epoch 176/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 110.4932 - val_loss: 23.3578\n",
            "Epoch 177/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 110.4692 - val_loss: 23.2312\n",
            "Epoch 178/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 110.4404 - val_loss: 23.1063\n",
            "Epoch 179/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.4287 - val_loss: 22.9764\n",
            "Epoch 180/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 110.4090 - val_loss: 22.8848\n",
            "Epoch 181/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 110.3897 - val_loss: 22.8122\n",
            "Epoch 182/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 110.3702 - val_loss: 22.7863\n",
            "Epoch 183/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 110.3553 - val_loss: 22.7554\n",
            "Epoch 184/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 110.3745 - val_loss: 22.7226\n",
            "Epoch 185/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 110.3640 - val_loss: 22.7363\n",
            "Epoch 186/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 110.3512 - val_loss: 22.7285\n",
            "Epoch 187/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.3290 - val_loss: 22.7103\n",
            "Epoch 188/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 110.3245 - val_loss: 22.6749\n",
            "Epoch 189/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 110.3171 - val_loss: 22.6621\n",
            "Epoch 190/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 110.3139 - val_loss: 22.6170\n",
            "Epoch 191/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 110.2981 - val_loss: 22.6032\n",
            "Epoch 192/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.2914 - val_loss: 22.7022\n",
            "Epoch 193/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 110.2857 - val_loss: 23.3532\n",
            "Epoch 194/700\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 110.2264 - val_loss: 22.5621\n",
            "Epoch 195/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 110.2704 - val_loss: 22.5152\n",
            "Epoch 196/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 110.2584 - val_loss: 22.4834\n",
            "Epoch 197/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 110.2555 - val_loss: 22.4473\n",
            "Epoch 198/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 110.2471 - val_loss: 22.4628\n",
            "Epoch 199/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 110.2432 - val_loss: 22.4678\n",
            "Epoch 200/700\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 110.2388 - val_loss: 22.4801\n",
            "Epoch 201/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 110.2293 - val_loss: 22.5056\n",
            "Epoch 202/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 110.2230 - val_loss: 22.4642\n",
            "Epoch 203/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 110.2178 - val_loss: 22.4567\n",
            "Epoch 204/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 110.2160 - val_loss: 22.4407\n",
            "Epoch 205/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 110.2120 - val_loss: 22.4266\n",
            "Epoch 206/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 110.2111 - val_loss: 22.4217\n",
            "Epoch 207/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 110.2058 - val_loss: 22.4422\n",
            "Epoch 208/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 110.1967 - val_loss: 22.4634\n",
            "Epoch 209/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.1939 - val_loss: 22.4789\n",
            "Epoch 210/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 110.1842 - val_loss: 23.2478\n",
            "Epoch 211/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.1768 - val_loss: 22.4632\n",
            "Epoch 212/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 110.1777 - val_loss: 22.4478\n",
            "Epoch 213/700\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 110.1756 - val_loss: 22.4387\n",
            "Epoch 214/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 110.1663 - val_loss: 22.4301\n",
            "Epoch 215/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 110.1592 - val_loss: 22.4386\n",
            "Epoch 216/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.1515 - val_loss: 22.4453\n",
            "Epoch 217/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 110.1501 - val_loss: 22.4361\n",
            "Epoch 218/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 110.1417 - val_loss: 22.4837\n",
            "Epoch 219/700\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 110.1369 - val_loss: 22.4809\n",
            "Epoch 220/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 110.1272 - val_loss: 22.5899\n",
            "Epoch 221/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 110.1288 - val_loss: 22.5579\n",
            "Epoch 222/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 110.1188 - val_loss: 22.5504\n",
            "Epoch 223/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 110.1021 - val_loss: 22.8359\n",
            "Epoch 224/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 110.0810 - val_loss: 22.8068\n",
            "Epoch 225/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 110.0686 - val_loss: 22.8474\n",
            "Epoch 226/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 110.0614 - val_loss: 22.7981\n",
            "Epoch 227/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 110.0579 - val_loss: 22.7471\n",
            "Epoch 228/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 110.0467 - val_loss: 22.7255\n",
            "Epoch 229/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 110.0398 - val_loss: 22.7293\n",
            "Epoch 230/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 110.0346 - val_loss: 22.7037\n",
            "Epoch 231/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 110.0301 - val_loss: 22.7135\n",
            "Epoch 232/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 110.0300 - val_loss: 22.7064\n",
            "Epoch 233/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 110.0423 - val_loss: 23.4236\n",
            "Epoch 234/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 110.0230 - val_loss: 24.4056\n",
            "Epoch 235/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 110.0007 - val_loss: 23.3218\n",
            "Epoch 236/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 109.9629 - val_loss: 23.2731\n",
            "Epoch 237/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 109.9674 - val_loss: 23.2199\n",
            "Epoch 238/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 109.9872 - val_loss: 22.4084\n",
            "Epoch 239/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 110.0226 - val_loss: 22.4434\n",
            "Epoch 240/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 110.0181 - val_loss: 22.4572\n",
            "Epoch 241/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 110.0049 - val_loss: 22.4488\n",
            "Epoch 242/700\n",
            "6/6 [==============================] - 3s 559ms/step - loss: 109.9978 - val_loss: 22.4902\n",
            "Epoch 243/700\n",
            "6/6 [==============================] - 3s 558ms/step - loss: 110.0030 - val_loss: 22.4880\n",
            "Epoch 244/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 110.0052 - val_loss: 22.5633\n",
            "Epoch 245/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 110.0585 - val_loss: 22.5927\n",
            "Epoch 246/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 110.0525 - val_loss: 22.6116\n",
            "Epoch 247/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 110.0381 - val_loss: 22.6031\n",
            "Epoch 248/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 110.0300 - val_loss: 22.6003\n",
            "Epoch 249/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 110.0169 - val_loss: 22.5430\n",
            "Epoch 250/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 110.0137 - val_loss: 22.5110\n",
            "Epoch 251/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 110.0049 - val_loss: 22.5158\n",
            "Epoch 252/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 110.0077 - val_loss: 22.4769\n",
            "Epoch 253/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 109.9784 - val_loss: 22.4928\n",
            "Epoch 254/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 109.9637 - val_loss: 23.0067\n",
            "Epoch 255/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 109.9450 - val_loss: 23.1771\n",
            "Epoch 256/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 109.9118 - val_loss: 23.1541\n",
            "Epoch 257/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 109.8935 - val_loss: 23.0673\n",
            "Epoch 258/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 109.8645 - val_loss: 23.0655\n",
            "Epoch 259/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 110.0557 - val_loss: 23.7019\n",
            "Epoch 260/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 109.9109 - val_loss: 23.6422\n",
            "Epoch 261/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 109.8408 - val_loss: 23.6460\n",
            "Epoch 262/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 109.8347 - val_loss: 23.5284\n",
            "Epoch 263/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 109.8130 - val_loss: 23.4483\n",
            "Epoch 264/700\n",
            "6/6 [==============================] - 3s 512ms/step - loss: 109.8035 - val_loss: 23.3573\n",
            "Epoch 265/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 109.7958 - val_loss: 23.2972\n",
            "Epoch 266/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 109.7896 - val_loss: 23.2260\n",
            "Epoch 267/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 109.7697 - val_loss: 23.1790\n",
            "Epoch 268/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 109.7614 - val_loss: 23.1676\n",
            "Epoch 269/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 109.7803 - val_loss: 23.1606\n",
            "Epoch 270/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 109.7268 - val_loss: 23.1566\n",
            "Epoch 271/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 109.7177 - val_loss: 23.0977\n",
            "Epoch 272/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 109.7122 - val_loss: 23.1100\n",
            "Epoch 273/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 109.7007 - val_loss: 23.0748\n",
            "Epoch 274/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 109.6928 - val_loss: 23.0661\n",
            "Epoch 275/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 109.6770 - val_loss: 23.0534\n",
            "Epoch 276/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 109.6835 - val_loss: 23.0760\n",
            "Epoch 277/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 109.6818 - val_loss: 23.0739\n",
            "Epoch 278/700\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 109.6758 - val_loss: 23.0896\n",
            "Epoch 279/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 109.6772 - val_loss: 23.0549\n",
            "Epoch 280/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 109.6693 - val_loss: 23.0536\n",
            "Epoch 281/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 109.6462 - val_loss: 23.0120\n",
            "Epoch 282/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 109.6435 - val_loss: 23.0421\n",
            "Epoch 283/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 109.6287 - val_loss: 23.0207\n",
            "Epoch 284/700\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 109.6249 - val_loss: 23.0078\n",
            "Epoch 285/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 109.6044 - val_loss: 23.0964\n",
            "Epoch 286/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 109.5724 - val_loss: 23.1259\n",
            "Epoch 287/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 109.5542 - val_loss: 23.1308\n",
            "Epoch 288/700\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 109.5429 - val_loss: 23.5011\n",
            "Epoch 289/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 109.4953 - val_loss: 23.8571\n",
            "Epoch 290/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 109.6638 - val_loss: 24.7215\n",
            "Epoch 291/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 109.6541 - val_loss: 24.1745\n",
            "Epoch 292/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 109.6071 - val_loss: 23.9796\n",
            "Epoch 293/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 109.5492 - val_loss: 23.7152\n",
            "Epoch 294/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 109.5435 - val_loss: 23.5262\n",
            "Epoch 295/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 109.5321 - val_loss: 23.3969\n",
            "Epoch 296/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 109.4799 - val_loss: 23.3022\n",
            "Epoch 297/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 109.4654 - val_loss: 23.2308\n",
            "Epoch 298/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 109.5050 - val_loss: 23.1887\n",
            "Epoch 299/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 109.4775 - val_loss: 23.1858\n",
            "Epoch 300/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 109.4820 - val_loss: 23.1857\n",
            "Epoch 301/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 109.4659 - val_loss: 23.1698\n",
            "Epoch 302/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 109.4471 - val_loss: 23.1958\n",
            "Epoch 303/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 109.4214 - val_loss: 23.1695\n",
            "Epoch 304/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 109.4104 - val_loss: 23.1572\n",
            "Epoch 305/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 109.4126 - val_loss: 23.1544\n",
            "Epoch 306/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 109.3904 - val_loss: 23.1271\n",
            "Epoch 307/700\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 109.3792 - val_loss: 23.1600\n",
            "Epoch 308/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 109.3580 - val_loss: 23.1771\n",
            "Epoch 309/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 109.3777 - val_loss: 23.1731\n",
            "Epoch 310/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 109.3497 - val_loss: 23.1954\n",
            "Epoch 311/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 109.3336 - val_loss: 23.2181\n",
            "Epoch 312/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 109.3309 - val_loss: 23.2113\n",
            "Epoch 313/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 109.3232 - val_loss: 23.9660\n",
            "Epoch 314/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 109.3131 - val_loss: 23.9320\n",
            "Epoch 315/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 109.2943 - val_loss: 23.8259\n",
            "Epoch 316/700\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 109.2724 - val_loss: 23.7589\n",
            "Epoch 317/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 109.2490 - val_loss: 23.6275\n",
            "Epoch 318/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 109.2295 - val_loss: 23.5522\n",
            "Epoch 319/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 109.2257 - val_loss: 23.4764\n",
            "Epoch 320/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 109.2349 - val_loss: 23.4717\n",
            "Epoch 321/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 109.2308 - val_loss: 23.3938\n",
            "Epoch 322/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 109.1974 - val_loss: 23.4175\n",
            "Epoch 323/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 109.2039 - val_loss: 23.3725\n",
            "Epoch 324/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 109.1790 - val_loss: 23.4042\n",
            "Epoch 325/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 109.1630 - val_loss: 23.3758\n",
            "Epoch 326/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 109.1487 - val_loss: 23.3830\n",
            "Epoch 327/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 109.1172 - val_loss: 23.3858\n",
            "Epoch 328/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 109.0910 - val_loss: 23.3612\n",
            "Epoch 329/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 109.0699 - val_loss: 23.3666\n",
            "Epoch 330/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 109.0513 - val_loss: 23.4230\n",
            "Epoch 331/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 109.0446 - val_loss: 23.4566\n",
            "Epoch 332/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 109.0262 - val_loss: 23.4533\n",
            "Epoch 333/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 109.0137 - val_loss: 23.4509\n",
            "Epoch 334/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 109.0010 - val_loss: 23.4259\n",
            "Epoch 335/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 108.9985 - val_loss: 23.4258\n",
            "Epoch 336/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 108.9732 - val_loss: 23.4372\n",
            "Epoch 337/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 108.9543 - val_loss: 23.4464\n",
            "Epoch 338/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 108.9496 - val_loss: 23.4364\n",
            "Epoch 339/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 108.9333 - val_loss: 23.4537\n",
            "Epoch 340/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 108.9293 - val_loss: 23.4332\n",
            "Epoch 341/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 108.9062 - val_loss: 23.5428\n",
            "Epoch 342/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 108.9045 - val_loss: 23.4185\n",
            "Epoch 343/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 108.9079 - val_loss: 23.4195\n",
            "Epoch 344/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 108.8948 - val_loss: 23.4151\n",
            "Epoch 345/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 108.8463 - val_loss: 23.4558\n",
            "Epoch 346/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 108.8265 - val_loss: 23.2330\n",
            "Epoch 347/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 108.7920 - val_loss: 23.4305\n",
            "Epoch 348/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 108.7480 - val_loss: 23.4651\n",
            "Epoch 349/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 108.7257 - val_loss: 23.4576\n",
            "Epoch 350/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 108.7055 - val_loss: 23.4478\n",
            "Epoch 351/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 108.7028 - val_loss: 23.3944\n",
            "Epoch 352/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 108.6898 - val_loss: 23.3317\n",
            "Epoch 353/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 108.6700 - val_loss: 23.3456\n",
            "Epoch 354/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 108.6479 - val_loss: 23.3414\n",
            "Epoch 355/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 108.6359 - val_loss: 23.3031\n",
            "Epoch 356/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 108.6098 - val_loss: 23.3838\n",
            "Epoch 357/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 108.5822 - val_loss: 23.3852\n",
            "Epoch 358/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 108.5649 - val_loss: 23.3987\n",
            "Epoch 359/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 108.5536 - val_loss: 23.4215\n",
            "Epoch 360/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 108.5521 - val_loss: 23.4893\n",
            "Epoch 361/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 108.5417 - val_loss: 23.4014\n",
            "Epoch 362/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 108.5398 - val_loss: 23.4108\n",
            "Epoch 363/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 108.5123 - val_loss: 24.0523\n",
            "Epoch 364/700\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 108.5497 - val_loss: 24.1412\n",
            "Epoch 365/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 108.4808 - val_loss: 23.9563\n",
            "Epoch 366/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 108.4588 - val_loss: 23.8270\n",
            "Epoch 367/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 108.4241 - val_loss: 23.7591\n",
            "Epoch 368/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 108.4084 - val_loss: 23.6484\n",
            "Epoch 369/700\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 108.3967 - val_loss: 23.7494\n",
            "Epoch 370/700\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 108.4559 - val_loss: 24.4435\n",
            "Epoch 371/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 108.4188 - val_loss: 24.2447\n",
            "Epoch 372/700\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 108.3778 - val_loss: 24.0545\n",
            "Epoch 373/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 108.3586 - val_loss: 23.8735\n",
            "Epoch 374/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 108.3282 - val_loss: 23.8014\n",
            "Epoch 375/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 108.3264 - val_loss: 23.6893\n",
            "Epoch 376/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 108.3040 - val_loss: 23.6909\n",
            "Epoch 377/700\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 108.3250 - val_loss: 24.4120\n",
            "Epoch 378/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 108.3228 - val_loss: 24.2183\n",
            "Epoch 379/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 108.2926 - val_loss: 24.0168\n",
            "Epoch 380/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 108.2603 - val_loss: 23.8715\n",
            "Epoch 381/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 108.2401 - val_loss: 23.7318\n",
            "Epoch 382/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 108.2297 - val_loss: 23.6591\n",
            "Epoch 383/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 108.2630 - val_loss: 23.5828\n",
            "Epoch 384/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 108.2618 - val_loss: 23.5859\n",
            "Epoch 385/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 108.2093 - val_loss: 23.5831\n",
            "Epoch 386/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 108.1927 - val_loss: 23.5590\n",
            "Epoch 387/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 108.1839 - val_loss: 23.6056\n",
            "Epoch 388/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 108.1555 - val_loss: 23.5654\n",
            "Epoch 389/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 108.1371 - val_loss: 23.6052\n",
            "Epoch 390/700\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 108.1244 - val_loss: 23.6036\n",
            "Epoch 391/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 108.1027 - val_loss: 23.5979\n",
            "Epoch 392/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 108.0819 - val_loss: 23.5667\n",
            "Epoch 393/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 108.0701 - val_loss: 23.6411\n",
            "Epoch 394/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 108.0359 - val_loss: 23.5851\n",
            "Epoch 395/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 108.0398 - val_loss: 23.5566\n",
            "Epoch 396/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 108.0722 - val_loss: 23.5516\n",
            "Epoch 397/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 108.0114 - val_loss: 23.5594\n",
            "Epoch 398/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 108.0074 - val_loss: 23.5047\n",
            "Epoch 399/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 107.9941 - val_loss: 24.0754\n",
            "Epoch 400/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 107.9780 - val_loss: 23.6626\n",
            "Epoch 401/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 107.9522 - val_loss: 23.5026\n",
            "Epoch 402/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 107.9280 - val_loss: 23.6538\n",
            "Epoch 403/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 107.9582 - val_loss: 23.7513\n",
            "Epoch 404/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 107.9083 - val_loss: 23.6501\n",
            "Epoch 405/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 107.8894 - val_loss: 23.6449\n",
            "Epoch 406/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 107.8678 - val_loss: 23.5128\n",
            "Epoch 407/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 107.8523 - val_loss: 23.5048\n",
            "Epoch 408/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.8334 - val_loss: 23.5009\n",
            "Epoch 409/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 107.8294 - val_loss: 23.4930\n",
            "Epoch 410/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.8180 - val_loss: 23.8085\n",
            "Epoch 411/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 107.8087 - val_loss: 23.5832\n",
            "Epoch 412/700\n",
            "6/6 [==============================] - 3s 558ms/step - loss: 107.9166 - val_loss: 23.9154\n",
            "Epoch 413/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 107.8978 - val_loss: 23.0893\n",
            "Epoch 414/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 107.8811 - val_loss: 23.5873\n",
            "Epoch 415/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 107.8074 - val_loss: 23.4803\n",
            "Epoch 416/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 107.8140 - val_loss: 23.7513\n",
            "Epoch 417/700\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 107.7187 - val_loss: 23.6843\n",
            "Epoch 418/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 107.7170 - val_loss: 23.6802\n",
            "Epoch 419/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 107.6911 - val_loss: 23.7573\n",
            "Epoch 420/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 107.6731 - val_loss: 23.6106\n",
            "Epoch 421/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 107.6146 - val_loss: 23.5943\n",
            "Epoch 422/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 107.6136 - val_loss: 23.5661\n",
            "Epoch 423/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 107.5769 - val_loss: 23.6391\n",
            "Epoch 424/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 107.5909 - val_loss: 23.6221\n",
            "Epoch 425/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 107.5852 - val_loss: 23.5483\n",
            "Epoch 426/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 107.6071 - val_loss: 23.5609\n",
            "Epoch 427/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 107.6001 - val_loss: 23.6623\n",
            "Epoch 428/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.6059 - val_loss: 23.8981\n",
            "Epoch 429/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 107.5555 - val_loss: 23.6318\n",
            "Epoch 430/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 107.4885 - val_loss: 23.8244\n",
            "Epoch 431/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.4877 - val_loss: 23.8302\n",
            "Epoch 432/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 107.4847 - val_loss: 23.8183\n",
            "Epoch 433/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 107.4631 - val_loss: 23.7280\n",
            "Epoch 434/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 107.4536 - val_loss: 23.6780\n",
            "Epoch 435/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 107.4074 - val_loss: 23.6768\n",
            "Epoch 436/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 107.3901 - val_loss: 23.6039\n",
            "Epoch 437/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 107.3706 - val_loss: 23.6293\n",
            "Epoch 438/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 107.3486 - val_loss: 23.6054\n",
            "Epoch 439/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 107.3269 - val_loss: 23.6055\n",
            "Epoch 440/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 107.3015 - val_loss: 23.5918\n",
            "Epoch 441/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 107.2842 - val_loss: 23.5633\n",
            "Epoch 442/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 107.2481 - val_loss: 23.5270\n",
            "Epoch 443/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 107.2340 - val_loss: 23.5607\n",
            "Epoch 444/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.2291 - val_loss: 23.5057\n",
            "Epoch 445/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 107.1932 - val_loss: 23.4968\n",
            "Epoch 446/700\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 107.1779 - val_loss: 23.4883\n",
            "Epoch 447/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.1786 - val_loss: 23.4551\n",
            "Epoch 448/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 107.1415 - val_loss: 23.5000\n",
            "Epoch 449/700\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 107.1211 - val_loss: 23.5020\n",
            "Epoch 450/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 107.1247 - val_loss: 23.4920\n",
            "Epoch 451/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 107.0838 - val_loss: 23.4630\n",
            "Epoch 452/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 107.0932 - val_loss: 23.4266\n",
            "Epoch 453/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 107.0672 - val_loss: 23.8018\n",
            "Epoch 454/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 107.0644 - val_loss: 23.7040\n",
            "Epoch 455/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 107.0537 - val_loss: 23.6535\n",
            "Epoch 456/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 107.0122 - val_loss: 23.6118\n",
            "Epoch 457/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 106.9615 - val_loss: 23.5756\n",
            "Epoch 458/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 106.9809 - val_loss: 23.4418\n",
            "Epoch 459/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 106.9592 - val_loss: 23.4304\n",
            "Epoch 460/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 106.9235 - val_loss: 23.4352\n",
            "Epoch 461/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 106.9498 - val_loss: 23.4695\n",
            "Epoch 462/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 106.9749 - val_loss: 23.4016\n",
            "Epoch 463/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 106.9441 - val_loss: 23.4870\n",
            "Epoch 464/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 106.8700 - val_loss: 23.4734\n",
            "Epoch 465/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 106.8288 - val_loss: 23.5147\n",
            "Epoch 466/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 106.8159 - val_loss: 23.4634\n",
            "Epoch 467/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 106.8095 - val_loss: 23.4635\n",
            "Epoch 468/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 106.8957 - val_loss: 23.4085\n",
            "Epoch 469/700\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 106.8422 - val_loss: 23.3493\n",
            "Epoch 470/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 106.7676 - val_loss: 23.4040\n",
            "Epoch 471/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 106.6914 - val_loss: 23.3800\n",
            "Epoch 472/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 106.6928 - val_loss: 23.4853\n",
            "Epoch 473/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 106.6902 - val_loss: 23.5172\n",
            "Epoch 474/700\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 106.6544 - val_loss: 23.5927\n",
            "Epoch 475/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 106.7732 - val_loss: 23.5339\n",
            "Epoch 476/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 106.7805 - val_loss: 23.5840\n",
            "Epoch 477/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 106.7240 - val_loss: 23.3872\n",
            "Epoch 478/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 106.6964 - val_loss: 23.3002\n",
            "Epoch 479/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 106.6718 - val_loss: 23.2358\n",
            "Epoch 480/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 106.6420 - val_loss: 23.3856\n",
            "Epoch 481/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 106.6506 - val_loss: 24.1720\n",
            "Epoch 482/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 106.5758 - val_loss: 23.5244\n",
            "Epoch 483/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 106.5567 - val_loss: 23.4378\n",
            "Epoch 484/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 106.5317 - val_loss: 23.7740\n",
            "Epoch 485/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 106.5133 - val_loss: 23.7132\n",
            "Epoch 486/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 106.4807 - val_loss: 23.6197\n",
            "Epoch 487/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 106.4701 - val_loss: 23.5670\n",
            "Epoch 488/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 106.4429 - val_loss: 23.5947\n",
            "Epoch 489/700\n",
            "6/6 [==============================] - 3s 510ms/step - loss: 106.4263 - val_loss: 23.5147\n",
            "Epoch 490/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 106.3880 - val_loss: 23.5131\n",
            "Epoch 491/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 106.3787 - val_loss: 23.3102\n",
            "Epoch 492/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 106.3463 - val_loss: 23.4248\n",
            "Epoch 493/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 106.3200 - val_loss: 23.4881\n",
            "Epoch 494/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 106.3128 - val_loss: 23.4205\n",
            "Epoch 495/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 106.2991 - val_loss: 23.3941\n",
            "Epoch 496/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 106.2757 - val_loss: 23.4043\n",
            "Epoch 497/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 106.2425 - val_loss: 23.4411\n",
            "Epoch 498/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 106.2177 - val_loss: 23.5842\n",
            "Epoch 499/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 106.2031 - val_loss: 23.6102\n",
            "Epoch 500/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 106.1781 - val_loss: 23.4194\n",
            "Epoch 501/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 106.1508 - val_loss: 23.4252\n",
            "Epoch 502/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 106.1283 - val_loss: 23.4351\n",
            "Epoch 503/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 106.1048 - val_loss: 23.4308\n",
            "Epoch 504/700\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 106.0871 - val_loss: 23.5396\n",
            "Epoch 505/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 106.0711 - val_loss: 23.4717\n",
            "Epoch 506/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 106.0585 - val_loss: 23.4772\n",
            "Epoch 507/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 106.0261 - val_loss: 23.5495\n",
            "Epoch 508/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 106.0091 - val_loss: 23.7116\n",
            "Epoch 509/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 105.9956 - val_loss: 23.7019\n",
            "Epoch 510/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 105.9794 - val_loss: 23.6080\n",
            "Epoch 511/700\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 105.9581 - val_loss: 23.5689\n",
            "Epoch 512/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 105.9221 - val_loss: 23.5558\n",
            "Epoch 513/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 105.8782 - val_loss: 23.5105\n",
            "Epoch 514/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 105.8968 - val_loss: 24.2895\n",
            "Epoch 515/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 105.8852 - val_loss: 24.0847\n",
            "Epoch 516/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 105.8150 - val_loss: 23.9619\n",
            "Epoch 517/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 105.8143 - val_loss: 23.6693\n",
            "Epoch 518/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 105.7644 - val_loss: 23.5939\n",
            "Epoch 519/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 105.7949 - val_loss: 23.5776\n",
            "Epoch 520/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 105.7639 - val_loss: 23.7669\n",
            "Epoch 521/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 105.7318 - val_loss: 23.6338\n",
            "Epoch 522/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 105.7096 - val_loss: 23.4627\n",
            "Epoch 523/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 105.6622 - val_loss: 23.5128\n",
            "Epoch 524/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 105.6216 - val_loss: 23.6331\n",
            "Epoch 525/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 105.6741 - val_loss: 23.4161\n",
            "Epoch 526/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 105.5796 - val_loss: 23.5764\n",
            "Epoch 527/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 105.5707 - val_loss: 23.7725\n",
            "Epoch 528/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 105.5426 - val_loss: 23.7772\n",
            "Epoch 529/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 105.4618 - val_loss: 23.5869\n",
            "Epoch 530/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 105.4401 - val_loss: 23.5553\n",
            "Epoch 531/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 105.4307 - val_loss: 23.7754\n",
            "Epoch 532/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 105.3800 - val_loss: 23.5938\n",
            "Epoch 533/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 105.4081 - val_loss: 23.5042\n",
            "Epoch 534/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 105.3673 - val_loss: 23.6955\n",
            "Epoch 535/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 105.4054 - val_loss: 23.8535\n",
            "Epoch 536/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 105.3535 - val_loss: 23.8660\n",
            "Epoch 537/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 105.2754 - val_loss: 23.3821\n",
            "Epoch 538/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 105.2774 - val_loss: 23.4668\n",
            "Epoch 539/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 105.3042 - val_loss: 23.6026\n",
            "Epoch 540/700\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 105.2263 - val_loss: 23.5257\n",
            "Epoch 541/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 105.1840 - val_loss: 23.4997\n",
            "Epoch 542/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 105.1506 - val_loss: 23.7354\n",
            "Epoch 543/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 105.1291 - val_loss: 23.5386\n",
            "Epoch 544/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 105.2120 - val_loss: 23.5521\n",
            "Epoch 545/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 105.1572 - val_loss: 23.4700\n",
            "Epoch 546/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 105.2490 - val_loss: 23.6915\n",
            "Epoch 547/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 105.2022 - val_loss: 23.9199\n",
            "Epoch 548/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 105.1447 - val_loss: 23.9710\n",
            "Epoch 549/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 105.1522 - val_loss: 23.7814\n",
            "Epoch 550/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 105.1092 - val_loss: 23.7066\n",
            "Epoch 551/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 105.0660 - val_loss: 23.7875\n",
            "Epoch 552/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 104.9841 - val_loss: 23.7130\n",
            "Epoch 553/700\n",
            "6/6 [==============================] - 3s 560ms/step - loss: 104.9498 - val_loss: 23.6593\n",
            "Epoch 554/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 104.9429 - val_loss: 23.5918\n",
            "Epoch 555/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 104.9199 - val_loss: 24.1110\n",
            "Epoch 556/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 104.9696 - val_loss: 23.9383\n",
            "Epoch 557/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 104.8833 - val_loss: 23.4233\n",
            "Epoch 558/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 104.8794 - val_loss: 23.5145\n",
            "Epoch 559/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 104.8243 - val_loss: 23.6708\n",
            "Epoch 560/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 104.7769 - val_loss: 23.6989\n",
            "Epoch 561/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 104.7460 - val_loss: 23.6527\n",
            "Epoch 562/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 104.7582 - val_loss: 23.6050\n",
            "Epoch 563/700\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 104.7290 - val_loss: 23.6161\n",
            "Epoch 564/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 104.6914 - val_loss: 23.6276\n",
            "Epoch 565/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 104.6496 - val_loss: 23.5666\n",
            "Epoch 566/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 104.6043 - val_loss: 23.5105\n",
            "Epoch 567/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 104.5740 - val_loss: 23.5109\n",
            "Epoch 568/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 104.5433 - val_loss: 23.5336\n",
            "Epoch 569/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 104.5298 - val_loss: 23.4203\n",
            "Epoch 570/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 104.5016 - val_loss: 23.5278\n",
            "Epoch 571/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 104.4706 - val_loss: 23.5772\n",
            "Epoch 572/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 104.4348 - val_loss: 23.4840\n",
            "Epoch 573/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 104.5872 - val_loss: 23.7534\n",
            "Epoch 574/700\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 104.6236 - val_loss: 23.4389\n",
            "Epoch 575/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 104.5736 - val_loss: 23.3498\n",
            "Epoch 576/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 104.5317 - val_loss: 23.5500\n",
            "Epoch 577/700\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 104.4758 - val_loss: 23.6076\n",
            "Epoch 578/700\n",
            "6/6 [==============================] - 3s 554ms/step - loss: 104.4382 - val_loss: 23.6447\n",
            "Epoch 579/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 104.3729 - val_loss: 23.7257\n",
            "Epoch 580/700\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 104.3289 - val_loss: 23.5774\n",
            "Epoch 581/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 104.2566 - val_loss: 23.9725\n",
            "Epoch 582/700\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 104.2546 - val_loss: 23.7758\n",
            "Epoch 583/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 104.2647 - val_loss: 23.7418\n",
            "Epoch 584/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 104.2097 - val_loss: 23.6695\n",
            "Epoch 585/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 104.1119 - val_loss: 23.5706\n",
            "Epoch 586/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 104.0685 - val_loss: 23.5369\n",
            "Epoch 587/700\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 104.0826 - val_loss: 23.4518\n",
            "Epoch 588/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 104.0174 - val_loss: 23.5521\n",
            "Epoch 589/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 104.0094 - val_loss: 23.4538\n",
            "Epoch 590/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 104.1135 - val_loss: 23.4144\n",
            "Epoch 591/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 104.0065 - val_loss: 23.4093\n",
            "Epoch 592/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 103.9583 - val_loss: 23.4821\n",
            "Epoch 593/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 103.9350 - val_loss: 24.2134\n",
            "Epoch 594/700\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 103.8586 - val_loss: 23.9867\n",
            "Epoch 595/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 103.8132 - val_loss: 23.8124\n",
            "Epoch 596/700\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 103.8117 - val_loss: 23.7922\n",
            "Epoch 597/700\n",
            "6/6 [==============================] - 3s 559ms/step - loss: 103.7666 - val_loss: 23.8409\n",
            "Epoch 598/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 103.7031 - val_loss: 23.6519\n",
            "Epoch 599/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 103.6528 - val_loss: 23.6431\n",
            "Epoch 600/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 103.6090 - val_loss: 23.6211\n",
            "Epoch 601/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 103.6957 - val_loss: 23.7032\n",
            "Epoch 602/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 103.5684 - val_loss: 23.8149\n",
            "Epoch 603/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 103.5054 - val_loss: 23.7009\n",
            "Epoch 604/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 103.4798 - val_loss: 23.6342\n",
            "Epoch 605/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 103.4554 - val_loss: 23.6661\n",
            "Epoch 606/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 103.4745 - val_loss: 23.8643\n",
            "Epoch 607/700\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 103.4166 - val_loss: 23.7847\n",
            "Epoch 608/700\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 103.3882 - val_loss: 23.9294\n",
            "Epoch 609/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 103.3176 - val_loss: 23.9156\n",
            "Epoch 610/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 103.2931 - val_loss: 23.8640\n",
            "Epoch 611/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 103.2806 - val_loss: 23.8792\n",
            "Epoch 612/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 103.2429 - val_loss: 23.8959\n",
            "Epoch 613/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 103.2074 - val_loss: 23.9676\n",
            "Epoch 614/700\n",
            "6/6 [==============================] - 3s 555ms/step - loss: 103.1807 - val_loss: 23.9156\n",
            "Epoch 615/700\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 103.1078 - val_loss: 23.8416\n",
            "Epoch 616/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 103.0671 - val_loss: 23.7642\n",
            "Epoch 617/700\n",
            "6/6 [==============================] - 3s 531ms/step - loss: 103.0173 - val_loss: 23.7673\n",
            "Epoch 618/700\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 102.9995 - val_loss: 23.7634\n",
            "Epoch 619/700\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 102.9976 - val_loss: 24.0986\n",
            "Epoch 620/700\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 102.8920 - val_loss: 23.8247\n",
            "Epoch 621/700\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 102.8846 - val_loss: 23.7198\n",
            "Epoch 622/700\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 102.9659 - val_loss: 23.8294\n",
            "Epoch 623/700\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 102.8777 - val_loss: 23.7708\n",
            "Epoch 624/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 102.8832 - val_loss: 23.6399\n",
            "Epoch 625/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 102.9475 - val_loss: 23.8345\n",
            "Epoch 626/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 102.8084 - val_loss: 23.9099\n",
            "Epoch 627/700\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 102.8251 - val_loss: 23.7526\n",
            "Epoch 628/700\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 102.7225 - val_loss: 23.5894\n",
            "Epoch 629/700\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 102.7145 - val_loss: 23.5673\n",
            "Epoch 630/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 102.6362 - val_loss: 23.6042\n",
            "Epoch 631/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 102.5508 - val_loss: 23.8999\n",
            "Epoch 632/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 102.5472 - val_loss: 24.1476\n",
            "Epoch 633/700\n",
            "6/6 [==============================] - 3s 555ms/step - loss: 102.4879 - val_loss: 23.8935\n",
            "Epoch 634/700\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 102.4643 - val_loss: 23.7803\n",
            "Epoch 635/700\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 102.4109 - val_loss: 23.8557\n",
            "Epoch 636/700\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 102.3994 - val_loss: 24.0946\n",
            "Epoch 637/700\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 102.3369 - val_loss: 23.8776\n",
            "Epoch 638/700\n",
            "6/6 [==============================] - 3s 560ms/step - loss: 102.3042 - val_loss: 23.9357\n",
            "Epoch 639/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 102.4597 - val_loss: 23.7781\n",
            "Epoch 640/700\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 102.4038 - val_loss: 23.9772\n",
            "Epoch 641/700\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 102.2598 - val_loss: 24.2996\n",
            "Epoch 642/700\n",
            "6/6 [==============================] - 3s 557ms/step - loss: 102.2098 - val_loss: 24.2701\n",
            "Epoch 643/700\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 102.1971 - val_loss: 24.0769\n",
            "Epoch 644/700\n",
            "6/6 [==============================] - 3s 559ms/step - loss: 102.2552 - val_loss: 24.0746\n",
            "Epoch 645/700\n",
            "6/6 [==============================] - 3s 557ms/step - loss: 102.2461 - val_loss: 23.7851\n",
            "Epoch 646/700\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 102.1102 - val_loss: 23.7530\n",
            "Epoch 647/700\n",
            "6/6 [==============================] - 3s 563ms/step - loss: 102.0979 - val_loss: 23.9114\n",
            "Epoch 648/700\n",
            "6/6 [==============================] - 3s 564ms/step - loss: 102.0799 - val_loss: 23.8138\n",
            "Epoch 649/700\n",
            "6/6 [==============================] - 3s 556ms/step - loss: 102.0093 - val_loss: 23.8006\n",
            "Epoch 650/700\n",
            "6/6 [==============================] - 3s 573ms/step - loss: 101.8977 - val_loss: 23.8120\n",
            "Epoch 651/700\n",
            "6/6 [==============================] - 3s 563ms/step - loss: 101.8401 - val_loss: 23.7594\n",
            "Epoch 652/700\n",
            "6/6 [==============================] - 3s 570ms/step - loss: 101.7662 - val_loss: 23.6269\n",
            "Epoch 653/700\n",
            "6/6 [==============================] - 3s 566ms/step - loss: 101.7599 - val_loss: 23.6879\n",
            "Epoch 654/700\n",
            "6/6 [==============================] - 3s 577ms/step - loss: 101.7191 - val_loss: 23.7444\n",
            "Epoch 655/700\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 101.6510 - val_loss: 23.9588\n",
            "Epoch 656/700\n",
            "6/6 [==============================] - 3s 576ms/step - loss: 101.6224 - val_loss: 23.7902\n",
            "Epoch 657/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 101.5789 - val_loss: 23.7752\n",
            "Epoch 658/700\n",
            "6/6 [==============================] - 3s 563ms/step - loss: 101.5202 - val_loss: 23.6399\n",
            "Epoch 659/700\n",
            "6/6 [==============================] - 3s 562ms/step - loss: 101.4950 - val_loss: 23.6124\n",
            "Epoch 660/700\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 101.4209 - val_loss: 23.6729\n",
            "Epoch 661/700\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 101.4263 - val_loss: 24.1173\n",
            "Epoch 662/700\n",
            "6/6 [==============================] - 3s 571ms/step - loss: 101.3535 - val_loss: 23.9762\n",
            "Epoch 663/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 101.2949 - val_loss: 24.6209\n",
            "Epoch 664/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 101.2646 - val_loss: 24.2054\n",
            "Epoch 665/700\n",
            "6/6 [==============================] - 3s 575ms/step - loss: 101.2047 - val_loss: 24.1031\n",
            "Epoch 666/700\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 101.1526 - val_loss: 24.1948\n",
            "Epoch 667/700\n",
            "6/6 [==============================] - 3s 571ms/step - loss: 101.1378 - val_loss: 23.9475\n",
            "Epoch 668/700\n",
            "6/6 [==============================] - 3s 575ms/step - loss: 101.1384 - val_loss: 24.0482\n",
            "Epoch 669/700\n",
            "6/6 [==============================] - 3s 582ms/step - loss: 101.0450 - val_loss: 23.7841\n",
            "Epoch 670/700\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 101.0067 - val_loss: 23.7649\n",
            "Epoch 671/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 100.9628 - val_loss: 24.0583\n",
            "Epoch 672/700\n",
            "6/6 [==============================] - 3s 566ms/step - loss: 100.9048 - val_loss: 24.1441\n",
            "Epoch 673/700\n",
            "6/6 [==============================] - 3s 577ms/step - loss: 100.8386 - val_loss: 24.0918\n",
            "Epoch 674/700\n",
            "6/6 [==============================] - 3s 573ms/step - loss: 100.9155 - val_loss: 23.9278\n",
            "Epoch 675/700\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 100.8934 - val_loss: 24.4197\n",
            "Epoch 676/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 100.9928 - val_loss: 23.9811\n",
            "Epoch 677/700\n",
            "6/6 [==============================] - 3s 566ms/step - loss: 100.9608 - val_loss: 24.5115\n",
            "Epoch 678/700\n",
            "6/6 [==============================] - 3s 570ms/step - loss: 100.7224 - val_loss: 24.3839\n",
            "Epoch 679/700\n",
            "6/6 [==============================] - 3s 578ms/step - loss: 100.5575 - val_loss: 24.0544\n",
            "Epoch 680/700\n",
            "6/6 [==============================] - 3s 574ms/step - loss: 100.5649 - val_loss: 24.1494\n",
            "Epoch 681/700\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 100.4825 - val_loss: 23.9288\n",
            "Epoch 682/700\n",
            "6/6 [==============================] - 3s 572ms/step - loss: 100.4531 - val_loss: 24.0618\n",
            "Epoch 683/700\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 100.3912 - val_loss: 24.1079\n",
            "Epoch 684/700\n",
            "6/6 [==============================] - 3s 566ms/step - loss: 100.3786 - val_loss: 24.8762\n",
            "Epoch 685/700\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 100.3766 - val_loss: 24.1247\n",
            "Epoch 686/700\n",
            "6/6 [==============================] - 3s 574ms/step - loss: 100.4271 - val_loss: 23.8238\n",
            "Epoch 687/700\n",
            "6/6 [==============================] - 3s 572ms/step - loss: 100.3766 - val_loss: 23.8375\n",
            "Epoch 688/700\n",
            "6/6 [==============================] - 3s 567ms/step - loss: 100.2510 - val_loss: 23.9527\n",
            "Epoch 689/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 100.1738 - val_loss: 24.0910\n",
            "Epoch 690/700\n",
            "6/6 [==============================] - 3s 562ms/step - loss: 100.0248 - val_loss: 23.9846\n",
            "Epoch 691/700\n",
            "6/6 [==============================] - 3s 572ms/step - loss: 99.9871 - val_loss: 24.0319\n",
            "Epoch 692/700\n",
            "6/6 [==============================] - 3s 566ms/step - loss: 99.9291 - val_loss: 23.8675\n",
            "Epoch 693/700\n",
            "6/6 [==============================] - 3s 557ms/step - loss: 99.8700 - val_loss: 24.2223\n",
            "Epoch 694/700\n",
            "6/6 [==============================] - 3s 562ms/step - loss: 99.8969 - val_loss: 24.2015\n",
            "Epoch 695/700\n",
            "6/6 [==============================] - 3s 564ms/step - loss: 99.7962 - val_loss: 24.0126\n",
            "Epoch 696/700\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 99.6677 - val_loss: 24.2585\n",
            "Epoch 697/700\n",
            "6/6 [==============================] - 3s 572ms/step - loss: 99.6609 - val_loss: 24.1647\n",
            "Epoch 698/700\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 99.8438 - val_loss: 23.9303\n",
            "Epoch 699/700\n",
            "6/6 [==============================] - 3s 574ms/step - loss: 99.8812 - val_loss: 23.8380\n",
            "Epoch 700/700\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 99.7392 - val_loss: 23.9045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "y1AAJbUmkuj1",
        "outputId": "b75472d0-cb8d-4d71-f571-1ac097f66ba7"
      },
      "source": [
        "plt.plot(history_e2d2.history['loss'])\n",
        "plt.plot(history_e2d2.history['val_loss'])\n",
        "plt.title(\"E2D2 Model Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Valid'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyPZhfBik46t"
      },
      "source": [
        "pred1_e2d2=model_e2d2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SqWoGwsk_zj",
        "outputId": "349fe486-c9ea-4aaf-9a49-6b7d922e7954"
      },
      "source": [
        "pred1_e2d2[0,:,-1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ApKfV8nrk5uE",
        "outputId": "e6d6d77a-e89e-426e-fdbc-57cb130df460"
      },
      "source": [
        "plt.plot(pred1_e2d2[:,0,-1],label=\"Predicted\")\n",
        "plt.plot(range(len(test_df)),test_df[\"Close\"],label=\"Actual\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqvY3tpClWXw",
        "outputId": "c91add9f-63aa-4135-cd20-a6e4772cc5e7"
      },
      "source": [
        "pred1_e2d2[:,0,-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.28015,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 , 528.2802 ,\n",
              "       528.2802 , 528.2802 , 528.2802 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD-cjwx8niQG"
      },
      "source": [
        "model_e2d2.save('nvidia1.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNFZ0yYBqiiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4fdc98-acee-43ed-ef40-797eebbf0d3e"
      },
      "source": [
        "model_e2d2.evaluate(X_test,y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 84ms/step - loss: 23.9045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.90453338623047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtSY4AWw8bmG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}